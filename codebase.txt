
================================================================================
FILE: ./README.md
================================================================================

# Mellon

Mellon is a client/server application to easily interface with ML tools with a focus on [Diffusers](https://github.com/huggingface/diffusers).

> [!CAUTION]
> This is just a proof of concept and it is not ready for production. It's not even alpha-stage. DO NOT USE IT unless you know what you are doing.

## Installation

```bash
git clone https://github.com/cubiq/Mellon.git
cd Mellon
python -m venv venv
source venv/bin/activate
pip install --upgrade pip
pip install -r requirements.txt
```

On Windows before the requirements you need to install torch for your platform:

```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124
```

Then you can run the server with:

```bash
python main.py
```

or on Linux:

```bash
./run.sh
```

To access the UI, open your browser and navigate to `http://localhost:8080`.

## Configuration

Not much configuration is available at the moment. If you need to run the server on a remote machine, you can create a `config.ini` file and change the `server` section as needed. Eg:

```ini
[server]
host = 0.0.0.0
port = 8080
cors = true
cors_routes = *
```

You should be able to access the UI at `http://<ip_address>:8080`.

## Usage

This is just an alpha-stage development version. Not much is supported but you can start from the SD35 Pipeline:

![Mellon workflow](./mellon_basic_wf.jpg)

## How it works

- The server loads the nodes definitions from the `__init__.py` files in the `modules` folder. The nodes are defined as Python classes with a `MODULE_MAP` object that maps the node structure.
- When the client first logs in, it gets a definition of all the nodes (route: `GET /nodes`) and the sidebar is populated.
- At this point you can drag and drop nodes in the canvas and connect them.
- Pressing `Run` will send the graph definition to the server (route: `POST /graph`). The workflow is queued and executed automatically.

## How to create a new node for a new module

The `modules` folder is for "official" modules. In the future `custom` is where you will put your custom modules.

For now create a new folder in the `modules` folder, inside of it put a python file with the same name of the directory and add an `__init__.py`. Eg:

```
modules/
    MyModule/
        __init__.py
        MyModule.py
```

In the `__init__.py` file, define the `MODULE_MAP` object. As reference you can look at the other modules.

The following is the node definition for the `BlendImages` node:

```python
MODULE_MAP = {
    'BlendImages': {
        'label': 'Blend Images',
        'category': 'image',
        'params': {
            'source': {
                'label': 'Source',
                'display': 'input',
                'type': 'image',
            },
            'target': {
                'label': 'Target',
                'display': 'input',
                'type': 'image',
            },
            'amount': {
                'label': 'Amount',
                'type': 'float',
                'display': 'slider',
                'default': 0.5,
                'min': 0,
                'max': 1,
            },
            'blend': {
                'label': 'Blend',
                'display': 'output',
                'type': 'image',
            },
        },
    }
}
```

Inside the `MyModule.py` file, create the node class. The class name must be the same as defined in the `MODULE_MAP`. In the example above, the class name is `BlendImages`.

```python
class BlendImages(NodeBase):
    def execute(self, source, target, amount):
        source = toTensor(source)
        target = toTensor(target)
        blend = source * amount + target * (1 - amount)
        blend = toPIL(blend)

        return { 'blend': blend }
```

It's important to extend your class from `NodeBase` class. That will take care of the basic validation, but technically you can build your own validation as long as the class has `__init__` and `__call__` methods.

The `execute` method expects all the parameters defined in the `MODULE_MAP`. In this case `source`, `target` and `amount`.

Note that `blend` is defined as an output parameter. The `execute` method should return a dictionary containing the `blend` key: `return { 'blend': blend }`.

You can change the name of the callback by setting the `CALLBACK` class attribute.

```python
class BlendImages(NodeBase):
    CALLBACK = 'blend_images'

    def blend_images(self, source, target, amount):
```

> [!IMPORTANT]
> This is a preliminary implementation and it will change in the future. Your suggestions are welcome.

## Client development

The client development is in a different repository: https://github.com/cubiq/Mellon-client

It's based on [ReactFlow](https://reactflow.dev/), [MUI](https://mui.com/) and [Vite](https://vitejs.dev/).

## Contact

At this stage the best way to contact me regarding the project is via [X/Twitter](https://x.com/cubiq) or [discord](https://latent.vision/discord).


================================================================================
FILE: ./codebase.txt
================================================================================



================================================================================
FILE: ./collect_codebase.py
================================================================================

import os
import fnmatch
import re

def should_skip_file(filename):
    # Root level files to skip
    root_level_skips = {
        'LICENSE',
        'LICENSE.txt',
        'LICENSE.md',
    }
    
    # If it's a root level file that should be skipped
    if os.path.dirname(filename) == '.' and os.path.basename(filename) in root_level_skips:
        return True

    # Skip patterns for files we don't want to include
    skip_patterns = [
        '*.min.js',      # Minified JavaScript
        '*.pyc',         # Python compiled files
        '*.pyo',         # Python optimized files
        '*.pyd',         # Python DLL files
        '*.so',          # Shared libraries
        '*.dll',         # DLL files
        '*.dylib',       # Dynamic libraries
        '*.class',       # Java compiled files
        '*.exe',         # Executables
        '*.o',           # Object files
        '*.a',           # Static libraries
        '*.lib',         # Library files
        '*.zip',         # Archives
        '*.tar',         # Archives
        '*.gz',          # Compressed files
        '*.rar',         # Compressed files
        '*.7z',          # Compressed files
        '*.map',         # Source map files
        'README*',       # README files
        'CHANGELOG*',    # Changelog files
        'requirements*.txt',  # Requirements files
        '*.svg',         # SVG files
        '*.png',         # Images
        '*.jpg',         # Images
        '*.jpeg',        # Images
        '*.gif',         # Images
        '*.ico',         # Icons
        '*.woff',        # Fonts
        '*.woff2',       # Fonts
        '*.ttf',         # Fonts
        '*.eot',         # Fonts
        '*.css',         # CSS files
        '*.scss',        # SCSS files
        '*.sass',        # SASS files
        '*.less',        # LESS files
        '*.json',        # JSON files
        'package-lock.json',  # NPM lock file
        'yarn.lock',     # Yarn lock file
        'pnpm-lock.yaml', # PNPM lock file
    ]
    
    # Skip files that look like build artifacts (containing hashes)
    if re.search(r'-[a-zA-Z0-9]{8,}\.', filename):
        return True
        
    return any(fnmatch.fnmatch(filename.lower(), pattern.lower()) for pattern in skip_patterns)

def should_skip_directory(dirpath):
    # Directories to skip
    skip_dirs = {
        'venv',
        'env',
        'node_modules',
        '__pycache__',
        '.git',
        '.idea',
        '.vscode',
        'site-packages',
        'dist',
        'build',
        'tests',
        'test',
        'docs',
        'examples',
        'assets',      # Web assets directory
        'static',      # Static files directory
        'public',      # Public assets
        'images',      # Image directories
        'img',         # Image directories
        'fonts',       # Font directories
        'css',         # CSS directories
        'scss',        # SCSS directories
        'styles',      # Style directories
    }
    
    dir_name = os.path.basename(dirpath)
    return dir_name.lower() in skip_dirs

def collect_code(start_path='.'):
    with open('codebase.txt', 'w', encoding='utf-8') as outfile:
        for root, dirs, files in os.walk(start_path):
            # Remove directories we want to skip
            dirs[:] = [d for d in dirs if not should_skip_directory(os.path.join(root, d)) and not d.startswith('.')]
            
            for file in sorted(files):
                if file.startswith('.'):
                    continue
                    
                filepath = os.path.join(root, file)
                
                if should_skip_file(filepath):
                    continue
                
                try:
                    with open(filepath, 'r', encoding='utf-8') as infile:
                        content = infile.read()
                        
                    # Write file path with clear demarcation
                    outfile.write('\n' + '=' * 80 + '\n')
                    outfile.write(f'FILE: {filepath}\n')
                    outfile.write('=' * 80 + '\n\n')
                    outfile.write(content)
                    outfile.write('\n')
                except (UnicodeDecodeError, IOError):
                    # Skip binary files or files that can't be read as text
                    continue

if __name__ == '__main__':
    collect_code() 

================================================================================
FILE: ./config.example.ini
================================================================================

[server]
host = 127.0.0.1
port = 8080

[logging]
level = INFO

[huggingface]
token = 
cache_dir = ./data/huggingface

# online_status = Always online | Connect if needed | Local files only
online_status = Connect if needed

[paths]
data = data
temp = data/temp

[environ]
# environment variables, eg:
# CC = /usr/bin/gcc-13
# CXX = /usr/bin/g++-13
# TORCH_CUDA_ARCH_LIST = 8.6+PTX

================================================================================
FILE: ./config.ini
================================================================================

[server]
host = 127.0.0.1
port = 8080
cors = true
cors_routes = *

================================================================================
FILE: ./config.py
================================================================================

import configparser
import logging
import os

class Config:
    def __init__(self):
        self.config = configparser.ConfigParser()
        self.config.read('config.ini')

        self.server = {
            'host': self.config.get('server', 'host', fallback='127.0.0.1'),
            'port': self.config.getint('server', 'port', fallback=8080),
            'cors': self.config.getboolean('server', 'cors', fallback=False),
            'cors_route': self.config.get('server', 'cors_route', fallback='*'),
        }

        self.app = {
            'global_seed': self.config.getint('app', 'global_seed', fallback=42),
        }

        self.log = {
            'level': getattr(logging, self.config.get('logging', 'level', fallback='INFO').upper()),
        }

        self.hf = {
            'token': self.config.get('huggingface', 'token', fallback=None),
            'cache_dir': self.config.get('huggingface', 'cache_dir', fallback=None),
            'online_status': self.config.get('huggingface', 'online_status', fallback='Connect if needed'),
        }

        self.paths = {
            'data': self.config.get('paths', 'data', fallback='data'),
            'temp': self.config.get('paths', 'temp', fallback='data/temp'),
        }

        for path, value in self.paths.items():
            if not os.path.isabs(value):
                value = os.path.join(os.path.dirname(__file__), value)
                self.paths[path] = value

            if not os.path.exists(value):
                os.makedirs(value)

        self.environ = self.config['environ'] if 'environ' in self.config else {}
        for key, value in self.environ.items():
            self.environ[key] = self.config.get('environ', key, fallback=None)

config = Config()


================================================================================
FILE: ./main.py
================================================================================

import logging
import os
from config import config
import torch # warm up since we are going to use it anyway

# initialize logging
logging.basicConfig(level=config.log['level'], format="%(asctime)s [%(levelname)s] %(message)s", datefmt="%Y%m%d %H.%M.%S")
logger = logging.getLogger('mellon')

# random seed generation
# import numpy as np
#import random
# torch.cuda.manual_seed(0)
# torch.cuda.manual_seed_all(0)
# torch.backends.cudnn.deterministic = True
# torch.backends.cudnn.benchmark = False
# np.random.seed(0)
# random.seed(0)
# os.environ['PYTHONHASHSEED'] = str(0)
# os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'
# torch.use_deterministic_algorithms(True)

# huggingface cache directory
if config.hf['cache_dir']:
    os.environ['HF_HOME'] = config.hf['cache_dir']

# load modules
from modules import MODULE_MAP

# start web server
from mellon.server import web_server #WebServer
#web_server = WebServer(MODULE_MAP, **config.server)

# welcome message
logger.info(f"""\x1b[33;20m
╔══════════════════════╗
║  Welcome to Mellon!  ║
╚══════════════════════╝\x1b[0m
Speak Friend and Enter: http://{config.server['host']}:{config.server['port']}""")

# Engage!
web_server.run()



================================================================================
FILE: ./requirements.txt
================================================================================

aiohttp
aiohttp_cors
nanoid
torch
torchvision
torchaudio
git+https://github.com/huggingface/diffusers
transformers
accelerate
safetensors
protobuf
sentencepiece
einops

================================================================================
FILE: ./requirements_opt.txt
================================================================================

# for quantization
optimum-quanto
--extra-index-url https://download.pytorch.org/whl/cu124
torchao

# for clean caption
beautifulsoup4

# generic graphics
opencv-python


================================================================================
FILE: ./run.sh
================================================================================

#! /bin/bash

source .venv/bin/activate
python main.py


================================================================================
FILE: ./web/index.html
================================================================================

<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <link rel="icon" type="image/svg+xml" href="/assets/mellon.svg" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Mellon</title>
    <script type="module" crossorigin src="/assets/index-CV5RNCjT.js"></script>
    <link rel="modulepreload" crossorigin href="/assets/three-fiber-BV1ARQju.js">
    <link rel="stylesheet" crossorigin href="/assets/index-Dy63FbyS.css">
  </head>
  <body>
    <div id="root"></div>
  </body>
</html>


================================================================================
FILE: ./utils/__init__.py
================================================================================



================================================================================
FILE: ./utils/diffusers_utils.py
================================================================================

import torch

schedulers_config = {
    'FlowMatchEulerDiscreteScheduler': {
        'num_train_timesteps': 1000,
        'shift': 3.0,
        'use_dynamic_shifting': False,
        'base_shift': 0.5,
        'max_shift': 1.15,
        'base_image_seq_len': 256,
        'max_image_seq_len': 4096,
        'invert_sigmas': False,
    },
    'FlowMatchHeunDiscreteScheduler': {
        'num_train_timesteps': 1000,
        'shift': 3.0,
    }
}

vae_config = {
    'SD3': {
        'in_channels': 3,
        'out_channels': 3,
        'down_block_types': ['DownEncoderBlock2D', 'DownEncoderBlock2D', 'DownEncoderBlock2D', 'DownEncoderBlock2D'],
        'up_block_types': ['UpDecoderBlock2D', 'UpDecoderBlock2D', 'UpDecoderBlock2D', 'UpDecoderBlock2D'],
        'block_out_channels': [128, 256, 512, 512],
        'layers_per_block': 2,
        'latent_channels': 16,
    }
}

def dummy_vae(model_id):
    from diffusers import AutoencoderKL
    config = vae_config[model_id]
    return AutoencoderKL(**config)


def get_clip_prompt_embeds(prompt, tokenizer, text_encoder, clip_skip=None, noise=0.0, scale=1.0):
    max_length = tokenizer.model_max_length
    bos = torch.tensor([tokenizer.bos_token_id]).unsqueeze(0).to(text_encoder.device)
    eos = torch.tensor([tokenizer.eos_token_id]).unsqueeze(0).to(text_encoder.device)
    one = torch.tensor([1]).unsqueeze(0).to(text_encoder.device)
    pad = tokenizer.pad_token_id

    text_input_ids = tokenizer(prompt, truncation=False, return_tensors="pt").input_ids.to(text_encoder.device)

    # remove start and end tokens
    text_input_ids = text_input_ids[:, 1:-1]

    # we create chunks of max_length-2, we add start and end tokens back later
    chunks = text_input_ids.split(max_length-2, dim=-1)

    concat_embeds = []
    pooled_prompt_embeds = None
    for chunk in chunks:
        mask = torch.ones_like(chunk)

        # add start and end tokens to each chunk
        chunk = torch.cat([bos, chunk, eos], dim=-1)
        mask = torch.cat([one, mask, one], dim=-1)

        # pad the chunk to the max length
        if chunk.shape[-1] < max_length:
            mask = torch.nn.functional.pad(mask, (0, max_length - mask.shape[-1]), value=0)
            chunk = torch.nn.functional.pad(chunk, (0, max_length - chunk.shape[-1]), value=pad)

        # encode the tokenized text
        prompt_embeds = text_encoder(chunk, attention_mask=mask, output_hidden_states=True)
        
        if pooled_prompt_embeds is None:
            pooled_prompt_embeds = prompt_embeds[0]

        if clip_skip is None:
            prompt_embeds = prompt_embeds.hidden_states[-2]
        else:
            prompt_embeds = prompt_embeds.hidden_states[-(clip_skip + 2)]

        concat_embeds.append(prompt_embeds)

    prompt_embeds = torch.cat(concat_embeds, dim=1)

    if scale != 1.0:
        prompt_embeds = prompt_embeds * scale
        pooled_prompt_embeds = pooled_prompt_embeds * scale

    if noise > 0.0:
        generator_state = torch.get_rng_state()

        seed = int(prompt_embeds.mean().item() * 1e6) % (2**32 - 1)
        torch.manual_seed(seed)
        embed_noise = torch.randn_like(prompt_embeds) * prompt_embeds.abs().mean() * noise
        #embed_noise = torch.randn_like(prompt_embeds) * noise
        prompt_embeds = prompt_embeds + embed_noise

        seed = int(pooled_prompt_embeds.mean().item() * 1e6) % (2**32 - 1)
        torch.manual_seed(seed)
        embed_noise = torch.randn_like(pooled_prompt_embeds) * pooled_prompt_embeds.abs().mean() * noise
        #embed_noise = torch.randn_like(pooled_prompt_embeds) * noise
        pooled_prompt_embeds = pooled_prompt_embeds + embed_noise

        torch.set_rng_state(generator_state)

    return (prompt_embeds, pooled_prompt_embeds)


def get_t5_prompt_embeds(prompt, tokenizer, text_encoder, num_images_per_prompt = 1, max_sequence_length=256, noise=0.0):
    prompt = [prompt] if isinstance(prompt, str) else prompt
    batch_size = len(prompt)
    # could be tokenizer.model_max_length but we are using a more conservative value (256)
    max_length = max_sequence_length
    eos = torch.tensor([1]).unsqueeze(0).to(text_encoder.device)
    pad = 0 # pad token is 0

    text_inputs_ids = tokenizer(prompt, truncation = False, add_special_tokens=True, return_tensors="pt").input_ids.to(text_encoder.device)

    # remove end token
    text_inputs_ids = text_inputs_ids[:, :-1]

    chunks = text_inputs_ids.split(max_length-1, dim=-1)

    concat_embeds = []
    for chunk in chunks:
        mask = torch.ones_like(chunk)

        # add end token back
        chunk = torch.cat([chunk, eos], dim=-1)
        mask = torch.cat([mask, eos], dim=-1)

        # pad the chunk to the max length
        if chunk.shape[-1] < max_length:
            mask = torch.nn.functional.pad(mask, (0, max_length - mask.shape[-1]), value=0)
            chunk = torch.nn.functional.pad(chunk, (0, max_length - chunk.shape[-1]), value=pad)

        # encode the tokenized text
        prompt_embeds = text_encoder(chunk)[0]
        concat_embeds.append(prompt_embeds)

    prompt_embeds = torch.cat(concat_embeds, dim=1)

    if noise > 0.0:
        generator_state = torch.get_rng_state()
        seed = int(prompt_embeds.mean().item() * 1e6) % (2**32 - 1)
        torch.manual_seed(seed)
        embed_noise = torch.randn_like(prompt_embeds) * prompt_embeds.abs().mean() * noise
        prompt_embeds = prompt_embeds + embed_noise
        torch.set_rng_state(generator_state)

    #_, seq_len, _ = prompt_embeds.shape
    # duplicate text embeddings and attention mask for each generation per prompt, using mps friendly method
    #prompt_embeds = prompt_embeds.repeat(1, num_images_per_prompt, 1)
    #prompt_embeds = prompt_embeds.view(batch_size * num_images_per_prompt, seq_len, -1)

    return prompt_embeds


================================================================================
FILE: ./utils/hf_utils.py
================================================================================

from huggingface_hub import scan_cache_dir
from config import config
import os
import json
from pathlib import Path
import re

def is_file_cached(repo_id, filename):
    cache_dir = config.hf['cache_dir']
    cache_info = scan_cache_dir(cache_dir)

    for repo in cache_info.repos:
        if repo.repo_id == repo_id:
            revision = list(repo.revisions)[-1] if repo.revisions else None
            if not revision:
                continue
            return filename in [f.file_name for f in revision.files]

    return False

# TODO: find better strategy to find different kinds of models
def list_local_models(config_file='model_index.json', filters={"_class_name": r"Pipeline$"}):
    cache_dir = config.hf['cache_dir']
    cache_info = scan_cache_dir(cache_dir)
    local_models = [] #[model.repo_id for model in cache_info.repos]

    if not isinstance(config_file, list):
        config_file = [config_file]

    for repo in cache_info.repos:
        revision = list(repo.revisions)[-1] if repo.revisions else None

        if not revision:
            continue

        config_path = next((f for f in revision.files if f.file_name in config_file), None)
        if not config_path:
            continue

        config_path = Path(config_path.file_path)

        if config_path.exists():
            with open(config_path, 'r') as f:
                model_info = json.load(f)
            if filters:
                # Check if all filter conditions match
                matches_all = True
                for key, pattern in filters.items():
                    if key not in model_info:
                        matches_all = False
                        break
                    
                    value = model_info[key]
                    # Handle both single values and lists
                    if not isinstance(value, list):
                        value = [value]
                    
                    # Check if any value matches the regex pattern
                    if not any(re.search(pattern, str(v)) for v in value):
                        matches_all = False
                        break
                
                if matches_all:
                    local_models.append(repo.repo_id)
            else:
                #if '_class_name' in model_info and 'Pipeline' in model_info['_class_name']:
                local_models.append(repo.repo_id)

    local_models.sort()
    return local_models

def get_repo_path(model_id):
    cache_dir = config.hf['cache_dir']
    cache_info = scan_cache_dir(cache_dir)
    for repo in cache_info.repos:
        if repo.repo_id == model_id:
            latest_revision = list(repo.revisions)[-1] if repo.revisions else None
            if latest_revision:
                return os.path.join(repo.repo_path, latest_revision.snapshot_path)

    return None

def is_local_files_only(model_id):
    return config.hf['online_status'] == 'Local files only' or (config.hf['online_status'] == 'Connect if needed' and model_id in list_local_models())


================================================================================
FILE: ./utils/memory_manager.py
================================================================================

import torch
import gc
import time
from utils.torch_utils import device_list
from enum import Enum
import logging
logger = logging.getLogger('mellon')


def memory_flush(gc_collect=False, reset=False):
    if gc_collect:
        gc.collect()

    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        #torch.cuda.synchronize()
        torch.cuda.ipc_collect()

        if reset:
            for _, d in device_list.items():
                torch.cuda.reset_max_memory_allocated(d['index'])
                torch.cuda.reset_peak_memory_stats(d['index'])

class MemoryManager:
    def __init__(self, memory_threshold=.9):
        self.cache = {}
        self.memory_threshold = memory_threshold

    def add_model(self, model, model_id, device='cpu', priority=2):
        priority = priority if isinstance(priority, int) else 2

        if model_id not in self.cache:
            self.cache[model_id] = {
                'model': model,
                'device': device,           # device the model is currently on
                'priority': priority,       # priority, lower priority models are unloaded first
                'last_used': time.time(),   # time the model was last used
            }

        return model_id

    def get_available_memory(self, device):
        return torch.cuda.get_device_properties(device).total_memory - torch.cuda.memory_allocated(device)

    def get_model(self, model_id):
        return self.cache[model_id]['model'] if model_id in self.cache else None

    def get_model_info(self, model_id):
        return self.cache[model_id] if model_id in self.cache else None

    def load_model(self, model_id, device):
        self.cache[model_id]['last_used'] = time.time()
        x = self.cache[model_id]['model']

        if device == str(x.device):
            return x

        if device == 'cpu':
            return self.unload_model(model_id)

        cache_priority = []
        # Sort models by priority and last_used
        for id, model in self.cache.items():
            if model['device'] == device:
                cache_priority.append((model['priority'], model['last_used'], id))

        cache_priority.sort()
        memory_flush()

        while True:
            # Attempt to load the model
            try:
                x = x.to(device)
                self.cache[model_id]['device'] = device
                return x
            
            except torch.OutOfMemoryError as e:
                if not cache_priority:
                    logger.debug("No more models to unload, cannot free sufficient memory")
                    raise e

                next_model_id = cache_priority.pop(0)[2]
                logger.debug(f"OOM error, unloading lower priority model: {next_model_id}")
                self.unload_model(next_model_id)

            except Exception as e:
                raise e


    def unload_model(self, model_id):
        if model_id in self.cache:
            self.cache[model_id]['model'] = self.cache[model_id]['model'].to('cpu')
            self.cache[model_id]['device'] = 'cpu'
            memory_flush()

        return self.cache[model_id]['model']
    
    def unload_all(self, exclude=[]):
        if not isinstance(exclude, list):
            exclude = [exclude]

        for model_id in self.cache:
            if model_id not in exclude:
                self.unload_model(model_id)

    def delete_model(self, model_id):
        model_id = model_id if isinstance(model_id, list) else [model_id]

        for m in model_id:
            if m in self.cache:
                classname = self.cache[m]['model'].__class__.__name__ if hasattr(self.cache[m]['model'], '__class__') else 'Unknown'
                logger.debug(f"Deleting model {classname}, id: {m}")
                #self.unload_model(m)
                del self.cache[m]['model']
                del self.cache[m]

        memory_flush()

    def update_model(self, model_id, model=None, priority=None, unload=True):
        if model_id in self.cache:
            if model:
                if unload:
                    self.unload_model(model_id)
                self.cache[model_id]['model'] = model
                memory_flush()
            if priority:
                self.cache[model_id]['priority'] = priority

    def is_cached(self, model_id):
        return model_id in self.cache
    
    def cache_count(self):
        return len(self.cache)
    
    def flash_load(self, model, model_id, device='cpu', priority=3):
        model_id = self.add_model(model, model_id, device=device, priority=priority)
        model = self.load_model(model_id, device)
        self.delete_model(model_id)

        return model
    
    def unload_next(self, device, exclude=[]):
        if not self.cache:
            return False
        
        if not isinstance(exclude, list):
            exclude = [exclude]

        # Sort models by priority and last_used
        cache_priority = []
        for id, model in self.cache.items():
            if model['device'] == device and id not in exclude:
                cache_priority.append((model['priority'], model['last_used'], id))

        cache_priority.sort()
        next_model_id = cache_priority.pop(0)[2]

        self.unload_model(next_model_id)
        return True

memory_manager = MemoryManager()


================================================================================
FILE: ./utils/torch_utils.py
================================================================================

import torch

def list_devices():
    host = ""  # TODO: support multiple hosts

    devices = {}
    default_device = None
    cpu = {
        "index": 0,
        "device": "cpu",
        "host": host,
        "label": host + "cpu",
        "total_memory": None,
        #"name": "CPU"
    } # TODO: probably need to support multiple cpus

    if torch.cuda.is_available():
        for i in range(torch.cuda.device_count()):
            key = f"{host}cuda:{i}"

            if default_device is None:
                default_device = key

            devices[key] = {
                "index": i,
                "device": f"cuda:{i}",
                "host": host,
                "label": host + f"cuda:{i}",
                "total_memory": torch.cuda.get_device_properties(i).total_memory,
                #"name": f"{torch.cuda.get_device_properties(i).name}"
            }

        devices[f"{host}cpu"] = cpu

    elif torch.mps.is_available():
        key = f"{host}mps"
        default_device = key
        devices[key] = {
            "index": 0,
            "device": "mps",
            "host": host,
            "label": host + "mps",
            "total_memory": None,
            #"name": "MPS"
        }

    else:
        key = f"{host}cpu"
        default_device = key
        devices[key] = cpu

    return devices, default_device

device_list, default_device = list_devices()

def str_to_dtype(dtype, params):
    return {
        'auto': None,
        'float32': torch.float32,
        'float16': torch.float16,
        'bfloat16': torch.bfloat16,
        'float8_e4m3fn': torch.float8_e4m3fn,
    }[dtype]

def toTensor(image):
    from torchvision.transforms import v2 as tt
    image = tt.PILToTensor()(image) / 255.0
    return image

def toPIL(tensor):
    from torchvision.transforms import v2 as tt
    if len(tensor.shape) == 3:
        tensor = tensor.unsqueeze(0)
    images = []
    for t in tensor:
        images.append(tt.ToPILImage()(t.clamp(0, 1).float()))

    return images

def toLatent(image):
    from torchvision.transforms import v2 as tt
    image = image.convert('RGB')
    image = tt.PILToTensor()(image) / 127.5 - 1
    if len(image.shape) == 3:
        image = image.unsqueeze(0)

    return image

def compile(model):
    torch._inductor.config.conv_1x1_as_mm = True
    torch._inductor.config.coordinate_descent_tuning = True
    torch._inductor.config.epilogue_fusion = False
    torch._inductor.config.coordinate_descent_check_all_directions = True
    model.to(memory_format=torch.channels_last)

    return torch.compile(model, mode='max-autotune', fullgraph=True)

================================================================================
FILE: ./mellon/NodeBase.py
================================================================================

import logging
logger = logging.getLogger('mellon')
from modules import MODULE_MAP
import torch
import time
from utils.memory_manager import memory_flush, memory_manager
from mellon.server import web_server
import nanoid

def get_module_params(module_name, class_name):
    params = MODULE_MAP[module_name][class_name]['params'] if module_name in MODULE_MAP and class_name in MODULE_MAP[module_name] else {}
    return { p: params[p]['default'] if 'default' in params[p] else None
            for p in params if not 'display' in params[p] or (params[p]['display'] != 'output' and params[p]['display'] != 'ui') }

def get_module_output(module_name, class_name):
    params = MODULE_MAP[module_name][class_name]['params'] if module_name in MODULE_MAP and class_name in MODULE_MAP[module_name] else {}
    return { p: None for p in params if 'display' in params[p] and params[p]['display'] == 'output' }

def filter_params(params, args):
    return { key: args[key] for key in args if key in params }

def has_changed(params, args):
    return any(params.get(key) != args.get(key) for key in args if key in params)

def are_different(a, b):
    # check if the types are different
    if type(a) != type(b):
        return True
    
    if isinstance(a, (list, tuple)):
        if len(a) != len(b):
            return True
        
        return any(are_different(x, y) for x, y in zip(a, b))

    if isinstance(a, dict):
        if a.keys() != b.keys():
            return True
        
        return any(are_different(a[k], b[k]) for k in a)

    if hasattr(a, 'dtype'):
        if not hasattr(b, 'dtype') or a.dtype != b.dtype:
            return True

    if hasattr(a, 'shape'):
        if not hasattr(b, 'shape') or a.shape != b.shape:
            return True
    
    if isinstance(a, torch.Tensor):
        return not torch.equal(a, b)

    if hasattr(a, '__dict__') and hasattr(b, '__dict__'):
        if a.__dict__ != b.__dict__:
            return True

    if a != b:
        return True

    return False

class NodeBase():
    CALLBACK = 'execute'

    def __init__(self, node_id=None):
        self.node_id = node_id
        self.module_name = self.__class__.__module__.split('.')[-1]
        if 'custom.' in self.__class__.__module__:
            self.module_name = self.module_name + '.custom'
        self.class_name = self.__class__.__name__
        self.params = {}
        self.output = get_module_output(self.module_name, self.class_name)
        
        self._client_id = None
        self._pipe_interrupt = False
        self._mm_model_ids = []
        self._execution_time = 0

    def __call__(self, **kwargs):
        self._pipe_interrupt = False

        # if the node_id is not set, the class was called by the user and it's not part of a workflow,
        # we execute the method directly
        if not self.node_id:
            params = { key: kwargs[key] for key in kwargs if not key.startswith('__') }
            return getattr(self, self.CALLBACK)(**params)

        values = self._validate_params(kwargs)

        execution_time = time.time()

        if self._has_changed(values):
            self.params.update(values)

            # delete previously loaded models
            # TODO: delete a model only if something changed about it
            if self._mm_model_ids:
                memory_manager.delete_model(self._mm_model_ids)
                self._mm_model_ids = []

            try:
                params = { key: self.params[key] for key in self.params if not key.startswith('__') }
                output = getattr(self, self.CALLBACK)(**params)
            except Exception as e:
                self.params = {}
                self.output = get_module_output(self.module_name, self.class_name)
                memory_flush(gc_collect=True)
                raise e

            if isinstance(output, dict):
                # Overwrite output values only for existing keys
                #self.output.update({k: output[k] for k in self.output if k in output})
                self.output = output
            else:
                # If only a single value is returned, assign it to the first output
                first_key = next(iter(self.output))
                self.output[first_key] = output

        self._execution_time = time.time() - execution_time

        # for good measure, flush the memory
        memory_flush()

        return self.output

    def __del__(self):
        del self.params, self.output # TODO: check if this actually works with cuda

        if self._mm_model_ids:
            memory_manager.delete_model(self._mm_model_ids)

        memory_flush(gc_collect=True)

    def _validate_params(self, values):
        # get the parameters schema for the module/class
        schema = MODULE_MAP[self.module_name][self.class_name]['params'] if self.module_name in MODULE_MAP and self.class_name in MODULE_MAP[self.module_name] else {}

        # get the default values for the parameters
        defaults = get_module_params(self.module_name, self.class_name)

        # filter out any input args that are not valid parameters and exclude the special fields starting with __
        values = { key: values[key] for key in values if key in defaults and not key.startswith('__') }

        # ensure the values are of the correct type
        for key in values:
            if 'type' in schema[key]:
                # type can be a list, used to allow multiple types with input handles (a helper for the UI)
                # the main type is the first one in the list
                type = (schema[key]['type'][0] if isinstance(schema[key]['type'], list) else schema[key]['type']).lower()

                if type.startswith('int'):
                    values[key] = int(values[key]) if not isinstance(values[key], list) else [int(v) for v in values[key]]
                elif type == 'float':
                    values[key] = float(values[key]) if not isinstance(values[key], list) else [float(v) for v in values[key]]
                elif type.startswith('bool'):
                    values[key] = bool(values[key]) if not isinstance(values[key], list) else [bool(v) for v in values[key]]
                elif type.startswith('str'):
                    values[key] = str(values[key] or '') if not isinstance(values[key], list) else [str(v or '') for v in values[key]]

        # we perform a second pass for cross parameter validation when calling the postProcess function
        for key in values:
            # ensure the value is a valid option (mostly for dropdowns)
            if 'options' in schema[key] and not ('no_validation' in schema[key] and schema[key]['no_validation']):
                options = schema[key]['options']

                # options can be in the format: [ 1, 2, 3 ] or { '1': { }, '2': { }, '3': { } }
                if isinstance(options, list):
                    val = [values[key]] if isinstance(values[key], str) else values[key]
                    if any(v not in options for v in val):
                        raise ValueError(f"Invalid value for {key}: {values[key]}")
                elif isinstance(options, dict):
                    val = [values[key]] if isinstance(values[key], str) else values[key]
                    if any(v not in options for v in val):
                        raise ValueError(f"Invalid value for {key}: {values[key]}")
                else:
                    raise ValueError(f"Invalid options for {key}: {options}")

            # call the postProcess function if present
            if 'postProcess' in schema[key]:
                # we pass the value and the entire dict for cross parameter validation
                values[key] = schema[key]['postProcess'](values[key], values)

        # update the default values with the validated values
        defaults.update(values)

        return defaults

    def _has_changed(self, values):
        return any(
            key not in self.params or
            are_different(self.params.get(key), values.get(key))
            for key in values
        )
    
    def pipe_callback(self, pipe, step_index, timestep, kwargs):
        import asyncio
        if self.node_id:
            try:
                progress = int((step_index + 1) / pipe._num_timesteps * 100)
                asyncio.run_coroutine_threadsafe(
                    web_server.client_queue.put({
                        "client_id": self._client_id,
                        "data": {
                            "type": "progress",
                            "nodeId": self.node_id,
                            "progress": progress
                        }
                    }), 
                    web_server.event_loop
                )
            except Exception as e:
                logger.warning(f"Error queuing progress update: {str(e)}")

            # interrupt callback
            if self._pipe_interrupt:
                pipe._interrupt = True

        return kwargs
    
    def mm_add(self, model, model_id=None, device=None, priority=2):
        # if the node_id is not set, the class was called directly and we skip the memory manager
        # it's up to the caller to manage the model
        if not self.node_id:
            return model

        if memory_manager.is_cached(model_id):
            self.mm_update(model_id, model=model, priority=priority)
            return model_id

        model_id = f'{self.node_id}.{model_id}' if model_id else f'{self.node_id}.{nanoid.generate(size=8)}'
        device = device if device else str(model.device)

        self._mm_model_ids.append(model_id)
        return memory_manager.add_model(model, model_id, device=device, priority=priority)

    def mm_get(self, model_id):
        model_id = model_id if isinstance(model_id, str) else model_id._mm_id if hasattr(model_id, '_mm_id') else None
        return memory_manager.get_model(model_id) if model_id else None

    def mm_load(self, model_id, device):
        model_id = model_id if isinstance(model_id, str) else model_id._mm_id if hasattr(model_id, '_mm_id') else None
        return memory_manager.load_model(model_id, device) if model_id else None

    def mm_unload(self, model_id):
        model_id = model_id if isinstance(model_id, str) else model_id._mm_id if hasattr(model_id, '_mm_id') else None
        return memory_manager.unload_model(model_id) if model_id else None

    def mm_update(self, model_id, model=None, priority=None, unload=True):
        model_id = model_id if isinstance(model_id, str) else model_id._mm_id if hasattr(model_id, '_mm_id') else None
        return memory_manager.update_model(model_id, model=model, priority=priority, unload=unload) if model_id else None
    
    def mm_inference(self, func, device, exclude=None, no_grad=False):
        exclude_list = []
        if exclude:
            exclude = [exclude] if not isinstance(exclude, list) else exclude
            for model in exclude:
                if isinstance(model, str):
                    exclude_list.append(model)
                elif hasattr(model, '_mm_id'):
                    exclude_list.append(model._mm_id)

        while True:
            try:
                with torch.inference_mode() if not no_grad else torch.no_grad():
                    return func()
            except torch.OutOfMemoryError as e:
                if memory_manager.unload_next(device, exclude=exclude):
                    continue
                else:
                    raise e
    
    def mm_flash_load(self, model, model_id=None, device='cpu', priority=3):
        model_id = f'{self.node_id}.{model_id}' if model_id else f'{self.node_id}.{nanoid.generate(size=8)}'
        device = device if device else str(model.device)

        return memory_manager.flash_load(model, model_id, device=device, priority=priority)


================================================================================
FILE: ./mellon/__init__.py
================================================================================



================================================================================
FILE: ./mellon/quantization.py
================================================================================

from config import config
from utils.memory_manager import memory_manager
import os

def set_compile_env():
    if 'CC' in config.environ and config.environ['CC']:
        os.environ['CC'] = config.environ['CC']
    if 'CXX' in config.environ and config.environ['CXX']:
        os.environ['CXX'] = config.environ['CXX']
    if 'TORCH_CUDA_ARCH_LIST' in config.environ and config.environ['TORCH_CUDA_ARCH_LIST']:
        os.environ['TORCH_CUDA_ARCH_LIST'] = config.environ['TORCH_CUDA_ARCH_LIST']

def quanto(model, weights, activations=None, exclude=None, device=None):
    from optimum.quanto import freeze, quantize

    set_compile_env()

    if device:
        model.to(device)

    weights_dtype = f"q{weights.lower()}"
    activations_dtype = f"q{activations.lower()}" if activations != 'none' else None

    weights_module = getattr(__import__('optimum.quanto', fromlist=[weights_dtype]), weights_dtype)
    activations_module = None
    if activations_dtype:
        activations_module = getattr(__import__('optimum.quanto', fromlist=[activations_dtype]), activations_dtype)

    exclude = exclude or []
    if isinstance(exclude, str):
        exclude = [item.strip() for item in exclude.split(',')]

    quantize(model, weights=weights_module, activations=activations_module, exclude=exclude)
    freeze(model)

    return model

def torchao(model, weights, device=None):
    from torchao.quantization.quant_api import quantize_

    set_compile_env()

    weights_dtype = f"{weights.lower()}"
    weights_module = getattr(__import__('torchao.quantization.quant_api', fromlist=[weights_dtype]), weights_dtype)

    quantize_(model, weights_module(), device=device)

class NodeQuantization():
    def quantize(self, type, **kwargs):
        if type == 'none':
            return
        elif type == 'torchao':
            return self._torchao(**kwargs)
        elif type == 'quanto':
            return self._quanto(**kwargs)
        else:
            raise ValueError(f"Invalid quantization type: {type}")

    def _torchao(self, model=None, device=None, torchao_weights=None, torchao_individual_layers=False, **kwargs):
        model_ids = model
        if not isinstance(model_ids, list):
            model_ids = [model_ids]
        
        device = device if torchao_individual_layers else None

        for model_id in model_ids:
            memory_manager.unload_all(exclude=[model_id])

            if not torchao_individual_layers:
                memory_manager.unload_all(exclude=[model_id])
                self.mm_load(model_id, device)
            else:
                memory_manager.unload_all()

            model = torchao(self.mm_get(model_id), torchao_weights, device=device)
            self.mm_update(model_id, model=model)

    def _quanto(self, model=None, device=None, quanto_weights=None, quanto_activations=None, quanto_exclude=None, **kwargs):
        model_ids = model
        if not isinstance(model_ids, list):
            model_ids = [model_ids]

        for model_id in model_ids:
            memory_manager.unload_all(exclude=[model_id])
            self.mm_load(model_id, device)
            model = quanto(self.mm_get(model_id), quanto_weights, activations=quanto_activations, exclude=quanto_exclude)
            self.mm_update(model_id, model=model)



================================================================================
FILE: ./mellon/server.py
================================================================================

import logging
logger = logging.getLogger('mellon')
from aiohttp import web, WSMsgType
from aiohttp_cors import setup as cors_setup, ResourceOptions
import json
import nanoid
import io
import base64
import re
from importlib import import_module
import asyncio
import traceback
from utils.memory_manager import memory_flush
from copy import deepcopy
import random
import signal
import time

class WebServer:
    def __init__(self, module_map: dict, host: str = "0.0.0.0", port: int = 8080, cors: bool = False, cors_route: str = "*"):
        self.module_map = module_map
        self.node_store = {}
        self.queue = asyncio.Queue()
        self.queue_task = None
        self.host = host
        self.port = port
        self.ws_clients = {}
        self.app = web.Application()
        self.event_loop = None

        self.client_queue = asyncio.Queue()
        self.client_task = None

        self.app.add_routes([web.get('/', self.index),
                             web.get('/nodes', self.nodes),
                             web.get('/view/{format}/{node}/{key}/{index}', self.view),
                             web.get('/custom_component/{module}/{component}', self.custom_component),
                             web.get('/custom_assets/{module}/{file_path}', self.custom_assets),
                             web.post('/graph', self.graph),
                             web.post('/nodeExecute', self.node_execute),
                             web.delete('/clearNodeCache', self.clear_node_cache),
                             web.static('/assets', 'web/assets'),
                             web.static('/custom', 'custom'),
                             web.get('/favicon.ico', self.favicon),
                             web.get('/ws', self.websocket_handler)])

        if cors:
            cors = cors_setup(self.app, defaults={
                cors_route: ResourceOptions(
                    allow_credentials=True,
                    expose_headers="*",
                    allow_headers="*",
                )
            })

            for route in list(self.app.router.routes()):
                cors.add(route)

    def run(self):
        async def start_app():
            shutdown_event = asyncio.Event()
            self.event_loop = asyncio.get_event_loop()

            async def shutdown():
                logger.info(f"Received signal interrupt. Namárië!")
                shutdown_event.set()

                # Close all websocket connections immediately
                for ws in list(self.ws_clients.values()):
                    await ws.close(code=1000, message=b'Server shutting down')
                self.ws_clients.clear()

            # Set up signal handlers
            for sig in (signal.SIGINT, signal.SIGTERM):
                self.event_loop.add_signal_handler(
                    sig,
                    lambda: asyncio.create_task(shutdown())
                )

            runner = web.AppRunner(self.app, client_max_size=1024**4)
            await runner.setup()
            site = web.TCPSite(runner, self.host, self.port)

            # Start queue processor
            self.queue_task = asyncio.create_task(self.process_queue())
            self.client_task = asyncio.create_task(self.process_client_messages())

            await site.start()

            try:
                await shutdown_event.wait()
            finally:
                # Cancel and wait for queue tasks
                for task in [self.queue_task, self.client_task]:
                    if task and not task.done():
                        task.cancel()
                        try:
                            await task
                        except asyncio.CancelledError:
                            pass

                await runner.cleanup()

        asyncio.run(start_app())

    async def process_client_messages(self):
        while True:
            message = await self.client_queue.get()
            try:
                await self.ws_clients[message["client_id"]].send_json(message["data"])
            except Exception as e:
                logger.error(f"Error sending client message: {str(e)}")
            finally:
                self.client_queue.task_done()

    async def process_queue(self):
        while True:
            item = await self.queue.get()
            try:
                if "kwargs" in item:
                    await self.node_execute_single(item)
                else:
                    await self.graph_execution(item)
            except Exception as e:
                logger.error(f"Error processing queue task: {str(e)}")
                logger.error(f"Error occurred in {traceback.format_exc()}")
                await self.broadcast({
                    "type": "error",
                    "error": "An unexpected error occurred while processing the graph"
                })
            finally:
                self.queue.task_done()

    async def index(self, request):
        response = web.FileResponse('web/index.html')
        response.headers["Cache-Control"] = "no-cache"
        response.headers["Pragma"] = "no-cache"
        response.headers["Expires"] = "0"
        return response

    async def favicon(self, request):
        return web.FileResponse('web/favicon.ico')

    """
    HTTP API
    """

    async def custom_component(self, request):
        module = request.match_info.get('module')
        component = request.match_info.get('component')

        # Handle full paths
        full_path = f"{module}/{component}"
        if '/' in component:
            full_path = f"{component}"

        response = web.FileResponse(f'{full_path}.js')
        response.headers["Content-Type"] = "application/javascript"
        response.headers["Cache-Control"] = "no-cache"
        response.headers["Pragma"] = "no-cache"
        response.headers["Expires"] = "0"
        return response

    async def custom_assets(self, request):
        module = request.match_info.get('module')
        file_path = request.match_info.get('file_path')

        #if module not in self.module_map:
        #    raise web.HTTPNotFound(text=f"Module {module} not found")

        return web.FileResponse(f'custom/{module}/web/assets/{file_path}')

    async def nodes(self, request):
        nodes = {}
        for module_name, actions in self.module_map.items():
            for action_name, action in actions.items():
                params = {}
                groups = {}
                if 'params' in action:
                    params = deepcopy(action['params'])

                    for p in params:
                        # remove attributes that are not needed by the client
                        if 'postProcess' in params[p]:
                            del params[p]['postProcess']

                nodes[f"{module_name}-{action_name}"] = {
                    "label": action.get('label', f"{module_name}: {action_name}"),
                    "module": module_name,
                    "action": action_name,
                    "category": self.slugify(action.get('category', 'default')),
                    "params": params,
                    "groups": groups,
                }
                if 'style' in action:
                    nodes[f"{module_name}-{action_name}"]["style"] = action['style']
                if 'resizable' in action:
                    nodes[f"{module_name}-{action_name}"]["resizable"] = action['resizable']
                if 'type' in action:
                    nodes[f"{module_name}-{action_name}"]["type"] = action['type']

        return web.json_response(nodes)
    
    async def view(self, request):
        allowed_formats = ['webp', 'png', 'jpeg', 'glb']

        format = request.match_info.get('format', 'webp').lower()
        if format not in allowed_formats:
            raise web.HTTPNotFound(text=f"Invalid format: {format}")

        nodeId = request.match_info.get('node')
        key = request.match_info.get('key')
        node = self.node_store.get(nodeId)

        if node is None:
            raise web.HTTPNotFound(text=f"Node {nodeId} not found")
        if key not in node.output:
            raise web.HTTPNotFound(text=f"Key {key} not found in node {nodeId}")   
        
        value = node.output[key]
        if value is None:
            raise web.HTTPNotFound(text=f"No data found for {key}")
        
        if not isinstance(value, list):
            value = [value]

        index = int(request.match_info.get("index", 0))
        if index < 0 or index >= len(value):
            raise web.HTTPNotFound(text=f"Index {index} out of bounds for {key}")
        
        # get additional request parameters
        quality = int(request.rel_url.query.get("quality", 100))
        quality = max(0, min(100, quality))
        scale = float(request.rel_url.query.get("scale", 1))
        scale = max(0.01, min(2, scale))
        filename = request.rel_url.query.get("filename", f"{key}_{index}.{format}")

        value = value[index]
        if scale != 1:
            from PIL.Image import Resampling
            width = int(value.width * scale)
            height = int(value.height * scale)
            value = value.resize((max(width, 1), max(height, 1)), resample=Resampling.BICUBIC)

        # return the value as image
        if format == "webp" or format == "png" or format == "jpeg":
            byte_arr = io.BytesIO()
            value.save(byte_arr, format=format.upper(), quality=quality)
            byte_arr = byte_arr.getvalue()
            return web.Response(
                body=byte_arr,
                content_type="image/webp",
                headers={
                    "Content-Disposition": f"inline; filename={filename}",
                    "Content-Length": str(len(byte_arr)),
                    "Cache-Control": "max-age=31536000, immutable",
                }
            )
        elif format == "glb":
            byte_arr = io.BytesIO()
            byte_arr.write(value)
            byte_arr = byte_arr.getvalue()
            return web.Response(
                body=byte_arr,
                content_type="model/glb",
                headers={
                    "Content-Disposition": f"inline; filename={key}.glb",
                    "Content-Length": str(len(byte_arr)),
                    "Cache-Control": "max-age=31536000, immutable",
                }
            )

    async def clear_node_cache(self, request):
        data = await request.json()
        nodeId = []

        if "nodeId" in data:
            nodeId = data["nodeId"] if isinstance(data["nodeId"], list) else [data["nodeId"]]
        else:
            nodeId = list(self.node_store.keys())

        for node in nodeId:
            if node in self.node_store:
                del self.node_store[node]

        memory_flush(gc_collect=True)

        return web.json_response({
            "type": "cacheCleared",
            "nodeId": nodeId
        })

    async def graph(self, request):
        graph = await request.json()
        # If graph has "type" and it's "tool", 
        # we might reject or do something else
        if graph.get("type") == "tool":
            return web.json_response({
                "error": "Global graph execution is not available for tool mode."
            }, status=400)

        # else do your normal workflow logic
        await self.queue.put(graph)
        return web.json_response({
            "type": "graphQueued",
            "sid": graph["sid"]
        })

    async def node_execute(self, request):
        data = await request.json()
        await self.queue.put(data)
        return web.json_response({
            "type": "nodeQueued",
            "sid": data["sid"],
        })

    async def node_execute_single(self, data):
        sid = data["sid"]
        module = data["module"]
        action = data["action"]
        kwargs = data["kwargs"]
        node = data["node"]

        if module not in self.module_map:
            raise ValueError("Invalid module")
        if action not in self.module_map[module]:
            raise ValueError("Invalid action")

        if module.endswith(".custom"):
            module = import_module(f"custom.{module.replace('.custom', '')}.{module.replace('.custom', '')}")
        else:
            module = import_module(f"modules.{module}.{module}")
        action = getattr(module, action)

        if not callable(action):
            raise ValueError("Action is not callable")

        node = action()
        node._client_id = sid

        result = {}

        try:
            result = await self.event_loop.run_in_executor(None, lambda: node(**kwargs))
        except Exception as e:
            logger.error(f"Error executing node {module}.{action}: {str(e)}")
            raise e

        await self.client_queue.put({
            "client_id": sid,
            "data": {
                "type": "single_executed",
                "nodeId": node,
                "module": module,
                "action": action,
                "result": result,
            }
        })

    async def graph_execution(self, graph):
        #graph = await request.json()
        sid = graph["sid"]
        nodes = graph["nodes"]
        paths = graph["paths"]

        randomized_fields = {}
        for path in paths:
            for node in path:
                module_name = nodes[node]["module"]
                action_name = nodes[node]["action"]
                logger.debug(f"Executing node {module_name}.{action_name}")

                params = nodes[node]["params"]
                ui_fields = {}
                args = {}
                for p in params:
                    source_id = params[p].get("sourceId")
                    source_key = params[p].get("sourceKey")

                    if "display" in params[p] and params[p]["display"] == "ui":
                        # store ui fields that need to be sent back to the client
                        if params[p]["type"] == "image":
                            ui_fields[p] = { "source": source_key, "type": params[p]["type"] }
                        elif params[p]["type"] == "3d":
                            ui_fields[p] = { "source": source_key, "type": params[p]["type"] }
                    else:
                        # handle list values (spawn input fields)
                        # if p ends with [d+], it means that the field is part of a list
                        if source_id and re.match(r".*\[\d+\]$", p):
                            spawn_key = re.sub(r"\[\d+\]$", "", p)
                            if not args.get(spawn_key):
                                args[spawn_key] = []
                            elif not isinstance(args[spawn_key], list):
                                args[spawn_key] = [args[spawn_key]]

                            args[spawn_key].append(self.node_store[source_id].output[source_key])
                        else:
                            # if there is a source id, it means that the value comes from a pipeline,
                            # so we follow the connection to the source node and get the associated value
                            # Otherwise we use the value in the params
                            args[p] = self.node_store[source_id].output[source_key] if source_id else params[p].get("value")

                # check if there is a field with the name __random__<param>
                # randomize the field unless it has been already randomized
                for key in args:
                    if key.startswith('__random__') and args[key] is True:
                        if node not in randomized_fields:
                            randomized_fields[node] = []
                        if key in randomized_fields[node]:
                            continue
                        randomized_fields[node].append(key)

                        random_field = key.split('__random__')[1]
                        args[random_field] = random.randint(0, (1<<53)-1) # TODO: allow min/max values
                        #self.node_store[node].params[random_field] = args[random_field]
                        params[random_field]["value"] = args[random_field]
                        await self.client_queue.put({
                            "client_id": sid,
                            "data": {
                                "type": "updateValues",
                                "nodeId": node,
                                "key": random_field,
                                "value": args[random_field]
                            }
                        })

                if module_name not in self.module_map:
                    raise ValueError("Invalid module")
                if action_name not in self.module_map[module_name]:
                    raise ValueError("Invalid action")

                # import the module and get the action
                if module_name.endswith(".custom"):
                    module = import_module(f"custom.{module_name.replace('.custom', '')}.{module_name.replace('.custom', '')}")
                else:
                    module = import_module(f"modules.{module_name}.{module_name}")
                action = getattr(module, action_name)

                # if the node is not in the node store, initialize it
                if node not in self.node_store:
                    self.node_store[node] = action(node)

                self.node_store[node]._client_id = sid

                if not callable(self.node_store[node]):
                    raise TypeError(f"The class `{module_name}.{action_name}` is not callable. Ensure that the class has a __call__ method or extend it from `NodeBase`.")

                # initialize the progress bar
                await self.client_queue.put({
                    "client_id": sid,
                    "data": {
                        "type": "progress",
                        "nodeId": node,
                        "progress": -1
                    }
                })

                try:
                    await self.event_loop.run_in_executor(None, lambda: self.node_store[node](**args))
                except Exception as e:
                    logger.error(f"Error executing node {module_name}.{action_name}: {str(e)}")
                    raise e

                execution_time = self.node_store[node]._execution_time if hasattr(self.node_store[node], '_execution_time') else 0

                await self.client_queue.put({
                    "client_id": sid,
                    "data": {
                        "type": "executed",
                        "nodeId": node,
                        "time": f"{execution_time:.2f}",
                        #"updateValues": updateValues
                        #"memory": f"{memory_usage/1024**3:.2f}"
                    }
                })

                logger.debug(f"Node {module_name}.{action_name} executed in {execution_time:.3f}s")

                for key in ui_fields:
                    source = ui_fields[key]["source"]
                    source_value = self.node_store[node].output[source]
                    length = len(source_value) if isinstance(source_value, list) else 1
                    format = 'webp' if ui_fields[key]["type"] == 'image' else 'glb'
                    data = []
                    for i in range(length):
                        if length > 1:
                            scale = 0.5 if source_value[i].width > 1024 or source_value[i].height > 1024 else 1
                        else:
                            scale = 0.5 if source_value[i].width > 2048 or source_value[i].height > 2048 else 1
                        data.append({
                            "url": f"/view/{format}/{node}/{source}/{i}?scale={scale}&t={time.time()}",
                            "width": source_value[i].width,
                            "height": source_value[i].height
                        })

                    await self.client_queue.put({
                        "client_id": sid,
                        "data": {
                            "type": ui_fields[key]["type"],
                            "key": key,
                            "nodeId": node,
                            "data": data
                            #"data": self.to_base64(ui_fields[key]["type"], value)
                        }
                    })

                await asyncio.sleep(0)

        # if updateValues:
        #     await self.client_queue.put({
        #         "client_id": sid,
        #         "data": {
        #             "type": "updateValues",
        #             "values": updateValues
        #         }
        #     })

    """
    WebSocket API
    """

    async def websocket_handler(self, request):
        ws = web.WebSocketResponse()
        await ws.prepare(request)
        sid = request.query.get("sid")
        logger.info(f"WebSocket connection with sid {sid}")
        if sid:
            if sid in self.ws_clients:
                del self.ws_clients[sid]
        else:
            # if the client does not provide a session id, we create one for them one
            sid = nanoid.generate(size=10)

        self.ws_clients[sid] = ws
        await ws.send_json({"type": "welcome", "sid": sid})

        async for msg in ws:
            if msg.type == WSMsgType.TEXT:
                data = json.loads(msg.data)

                try:
                    if data["type"] == "ping":
                        await ws.send_json({"type": "pong"})
                    elif data["type"] == "close":
                        await ws.close()
                        break
                        """
                    elif data["type"] == "module":
                        module_name = data["module"]
                        action_name = data["action"]
                        params = data["data"] if "data" in data else {}

                        if module_name not in self.module_map or action_name not in self.module_map[module_name]:
                            raise ValueError("Invalid module or action")

                        module = import_module(f"modules.{module_name}.{module_name}")
                        action = getattr(module, action_name)
                        result = await action(**params)
                        await ws.send_json({"type": "result", "result": result})

                    elif data["type"] == "graph":
                        graph = data["graph"]
                        for node in graph["nodes"]:
                            module_name = node["module"]
                            action_name = node["action"]
                            params = node["params"]
                            module = import_module(f"modules.{module_name}.{module_name}")
                            action = getattr(module, action_name)
                            result = await action(**params)
                            await ws.send_json({"type": "result", "result": result})
                        """
                    else:
                        raise ValueError("Invalid message type")

                #except KeyError as e:
                #    await ws.send_json({"type": "error", "message": f"Missing required field: {str(e)}"})
                #except ValueError as e:
                #    await ws.send_json({"type": "error", "message": str(e)})
                except Exception as e:
                    logger.error(f"Unexpected error: {str(e)}")
                    await ws.send_json({"type": "error", "message": "An unexpected error occurred"})

            elif msg.type == WSMsgType.ERROR:
                logger.error(f'WebSocket connection closed with exception {ws.exception()}')

        del self.ws_clients[sid]
        logger.info(f'WebSocket connection {sid} closed')

        return ws

    async def broadcast(self, message, client_id=None):
        if client_id:
            if client_id not in self.ws_clients:
                return
            ws_clients = [client_id] if not isinstance(client_id, list) else client_id
        else:
            ws_clients = self.ws_clients

        for client in ws_clients:
            await self.ws_clients[client].send_json(message)


    """
    Helper functions
    """
    def to_base64(self, type, value):
        if type == "image":
            img_byte_arr = io.BytesIO()
            value.save(img_byte_arr, format='WEBP', quality=100)
            img_byte_arr = img_byte_arr.getvalue()
            return base64.b64encode(img_byte_arr).decode('utf-8')
        elif type == "3d":
            glb_byte_arr = io.BytesIO()
            glb_byte_arr.write(value)
            glb_byte_arr = glb_byte_arr.getvalue()
            return base64.b64encode(glb_byte_arr).decode('utf-8')

    def slugify(self, text):
        return re.sub(r'[^\w\s-]', '', text).strip().replace(' ', '-')

from modules import MODULE_MAP
from config import config

web_server = WebServer(MODULE_MAP, **config.server)


================================================================================
FILE: ./modules/__init__.py
================================================================================

from os import scandir
from importlib import import_module
import logging
logger = logging.getLogger('mellon')

logger.debug("Loading modules...")

MODULE_MAP = {}

for m in scandir("modules"):
    if m.is_dir() and not m.name.startswith(("__", ".")) and m.name not in globals():
        MODULE_MAP[m.name] = import_module(f"modules.{m.name}").MODULE_MAP
        logger.debug(f"Loaded module: {m.name}")

logger.debug("Loading custom modules...")

for m in scandir("custom"):
    if m.is_dir() and not m.name.startswith(("__", ".")) and m.name not in globals():
        MODULE_MAP[f"{m.name}.custom"] = import_module(f"custom.{m.name}").MODULE_MAP
        logger.debug(f"Loaded custom module: {m.name}")


# Add random helper fields
def create_random_field(param):
    return {
        f"__random__{param}": {
            'label': 'Enable Random Seed',
            'type': 'boolean',
            'display': 'iconToggle',
            'default': False,
            'group': f"random-{param}",
            'icon': 'random',
            'onChange': {'action': 'disable', 'target': { True: [param], False: [] }}
        }
    }

for module, actions in MODULE_MAP.items():
    for action, data in actions.items():
        if 'params' not in data:
            continue
            
        random_params = {
            param: field for param, field in data['params'].items()
            if 'display' in field and field['display'] == 'random'
        }
        
        for param, field in random_params.items():
            field['group'] = f"random-{param}"
            field['display'] = "number"

            # if 'onAfterNodeExecute' not in data:
            #     data['onAfterNodeExecute'] = []
            # elif not isinstance(data['onAfterNodeExecute'], list):
            #     data['onAfterNodeExecute'] = [data['onAfterNodeExecute']]

            # data['onAfterNodeExecute'].append({
            #     'action': 'updateValue',
            #     'target': param
            # })

            data['params'].update(create_random_field(param))


================================================================================
FILE: ./modules/StableDiffusionXL/StableDiffusionXL.py
================================================================================

from diffusers import UNet2DConditionModel, AutoencoderKL, StableDiffusionXLPipeline, StableDiffusionXLImg2ImgPipeline
from transformers import CLIPTextModel, CLIPTextModelWithProjection, CLIPTokenizer
from mellon.NodeBase import NodeBase
from config import config
from utils.hf_utils import is_local_files_only
from utils.diffusers_utils import get_clip_prompt_embeds
import torch
from modules.VAE.VAE import VAEEncode
import random
import logging
logger = logging.getLogger('mellon')

HF_TOKEN = config.hf['token']

class SDXLPipelineLoader(NodeBase):
    def execute(self, model_id, dtype, variant, unet, text_encoders, vae):
        kwargs = {}

        if unet:
            kwargs['unet'] = unet

        if vae:
            kwargs['vae'] = vae

        model_id = model_id or 'stabilityai/stable-diffusion-xl-base-1.0'

        pipeline = StableDiffusionXLPipeline.from_pretrained(
            model_id,
            **kwargs,
            torch_dtype=dtype,
            token=HF_TOKEN,
            local_files_only=is_local_files_only(model_id),
            variant=variant,
            add_watermarker=False,
        )

        if text_encoders:
            pipeline.text_encoder = text_encoders['text_encoder'] if pipeline.text_encoder is not None else None
            pipeline.text_encoder_2 = text_encoders['text_encoder_2']
            pipeline.tokenizer = text_encoders['tokenizer'] if pipeline.tokenizer is not None else None
            pipeline.tokenizer_2 = text_encoders['tokenizer_2']
        
        if not hasattr(pipeline.unet, '_mm_id'):
            pipeline.unet._mm_id = self.mm_add(pipeline.unet, priority=3)

        # the refiner doesn't have the first text encoder
        if pipeline.text_encoder and not hasattr(pipeline.text_encoder, '_mm_id'):
            pipeline.text_encoder._mm_id = self.mm_add(pipeline.text_encoder, priority=1)

        if not hasattr(pipeline.text_encoder_2, '_mm_id'):
            pipeline.text_encoder_2._mm_id = self.mm_add(pipeline.text_encoder_2, priority=1)

        if not hasattr(pipeline.vae, '_mm_id'):
            pipeline.vae._mm_id = self.mm_add(pipeline.vae, priority=2)

        return {
            'pipeline': pipeline,
            'unet_out': pipeline.unet,
            'vae_out': pipeline.vae,
            'text_encoders_out': {
                'text_encoder': pipeline.text_encoder,
                'text_encoder_2': pipeline.text_encoder_2,
                'tokenizer': pipeline.tokenizer,
                'tokenizer_2': pipeline.tokenizer_2,
            },
        }

class SDXLUnetLoader(NodeBase):
    def execute(self, model_id, dtype, variant):
        model_id = model_id or 'stabilityai/stable-diffusion-xl-base-1.0'

        local_files_only = is_local_files_only(model_id)

        if not variant:
            variant = None

        unet = UNet2DConditionModel.from_pretrained(
            model_id,
            torch_dtype=dtype,
            subfolder="unet",
            token=HF_TOKEN,
            local_files_only=local_files_only,
            variant=variant,
        )

        #if not is_file_cached(model_id, 'model_index.json'):
        #    from huggingface_hub import hf_hub_download
        #    hf_hub_download(repo_id=model_id, filename='model_index.json', token=HF_TOKEN)

        unet._mm_id = self.mm_add(unet, priority=3)

        return { 'model': unet }

class SDXLTextEncodersLoader(NodeBase):
    def execute(self, model_id, dtype):
        model_id = model_id or 'stabilityai/stable-diffusion-xl-base-1.0'

        model_cfg = {
            'torch_dtype': dtype,
            'token': HF_TOKEN,
            'local_files_only': is_local_files_only(model_id),
        }

        text_encoder = CLIPTextModel.from_pretrained(model_id, subfolder="text_encoder", **model_cfg)
        tokenizer = CLIPTokenizer.from_pretrained(model_id, subfolder="tokenizer", **model_cfg)
        text_encoder_2 = CLIPTextModelWithProjection.from_pretrained(model_id, subfolder="text_encoder_2", **model_cfg)
        tokenizer_2 = CLIPTokenizer.from_pretrained(model_id, subfolder="tokenizer_2", **model_cfg)
        
        text_encoder._mm_id = self.mm_add(text_encoder, priority=1)
        text_encoder_2._mm_id = self.mm_add(text_encoder_2, priority=1)

        return { 'model': {
            'text_encoder': text_encoder,
            'tokenizer': tokenizer,
            'text_encoder_2': text_encoder_2,
            'tokenizer_2': tokenizer_2,
        }}      


class SDXLSinglePromptEncoder(NodeBase):
    def execute(self, text_encoders, prompt, prompt_2, clip_skip, noise, prompt_scale, prompt_scale_2):
        if not isinstance(text_encoders, dict):
            text_encoders = {
                'text_encoder': text_encoders.text_encoder,
                'text_encoder_2': text_encoders.text_encoder_2,
                'tokenizer': text_encoders.tokenizer,
                'tokenizer_2': text_encoders.tokenizer_2,
            }

        prompt_embed, pooled_prompt_embed = self.encode_prompt(text_encoders, prompt, prompt_2, clip_skip, noise, prompt_scale, prompt_scale_2)

        return { 'embeds': {
            'prompt_embeds': prompt_embed,
            'pooled_prompt_embeds': pooled_prompt_embed,
        }}
    
    def encode_prompt(self, text_encoders, device, prompt="", prompt_2="", clip_skip=0, noise=0.0, prompt_scale=1.0, prompt_scale_2=1.0):
        prompt = prompt or ""
        prompt_2 = prompt_2 or prompt

        prompt = [prompt] if isinstance(prompt, str) else prompt
        prompt_2 = [prompt_2] if isinstance(prompt_2, str) else prompt_2

        concat_embeds = []
        if text_encoders['text_encoder']:
            text_encoders['text_encoder'] = self.mm_load(text_encoders['text_encoder'], device)
            prompt_embeds, _ = self.mm_inference(
                lambda: get_clip_prompt_embeds(prompt, text_encoders['tokenizer'], text_encoders['text_encoder'], clip_skip=clip_skip, noise=noise, scale=prompt_scale),
                device,
                exclude=text_encoders['text_encoder']
            )
            concat_embeds.append(prompt_embeds)

        text_encoders['text_encoder_2'] = self.mm_load(text_encoders['text_encoder_2'], device)
        prompt_embeds_2, pooled_prompt_embeds_2 = self.mm_inference(
            lambda: get_clip_prompt_embeds(prompt_2, text_encoders['tokenizer_2'], text_encoders['text_encoder_2'], clip_skip=clip_skip, noise=noise, scale=prompt_scale_2),
            device,
            exclude=text_encoders['text_encoder_2']
        )
        concat_embeds.append(prompt_embeds_2)

        prompt_embeds = torch.cat(concat_embeds, dim=-1).to('cpu')
        #prompt_embeds = torch.cat([prompt_embeds, prompt_embeds_2], dim=-1).to('cpu')
        pooled_prompt_embeds = pooled_prompt_embeds_2.to('cpu')

        return (prompt_embeds, pooled_prompt_embeds)


class SDXLPromptsEncoder(NodeBase):
    def execute(self, text_encoders, prompt, prompt_2, negative_prompt, negative_prompt_2, clip_skip, noise_positive, noise_negative, device):
        if not isinstance(text_encoders, dict):
            text_encoders = {
                'text_encoder': text_encoders.text_encoder,
                'text_encoder_2': text_encoders.text_encoder_2,
                'tokenizer': text_encoders.tokenizer,
                'tokenizer_2': text_encoders.tokenizer_2,
            }

        clip_skip = clip_skip if clip_skip > 0 else None
        prompt = prompt or ""
        prompt_2 = prompt_2 or prompt
        negative_prompt = negative_prompt or ""
        negative_prompt_2 = negative_prompt_2 or negative_prompt

        def encode(positive_prompt, negative_prompt, text_encoder, tokenizer, clip_skip=None, noise_positive=0.0, noise_negative=0.0):
            prompt_embeds, pooled_prompt_embeds = get_clip_prompt_embeds(positive_prompt, tokenizer, text_encoder, clip_skip=clip_skip, noise=noise_positive)
            negative_prompt_embeds, negative_pooled_prompt_embeds = get_clip_prompt_embeds(negative_prompt, tokenizer, text_encoder, clip_skip=clip_skip, noise=noise_negative)
            return (prompt_embeds, negative_prompt_embeds, pooled_prompt_embeds, negative_pooled_prompt_embeds)

        # Encode the prompts with the first text encoder
        concat_embeds = []
        concat_negative_embeds = []
        if text_encoders['text_encoder']:
            text_encoders['text_encoder'] = self.mm_load(text_encoders['text_encoder'], device)
            prompt_embeds, negative_prompt_embeds, _, _ = self.mm_inference(
                lambda: encode(prompt, negative_prompt, text_encoders['text_encoder'], text_encoders['tokenizer'], clip_skip=clip_skip, noise_positive=noise_positive, noise_negative=noise_negative),
                device,
                exclude=text_encoders['text_encoder']
            )
            concat_embeds.append(prompt_embeds)
            concat_negative_embeds.append(negative_prompt_embeds)

        # Encode the prompts with the second text encoder
        text_encoders['text_encoder_2'] = self.mm_load(text_encoders['text_encoder_2'], device)
        prompt_embeds_2, negative_prompt_embeds_2, pooled_prompt_embeds_2, negative_pooled_prompt_embeds_2 = self.mm_inference(
            lambda: encode(prompt_2, negative_prompt_2, text_encoders['text_encoder_2'], text_encoders['tokenizer_2'], clip_skip=clip_skip, noise_positive=noise_positive, noise_negative=noise_negative),
            device,
            exclude=text_encoders['text_encoder_2']
        )
        concat_embeds.append(prompt_embeds_2)
        concat_negative_embeds.append(negative_prompt_embeds_2)

        # Concatenate both prompt embeddings
        prompt_embeds = torch.cat(concat_embeds, dim=-1).to('cpu')
        negative_prompt_embeds = torch.cat(concat_negative_embeds, dim=-1).to('cpu')
        pooled_prompt_embeds = pooled_prompt_embeds_2.to('cpu')
        negative_pooled_prompt_embeds = negative_pooled_prompt_embeds_2.to('cpu')
        del prompt_embeds_2, negative_prompt_embeds_2, pooled_prompt_embeds_2, negative_pooled_prompt_embeds_2, concat_embeds, concat_negative_embeds

        # Ensure both prompt embeddings have the same length
        if prompt_embeds.shape[1] > negative_prompt_embeds.shape[1]:
            negative_prompt_embeds = torch.nn.functional.pad(negative_prompt_embeds, (0, 0, 0, prompt_embeds.shape[1] - negative_prompt_embeds.shape[1]))
        elif prompt_embeds.shape[1] < negative_prompt_embeds.shape[1]:
            prompt_embeds = torch.nn.functional.pad(prompt_embeds, (0, 0, 0, negative_prompt_embeds.shape[1] - prompt_embeds.shape[1]))

        return { 'embeds': {
            'prompt_embeds': prompt_embeds,
            'pooled_prompt_embeds': pooled_prompt_embeds,
            'negative_prompt_embeds': negative_prompt_embeds,
            'negative_pooled_prompt_embeds': negative_pooled_prompt_embeds,
        }}

class SDXLSampler(NodeBase):
    def execute(self,
                pipeline,
                prompt,
                width,
                height,
                seed,
                steps,
                cfg,
                num_images,
                scheduler,
                latents_in,
                denoise_range,
                device,
                sync_latents,
        ):
        #generator = [torch.Generator(device=device).manual_seed(seed + i) for i in range(num_images)]
        generator = []

        random_state = random.getstate()
        random.seed(seed)
        for _ in range(num_images):
            generator.append(torch.Generator(device=device).manual_seed(seed))
            # there is a very slight chance that the seed is the same as the previous one, I don't think it's a big deal
            seed = random.randint(0, (1<<53)-1)
        random.setstate(random_state)

        denoise_range_start = denoise_range[0] if denoise_range[0] > 0 else None
        denoise_range_end = denoise_range[1] if denoise_range[1] < 1 else None

        # 1. Select the scheduler
        sampling_scheduler = pipeline.scheduler
        if ( pipeline.scheduler.__class__.__name__ != scheduler ):
            scheduler_cls = getattr(__import__('diffusers', fromlist=[scheduler]), scheduler)
            sampling_scheduler = scheduler_cls.from_config(pipeline.scheduler.config)

        # 2. Prepare the prompts
        positive = { 'prompt_embeds': prompt['prompt_embeds'], 'pooled_prompt_embeds': prompt['pooled_prompt_embeds'] }
        negative = None

        if 'negative_prompt_embeds' in prompt:
            negative = { 'prompt_embeds': prompt['negative_prompt_embeds'], 'pooled_prompt_embeds': prompt['negative_pooled_prompt_embeds'] }

        if not negative:
            negative = { 'prompt_embeds': torch.zeros_like(positive['prompt_embeds']), 'pooled_prompt_embeds': torch.zeros_like(positive['pooled_prompt_embeds']) }
        
        # Ensure both prompt embeddings have the same length, the length might be different because our custom text encoder supports long prompts
        if positive['prompt_embeds'].shape[1] > negative['prompt_embeds'].shape[1]:
            negative['prompt_embeds'] = torch.nn.functional.pad(negative['prompt_embeds'], (0, 0, 0, positive['prompt_embeds'].shape[1] - negative['prompt_embeds'].shape[1]))
        elif positive['prompt_embeds'].shape[1] < negative['prompt_embeds'].shape[1]:
            positive['prompt_embeds'] = torch.nn.functional.pad(positive['prompt_embeds'], (0, 0, 0, negative['prompt_embeds'].shape[1] - positive['prompt_embeds'].shape[1]))

        # if the pipeline doesn't have the first text encoder, this is likely the refiner
        # so we need only the embeddings for the second text encoder
        if pipeline.text_encoder is None and positive['prompt_embeds'].shape[-1] > 1280:
            positive['prompt_embeds'] = positive['prompt_embeds'][:, :, 768:]
            negative['prompt_embeds'] = negative['prompt_embeds'][:, :, 768:]

        # 3. Latents or Images input
        denoising_start = None
        denoising_end = denoise_range_end
        image_latents = None
        strength = None
        if latents_in is not None:
            if isinstance(latents_in, torch.Tensor):
                image_latents = latents_in.clone()
                if hasattr(latents_in, '_denoising_end'):
                    denoising_start = latents_in._denoising_end
                    steps = latents_in._num_inference_steps
                else:
                    strength = 1 - (denoise_range_start or 0)
            else:
                # since we are sampling without a VAE, we need to encode the input image before passing it to the pipeline
                image_latents = VAEEncode()(model=pipeline.vae, images=latents_in, divisible_by=16, device=device)['latents']
                strength = 1 - (denoise_range_start or 0)

        if denoising_start is not None and denoising_end is not None:
            denoising_end = max(denoising_end, denoising_start + 0.01)
            logger.warning(f"Denoise range value error. Denoising end increased to: {denoising_end}")

        # 4. Run the denoise loop
        def denoise():
            # We don't need the VAE for sampling, but we need to pass something to the pipeline
            dummy_vae = AutoencoderKL(
                in_channels=3,
                out_channels=3,
                down_block_types=["DownEncoderBlock2D", "DownEncoderBlock2D", "DownEncoderBlock2D", "DownEncoderBlock2D"],
                up_block_types=["UpDecoderBlock2D", "UpDecoderBlock2D", "UpDecoderBlock2D", "UpDecoderBlock2D"],
                block_out_channels=[128, 256, 512, 512],
                layers_per_block=2,
                latent_channels=4,
            )

            sampling_config = {
                'generator': generator,
                'prompt_embeds': positive['prompt_embeds'].to(device, dtype=pipeline.unet.dtype),
                'pooled_prompt_embeds': positive['pooled_prompt_embeds'].to(device, dtype=pipeline.unet.dtype),
                'negative_prompt_embeds': negative['prompt_embeds'].to(device, dtype=pipeline.unet.dtype),
                'negative_pooled_prompt_embeds': negative['pooled_prompt_embeds'].to(device, dtype=pipeline.unet.dtype),
                'width': width,
                'height': height,
                'guidance_scale': cfg,
                'num_inference_steps': steps,
                'output_type': "latent",
                'callback_on_step_end': self.pipe_callback,
                'denoising_start': denoising_start,
                'denoising_end': denoising_end,
                'num_images_per_prompt': num_images,
            }

            if image_latents is not None:
                sampling_config['width'] = None
                sampling_config['height'] = None
                sampling_config['image'] = image_latents.to(device)
                if strength:
                    sampling_config['strength'] = strength
                    #sampling_config['num_inference_steps'] = round(steps / strength)
                PipelineCls = StableDiffusionXLImg2ImgPipeline
                #else:
                #    sampling_config['latents'] = image_latents.to(device)
                #    PipelineCls = StableDiffusionXLPipeline
                #sampling_config['strength'] = 1 - (denoising_start or 0)
                #sampling_config['denoising_start'] = None
                #sampling_config['denoising_end'] = None
                #sampling_config['num_inference_steps'] = round(steps / sampling_config['strength'])
            else:
                PipelineCls = StableDiffusionXLPipeline

            sampling_pipe = PipelineCls.from_pretrained(
                pipeline.config._name_or_path,
                unet=pipeline.unet,
                scheduler=sampling_scheduler,
                vae=dummy_vae.to(device),
                text_encoder=None,
                text_encoder_2=None,
                tokenizer=None,
                tokenizer_2=None,
                local_files_only=True,
                add_watermarker=False,
            )
            sampling_pipe.watermark = None

            latents = sampling_pipe(**sampling_config).images
            del sampling_pipe, sampling_config, dummy_vae
            return latents

        self.mm_load(pipeline.unet, device)
        latents = self.mm_inference(
            lambda: denoise(),
            device,
            exclude=pipeline.unet
        )
        latents = latents.to('cpu')

        if denoising_end:
            latents._denoising_end = denoising_end
            latents._num_inference_steps = steps

        return { 'latents': latents, 'pipeline_out': pipeline }


================================================================================
FILE: ./modules/StableDiffusionXL/__init__.py
================================================================================

from utils.hf_utils import list_local_models
from utils.torch_utils import device_list, default_device, str_to_dtype

MODULE_MAP = {
    'SDXLPipelineLoader': {
        'label': 'SDXL Pipeline Loader',
        'description': 'Load the SDXL Pipeline',
        'category': 'loaders',
        'params': {
            'unet_out': {
                'label': 'UNet',
                'type': 'UNet2DConditionModel',
                'display': 'output',
            },
            'text_encoders_out': {
                'label': 'Text Encoders',
                'type': 'SDXLTextEncoders',
                'display': 'output',
            },
            'vae_out': {
                'label': 'VAE',
                'type': 'VAE',
                'display': 'output',
            },
            'pipeline': {
                'label': 'SDXL Pipeline',
                'type': 'pipeline',
                'display': 'output',
            },
            'model_id': {
                'label': 'Model ID',
                'type': 'string',
                'options': list_local_models(filters={"_class_name": r"XLPipeline$"}),
                'display': 'autocomplete',
                'no_validation': True,
                'default': 'stabilityai/stable-diffusion-xl-base-1.0',
            },
            'dtype': {
                'label': 'dtype',
                'options': ['auto', 'float32', 'bfloat16','float16'],
                'default': 'bfloat16',
                'postProcess': str_to_dtype,
            },
            'variant': {
                'label': 'Variant',
                'type': 'string',
                'options': ['', 'fp16', 'emaonly'],
                'default': 'fp16',
                'display': 'autocomplete',
                'no_validation': True,
                'postProcess': lambda x, _: x or None,
            },
            'unet': {
                'label': 'UNet',
                'type': 'UNet2DConditionModel',
                'display': 'input',
            },
            'text_encoders': {
                'label': 'Text Encoders',
                'type': 'SDXLTextEncoders',
                'display': 'input',
            },
            'vae': {
                'label': 'VAE',
                'type': 'VAE',
                'display': 'input',
            },
        },
    },

    'SDXLPromptsEncoder': {
        'label': 'SDXL Prompts Encoder',
        'category': 'text-encoders',
        'params': {
            'text_encoders': {
                'label': 'SDXL Encoders | Pipeline',
                'display': 'input',
                'type': ['pipeline', 'SDXLTextEncoders'],
            },
            'embeds': {
                'label': 'Embeddings',
                'display': 'output',
                'type': 'SDXLEmbeddings',
            },
            'prompt': {
                'label': 'Prompt',
                'type': 'string',
                'display': 'textarea',
            },
            'negative_prompt': {
                'label': 'Negative Prompt',
                'type': 'string',
                'display': 'textarea',
            },
            'prompt_2': {
                'label': 'Prompt CLIP G',
                'type': 'string',
                'display': 'textarea',
                'group': { 'key': 'extra_prompts', 'label': 'Extra Prompts', 'display': 'collapse' },
            },
            'negative_prompt_2': {
                'label': 'Negative Prompt CLIP G',
                'type': 'string',
                'display': 'textarea',
                'group': 'extra_prompts',
            },
            'clip_skip': {
                'label': 'Clip Skip',
                'type': 'int',
                'default': 0,
                'min': 0,
                'max': 10,
            },
            'noise_positive': {
                'label': 'Positive Noise',
                'type': 'float',
                'default': 0.0,
                'display': 'slider',
                'min': 0,
                'max': 1,
                'step': 0.05,
                'group': { 'key': 'noise', 'label': 'Noise', 'display': 'collapse' },
            },
            'noise_negative': {
                'label': 'Negative Noise',
                'type': 'float',
                'default': 0.0,
                'display': 'slider',
                'min': 0,
                'max': 1,
                'step': 0.05,
                'group': 'noise',
            },
            'device': {
                'label': 'Device',
                'type': 'string',
                'options': device_list,
                'default': default_device,
            },
        },
    },

    'SDXLSampler': {
        'label': 'SDXL Sampler',
        'category': 'samplers',
        'style': {
            'maxWidth': '360px',
        },
        'params': {
            'pipeline': {
                'label': 'Pipeline',
                'display': 'input',
                'type': 'pipeline',
            },
            'prompt': {
                'label': 'Embeddings',
                'display': 'input',
                'type': ['SDXLEmbeddings', 'embeddings'],
            },
            'pipeline_out': {
                'label': 'Pipeline',
                'display': 'output',
                'type': 'pipeline',
            },
            'latents': {
                'label': 'Latents',
                'type': 'latent',
                'display': 'output',
            },
            'width': {
                'label': 'Width',
                'type': 'int',
                'display': 'text',
                'default': 1024,
                'min': 8,
                'max': 8192,
                'group': 'dimensions',
            },
            'height': {
                'label': 'Height',
                'type': 'int',
                'display': 'text',
                'default': 1024,
                'min': 8,
                'max': 8192,
                'group': 'dimensions',
            },
            'resolution_picker': {
                'label': 'Resolution',
                'display': 'ui',
                'type': 'dropdownIcon',
                'options': [
                    { 'label': ' 720×1280 (9:16)','value': [720, 1280] },
                    { 'label': ' 768×1344 (0.57)','value': [768, 1344] },
                    { 'label': ' 768×1280 (3:5)', 'value': [768, 1280] },
                    { 'label': ' 832×1152 (3:4)', 'value': [832, 1152] },
                    { 'label': '1024×1024 (1:1)', 'value': [1024, 1024] },
                    { 'label': ' 1152×832 (4:3)', 'value': [1152, 832] },
                    { 'label': ' 1280×768 (5:3)', 'value': [1280, 768] },
                    { 'label': ' 1280×720 (16:9)','value': [1280, 720] },
                    { 'label': ' 1344×768 (1.75)','value': [1344, 768] },
                    { 'label': '---','value': None }, # divider
                    { 'label': ' 512×2048 (0.25)', 'value': [512, 2048] },
                    { 'label': ' 512×1984 (0.26)', 'value': [512, 1984] },
                    { 'label': ' 512×1920 (0.27)', 'value': [512, 1920] },
                    { 'label': ' 512×1856 (0.28)', 'value': [512, 1856] },
                    { 'label': ' 576×1792 (0.32)', 'value': [576, 1792] },
                    { 'label': ' 576×1728 (0.33)', 'value': [576, 1728] },
                    { 'label': ' 576×1664 (0.35)', 'value': [576, 1664] },
                    { 'label': ' 640×1600 (0.4)',  'value': [640, 1600] },
                    { 'label': ' 640×1536 (0.42)', 'value': [640, 1536] },
                    { 'label': ' 704×1472 (0.48)', 'value': [704, 1472] },
                    { 'label': ' 704×1408 (1:2)',  'value': [704, 1408] },
                    { 'label': ' 704×1344 (0.52)', 'value': [704, 1344] },
                    { 'label': ' 832×1216 (0.68)', 'value': [832, 1216] },
                    { 'label': ' 896×1152 (0.78)', 'value': [896, 1152] },
                    { 'label': ' 896×1088 (0.82)', 'value': [896, 1088] },
                    { 'label': ' 960×1088 (0.88)', 'value': [960, 1088] },
                    { 'label': ' 960×1024 (0.94)', 'value': [960, 1024] },
                    { 'label': ' 1024×960 (1.07)', 'value': [1024, 960] },
                    { 'label': ' 1088×960 (1.13)', 'value': [1088, 960] },
                    { 'label': ' 1088×896 (1.21)', 'value': [1088, 896] },
                    { 'label': ' 1152×896 (1.29)', 'value': [1152, 896] },
                    { 'label': ' 1216×832 (1.46)', 'value': [1216, 832] },
                    { 'label': ' 1408×704 (2.0)',  'value': [1408, 704] },
                    { 'label': ' 1472×704 (2.09)', 'value': [1472, 704] },
                    { 'label': ' 1536×640 (2.4)',  'value': [1536, 640] },
                    { 'label': ' 1600×640 (2.5)',  'value': [1600, 640] },
                    { 'label': ' 1664×576 (2.89)', 'value': [1664, 576] },
                    { 'label': ' 1728×576 (3.0)',  'value': [1728, 576] },
                    { 'label': ' 1792×576 (3.11)', 'value': [1792, 576] },
                    { 'label': ' 1856×512 (3.62)', 'value': [1856, 512] },
                    { 'label': ' 1920×512 (3.75)', 'value': [1920, 512] },
                    { 'label': ' 1984×512 (3.88)', 'value': [1984, 512] },
                    { 'label': ' 2048×512 (4.0)',  'value': [2048, 512] },
                ],
                'onChange': { 'action': 'set', 'target': ['width', 'height'] },
                'group': 'dimensions',
            },
            'seed': {
                'label': 'Seed',
                'type': 'int',
                'default': 0,
                'min': 0,
                'display': 'random',
            },
            'steps': {
                'label': 'Steps',
                'type': 'int',
                'default': 25,
                'min': 1,
                'max': 1000,
            },
            'cfg': {
                'label': 'Guidance',
                'type': 'float',
                'default': 7,
                'min': 0,
                'max': 100,
            },
            'num_images': {
                'label': 'Num Images',
                'type': 'int',
                'default': 1,
                'min': 1,
                'max': 1000,
            },
            'scheduler': {
                'label': 'Scheduler',
                'display': 'select',
                'type': ['string', 'scheduler'],
                'options': {
                    'DDIMScheduler': 'DDIM',
                    'DDPMScheduler': 'DDPM',
                    'DEISMultistepScheduler': 'DEIS Multistep',
                    'DPMSolverSinglestepScheduler': 'DPMSolver Singlestep',
                    'DPMSolverMultistepScheduler': 'DPMSolver Multistep',
                    'DPMSolverSDEScheduler': 'DPMSolver SDE',
                    'EulerDiscreteScheduler': 'Euler Discrete',
                    'EulerAncestralDiscreteScheduler': 'Euler Ancestral',
                    'HeunDiscreteScheduler': 'Heun Discrete',
                    'KDPM2DiscreteScheduler': 'KDPM2 Discrete',
                    'KDPM2AncestralDiscreteScheduler': 'KDPM2 Ancestral',
                    'LMSDiscreteScheduler': 'LMS Discrete',
                    'PNDMScheduler': 'PNDM',
                    'UniPCMultistepScheduler': 'UniPC Multistep',
                },
                'default': 'EulerDiscreteScheduler',
            },
            'latents_in': {
                'label': 'Latents | Images',
                'display': 'input',
                'type': ['latent', 'image'],
                #'onChange': { 'action': 'disable', 'target': { 'connected': ['dimensions_group'], 'disconnected': ['strength'] } },
            },
            'sync_latents': {
                'label': 'Sync with previous latents',
                'type': 'boolean',
                'default': False,
                'onChange': { 'action': 'disable', 'target': { True: ['denoise_range', 'steps', 'dimensions_group'], False: [] } },
            },
            'denoise_range': {
                'label': 'Denoise Range',
                'type': 'float',
                'display': 'range',
                'default': [0, 1],
                'min': 0,
                'max': 1,
                'step': 0.01,
            },
            'device': {
                'label': 'Device',
                'type': 'string',
                'options': device_list,
                'default': default_device,
            },
        },
    },

    'SDXLUnetLoader': {
        'label': 'SDXL UNet Loader',
        'description': 'Load the UNet of an SDXL model',
        'category': 'loaders',
        'params': {
            'model': {
                'label': 'UNet',
                'type': 'UNet2DConditionModel',
                'display': 'output',
            },
            'model_id': {
                'label': 'Model ID',
                'type': 'string',
                'options': list_local_models(filters={"_class_name": r"XLPipeline$"}),
                'display': 'autocomplete',
                'no_validation': True,
                'default': 'stabilityai/stable-diffusion-xl-base-1.0',
            },
            'dtype': {
                'label': 'dtype',
                'options': ['auto', 'float32', 'bfloat16','float16'],
                'default': 'bfloat16',
                'postProcess': str_to_dtype,
            },
            'variant': {
                'label': 'Variant',
                'type': 'string',
                'options': ['', 'fp16', 'emaonly'],
                'default': '',
                'display': 'autocomplete',
                'no_validation': True,
            },
        },
    },

    'SDXLTextEncodersLoader': {
        'label': 'SDXL Text Encoders Loader',
        'description': 'Load the CLIP Text Encoders',
        'category': 'loaders',
        'params': {
            'model': {
                'label': 'SDXL Encoders',
                'display': 'output',
                'type': 'SDXLTextEncoders',
            },
            'model_id': {
                'label': 'Model ID',
                'type': 'string',
                'options': list_local_models(filters={"_class_name": r"XLPipeline$"}),
                'display': 'autocomplete',
                'no_validation': True,
                'default': 'stabilityai/stable-diffusion-xl-base-1.0',
            },
            'dtype': {
                'label': 'Dtype',
                'type': 'string',
                'options': ['auto', 'float32', 'float16', 'bfloat16'],
                'default': 'bfloat16',
            },
        },
    },
}



"""
    'SDXLSinglePromptEncoder': {
        'label': 'SDXL Single Prompt Encoder',
        'category': 'text-encoders',
        'params': {
            'text_encoders': {
                'label': 'SDXL Encoders | SDXL Pipeline',
                'display': 'input',
                'type': ['SDXLTextEncoders', 'pipeline'],
            },
            'embeds': {
                'label': 'Embeddings',
                'display': 'output',
                'type': 'SDXLEmbeddings',
            },
            'prompt': {
                'label': 'Prompt',
                'type': 'string',
                'display': 'textarea',
            },
            'prompt_2': {
                'label': 'Prompt CLIP G',
                'type': 'string',
                'display': 'textarea',
                'group': { 'key': 'extra_prompts', 'label': 'Extra Prompts', 'display': 'collapse' },
            },
            'clip_skip': {
                'label': 'Clip Skip',
                'type': 'int',
                'default': 0,
                'min': 0,
                'max': 10,
            },
            'noise': {
                'label': 'Add Noise',
                'type': 'float',
                'default': 0.0,
                'display': 'slider',
                'min': 0,
                'max': 1,
                'step': 0.05,
                'group': { 'key': 'noise', 'label': 'Noise', 'display': 'collapse' },
            },
            'prompt_scale': {
                'label': 'CLIP L',
                'type': 'float',
                'display': 'slider',
                'default': 1.0,
                'min': 0,
                'max': 2,
                'step': 0.05,
                'group': { 'key': 'prompts_scale', 'label': 'Prompts Scale', 'display': 'collapse' },
            },
            'prompt_scale_2': {
                'label': 'CLIP G',
                'type': 'float',
                'default': 1.0,
                'display': 'slider',
                'min': 0,
                'max': 2,
                'step': 0.05,
                'group': 'prompts_scale',
            },
            'device': {
                'label': 'Device',
                'type': 'string',
                'options': device_list,
                'default': default_device,
            },
        },
    },
"""

================================================================================
FILE: ./modules/Embeddings/Embeddings.py
================================================================================

from mellon.NodeBase import NodeBase
import torch

class CombineEmbeddings(NodeBase):
    def execute(self, embeddings_1, embeddings_2, ratio):
        out = {}
        if 'prompt_embeds' in embeddings_1 and 'prompt_embeds' in embeddings_2:
            embeds_1 = embeddings_1['prompt_embeds']
            embeds_2 = embeddings_2['prompt_embeds']
            out['prompt_embeds'] = embeds_1 * ratio + embeds_2 * (1 - ratio)
        
        if 'pooled_prompt_embeds' in embeddings_1 and 'pooled_prompt_embeds' in embeddings_2:
            pooled_embeds_1 = embeddings_1['pooled_prompt_embeds']
            pooled_embeds_2 = embeddings_2['pooled_prompt_embeds']
            out['pooled_prompt_embeds'] = pooled_embeds_1 * ratio + pooled_embeds_2 * (1 - ratio)
        
        return { 'embeddings_out': out }


================================================================================
FILE: ./modules/Embeddings/__init__.py
================================================================================


MODULE_MAP = {
    'CombineEmbeddings': {
        'label': 'Combine Embeddings',
        'category': 'text-encoders',
        'params': {
            'embeddings_1': {
                'label': 'Embeddings 1',
                'type': 'SD3Embeddings',
                'display': 'input',
            },
            'embeddings_2': {
                'label': 'Embeddings 2',
                'type': 'SD3Embeddings',
                'display': 'input',
            },
            'embeddings_out': {
                'label': 'Embeddings',
                'type': 'embeddings',
                'display': 'output',
            },
            'ratio': {
                'label': 'Ratio',
                'type': 'float',
                'default': 0.5,
                'step': 0.01,
                'display': 'slider',
                'min': 0,
                'max': 1,
            },
        },
    },
}


================================================================================
FILE: ./modules/StableDiffusion3/StableDiffusion3.py
================================================================================

import logging
logger = logging.getLogger('mellon')
import torch
from diffusers import SD3Transformer2DModel, AutoencoderKL, StableDiffusion3Pipeline, StableDiffusion3Img2ImgPipeline
from transformers import CLIPTextModelWithProjection, CLIPTokenizer, T5EncoderModel, T5TokenizerFast
from mellon.NodeBase import NodeBase
from utils.memory_manager import memory_flush
from utils.hf_utils import is_local_files_only, get_repo_path
from utils.diffusers_utils import get_clip_prompt_embeds, get_t5_prompt_embeds
from config import config
from mellon.quantization import NodeQuantization
import math

HF_TOKEN = config.hf['token']

def calculate_mu(width: int, height: int, 
                patch_size: int = 2,
                base_image_seq_len: int = 256,
                max_image_seq_len: int = 4096,
                base_shift: float = 0.5,
                max_shift: float = 1.15) -> float:

    # latent size
    width = width // 8
    height = height // 8

    seq_len = (width // patch_size) * (height // patch_size)
    seq_len = max(min(seq_len, max_image_seq_len), base_image_seq_len)

    # this is the default mu calculation
    #m = (max_shift - base_shift) / (max_image_seq_len - base_image_seq_len)
    #b = base_shift - m * base_image_seq_len
    #mu = seq_len * m + b
    
    # This is my own mess. TODO: check if this is correct
    factor = (math.log2(seq_len) - math.log2(base_image_seq_len)) / (math.log2(max_image_seq_len) - math.log2(base_image_seq_len))
    factor = max(min(factor, 1.0), 0.0)
    mu = base_shift + factor * (max_shift - base_shift)

    return mu

class SD3PipelineLoader(NodeBase):
    def execute(
            self,
            model_id,
            dtype,
            load_t5,
            transformer_in,
            text_encoders_in,
            vae_in
        ):
        kwargs = {}

        if transformer_in:
            kwargs['transformer'] = transformer_in

        if text_encoders_in:
            kwargs['text_encoder'] = text_encoders_in['text_encoder']
            kwargs['text_encoder_2'] = text_encoders_in['text_encoder_2']
            kwargs['text_encoder_3'] = text_encoders_in['text_encoder_3']
            kwargs['tokenizer'] = text_encoders_in['tokenizer']
            kwargs['tokenizer_2'] = text_encoders_in['tokenizer_2']
            kwargs['tokenizer_3'] = text_encoders_in['tokenizer_3']

        if vae_in:
            kwargs['vae'] = vae_in

        if not load_t5:
            kwargs['text_encoder_3'] = None
            kwargs['tokenizer_3'] = None

        model_id = model_id or 'stabilityai/stable-diffusion-3.5-large'

        pipeline = StableDiffusion3Pipeline.from_pretrained(
            model_id,
            **kwargs,
            torch_dtype=dtype,
            token=HF_TOKEN,
            local_files_only=is_local_files_only(model_id),
        )

        if not hasattr(pipeline.transformer, '_mm_id'):
            pipeline.transformer._mm_id = self.mm_add(pipeline.transformer, priority=3)

        if not hasattr(pipeline.text_encoder, '_mm_id'):
            pipeline.text_encoder._mm_id = self.mm_add(pipeline.text_encoder, priority=1)

        if not hasattr(pipeline.text_encoder_2, '_mm_id'):
            pipeline.text_encoder_2._mm_id = self.mm_add(pipeline.text_encoder_2, priority=1)

        if load_t5 and not hasattr(pipeline.text_encoder_3, '_mm_id'):
            pipeline.text_encoder_3._mm_id = self.mm_add(pipeline.text_encoder_3, priority=1)

        if not hasattr(pipeline.vae, '_mm_id'):
            pipeline.vae._mm_id = self.mm_add(pipeline.vae, priority=2)

        return {
            'pipeline': pipeline,
            'transformer': pipeline.transformer,
            'text_encoders': {
                'text_encoder': pipeline.text_encoder,
                'text_encoder_2': pipeline.text_encoder_2,
                'text_encoder_3': pipeline.text_encoder_3,
                'tokenizer': pipeline.tokenizer,
                'tokenizer_2': pipeline.tokenizer_2,
                'tokenizer_3': pipeline.tokenizer_3,
            },
            'vae': pipeline.vae,
        }

class SD3TransformerLoader(NodeBase, NodeQuantization):
    def execute(self, model_id, dtype, device, quantization, **kwargs):
        import os
        model_id = model_id or 'stabilityai/stable-diffusion-3.5-large'

        local_files_only = is_local_files_only(model_id)

        # overcome bug in diffusers loader with sharded weights
        if local_files_only:
            model_path = os.path.join(get_repo_path(model_id), "transformer")
        else:
            model_path = model_id

        transformer_model = SD3Transformer2DModel.from_pretrained(
            model_path,
            torch_dtype=dtype,
            subfolder="transformer" if not local_files_only else None,
            token=HF_TOKEN,
            local_files_only=local_files_only,
        )

        mm_id = self.mm_add(transformer_model, priority=3)

        if quantization != 'none':
            self.quantize(quantization, model=mm_id, device=device, **kwargs)

        return { 'model': { 'transformer': mm_id, 'device': device, 'model_id': model_id } }


class SD3TextEncodersLoader(NodeBase, NodeQuantization):
    def execute(self, model_id, dtype, load_t5, device, quantization, **kwargs):
        model_id = model_id or 'stabilityai/stable-diffusion-3.5-large'

        model_cfg = {
            'torch_dtype': dtype,
            'token': HF_TOKEN,
            'local_files_only': is_local_files_only(model_id),
            #'use_safetensors': True,
        }

        text_encoder = CLIPTextModelWithProjection.from_pretrained(model_id, subfolder="text_encoder", **model_cfg)
        tokenizer = CLIPTokenizer.from_pretrained(model_id, subfolder="tokenizer", **model_cfg)
        text_encoder_2 = CLIPTextModelWithProjection.from_pretrained(model_id, subfolder="text_encoder_2", **model_cfg)
        tokenizer_2 = CLIPTokenizer.from_pretrained(model_id, subfolder="tokenizer_2", **model_cfg)
        text_encoder = self.mm_add(text_encoder, priority=1)
        text_encoder_2 = self.mm_add(text_encoder_2, priority=1)

        t5_encoder = None
        t5_tokenizer = None
        if load_t5:
            t5_encoder = T5EncoderModel.from_pretrained(model_id, subfolder="text_encoder_3", **model_cfg)
            t5_tokenizer = T5TokenizerFast.from_pretrained(model_id, subfolder="tokenizer_3", **model_cfg)
            t5_encoder = self.mm_add(t5_encoder, priority=0)

        if quantization != 'none' and t5_encoder:
            self.quantize(quantization, model=t5_encoder, device=device, **kwargs)

        return { 'model': {
            'text_encoder': text_encoder,
            'tokenizer': tokenizer,
            'text_encoder_2': text_encoder_2,
            'tokenizer_2': tokenizer_2,
            't5_encoder': t5_encoder,
            't5_tokenizer': t5_tokenizer,
            'device': device,
            'model_id': model_id,
        }}

class SD3PromptEncoder(NodeBase):
    def execute(self,
                text_encoders,
                prompt,
                prompt_2,
                prompt_3,
                negative_prompt,
                negative_prompt_2,
                negative_prompt_3,
                noise_clip,
                noise_negative_clip,
                noise_t5,
                noise_negative_t5,
                device):
        
        if not isinstance(text_encoders, dict):
            text_encoders = {
                'text_encoder': text_encoders.text_encoder,
                'text_encoder_2': text_encoders.text_encoder_2,
                'text_encoder_3': text_encoders.text_encoder_3,
                'tokenizer': text_encoders.tokenizer,
                'tokenizer_2': text_encoders.tokenizer_2,
                'tokenizer_3': text_encoders.tokenizer_3,
            }

        prompt = prompt or ""
        prompt_2 = prompt_2 or prompt
        prompt_3 = prompt_3 or prompt
        negative_prompt = negative_prompt or ""
        negative_prompt_2 = negative_prompt_2 or negative_prompt
        negative_prompt_3 = negative_prompt_3 or negative_prompt

        def encode(positive_prompt, negative_prompt, text_encoder, tokenizer, clip_skip=None, noise=0.0, negative_noise=0.0):
            prompt_embeds, pooled_prompt_embeds = get_clip_prompt_embeds(positive_prompt, tokenizer, text_encoder, clip_skip=clip_skip, noise=noise)
            negative_prompt_embeds, negative_pooled_prompt_embeds = get_clip_prompt_embeds(negative_prompt, tokenizer, text_encoder, clip_skip=clip_skip, noise=negative_noise)
            return (prompt_embeds, negative_prompt_embeds, pooled_prompt_embeds, negative_pooled_prompt_embeds)

        # 1. Encode the prompts with the first text encoder
        text_encoders['text_encoder'] = self.mm_load(text_encoders['text_encoder'], device)
        prompt_embeds, negative_prompt_embeds, pooled_prompt_embeds, negative_pooled_prompt_embeds = self.mm_inference(
            lambda: encode(prompt, negative_prompt, text_encoders['text_encoder'], text_encoders['tokenizer'], noise=noise_clip, negative_noise=noise_negative_clip),
            device,
            exclude=text_encoders['text_encoder']
        )

        # 2. Encode the prompts with the second text encoder
        text_encoders['text_encoder_2'] = self.mm_load(text_encoders['text_encoder_2'], device)
        prompt_embeds_2, negative_prompt_embeds_2, pooled_prompt_embeds_2, negative_pooled_prompt_embeds_2 = self.mm_inference(
            lambda: encode(prompt_2, negative_prompt_2, text_encoders['text_encoder_2'], text_encoders['tokenizer_2'], noise=noise_clip, negative_noise=noise_negative_clip),
            device,
            exclude=text_encoders['text_encoder_2']
        )

        # 3. Concatenate all clip embeddings
        prompt_embeds = torch.cat([prompt_embeds, prompt_embeds_2], dim=-1).to('cpu')
        negative_prompt_embeds = torch.cat([negative_prompt_embeds, negative_prompt_embeds_2], dim=-1).to('cpu')
        pooled_prompt_embeds = torch.cat([pooled_prompt_embeds, pooled_prompt_embeds_2], dim=-1).to('cpu')
        negative_pooled_prompt_embeds = torch.cat([negative_pooled_prompt_embeds, negative_pooled_prompt_embeds_2], dim=-1).to('cpu')
        del prompt_embeds_2, negative_prompt_embeds_2, pooled_prompt_embeds_2, negative_pooled_prompt_embeds_2

        # 4. Encode the prompts with the third text encoder
        if text_encoders['text_encoder_3']:
            text_encoders['text_encoder_3'] = self.mm_load(text_encoders['text_encoder_3'], device)
            prompt_embeds_3 = self.mm_inference(
                lambda: get_t5_prompt_embeds(prompt_3, text_encoders['tokenizer_3'], text_encoders['text_encoder_3'], noise=noise_t5),
                device,
                exclude=text_encoders['text_encoder_3']
            )
            negative_prompt_embeds_3 = self.mm_inference(   
                lambda: get_t5_prompt_embeds(negative_prompt_3, text_encoders['tokenizer_3'], text_encoders['text_encoder_3'], noise=noise_negative_t5),
                device,
                exclude=text_encoders['text_encoder_3']
            )
        else:
            prompt_embeds_3 = torch.zeros((prompt_embeds.shape[0], 256, 4096), device='cpu', dtype=prompt_embeds.dtype)
            negative_prompt_embeds_3 = prompt_embeds_3

        # 5. Merge the clip and T5 embedings
        # T5 should be always longer but you never know with long prompt support
        if prompt_embeds.shape[-1] > prompt_embeds_3.shape[-1]:
            prompt_embeds_3 = torch.nn.functional.pad(prompt_embeds_3, (0, prompt_embeds.shape[-1] - prompt_embeds_3.shape[-1]))
        elif prompt_embeds.shape[-1] < prompt_embeds_3.shape[-1]:
            prompt_embeds = torch.nn.functional.pad(prompt_embeds, (0, prompt_embeds_3.shape[-1] - prompt_embeds.shape[-1]))
        if negative_prompt_embeds.shape[-1] > negative_prompt_embeds_3.shape[-1]:
            negative_prompt_embeds_3 = torch.nn.functional.pad(negative_prompt_embeds_3, (0, negative_prompt_embeds.shape[-1] - negative_prompt_embeds_3.shape[-1]))
        elif negative_prompt_embeds.shape[-1] < negative_prompt_embeds_3.shape[-1]:
            negative_prompt_embeds = torch.nn.functional.pad(negative_prompt_embeds, (0, negative_prompt_embeds_3.shape[-1] - negative_prompt_embeds.shape[-1]))

        prompt_embeds_3 = prompt_embeds_3.to('cpu')
        negative_prompt_embeds_3 = negative_prompt_embeds_3.to('cpu')
        prompt_embeds = torch.cat([prompt_embeds, prompt_embeds_3], dim=-2)
        negative_prompt_embeds = torch.cat([negative_prompt_embeds, negative_prompt_embeds_3], dim=-2)

        # Finally ensure positive and negative prompt embeddings have the same length
        if prompt_embeds.shape[1] > negative_prompt_embeds.shape[1]:
            negative_prompt_embeds = torch.nn.functional.pad(negative_prompt_embeds, (0, 0, 0, prompt_embeds.shape[1] - negative_prompt_embeds.shape[1]))
        elif prompt_embeds.shape[1] < negative_prompt_embeds.shape[1]:
            prompt_embeds = torch.nn.functional.pad(prompt_embeds, (0, 0, 0, negative_prompt_embeds.shape[1] - prompt_embeds.shape[1]))

        return {
            'embeds': {
                'prompt_embeds': prompt_embeds,
                'pooled_prompt_embeds': pooled_prompt_embeds,
                'negative_prompt_embeds': negative_prompt_embeds,
                'negative_pooled_prompt_embeds': negative_pooled_prompt_embeds,
            }
        }

class SD3Sampler(NodeBase):
    # def __init__(self, node_id):
    #     super().__init__(node_id)

    #     self.dummy_vae = AutoencoderKL(
    #         in_channels=3,
    #         out_channels=3,
    #         down_block_types=['DownEncoderBlock2D', 'DownEncoderBlock2D', 'DownEncoderBlock2D', 'DownEncoderBlock2D'],
    #         up_block_types=['UpDecoderBlock2D', 'UpDecoderBlock2D', 'UpDecoderBlock2D', 'UpDecoderBlock2D'],
    #         block_out_channels=[128, 256, 512, 512],
    #         layers_per_block=2,
    #         latent_channels=16,
    #     )

    #     self.schedulers_config = {
    #         'FlowMatchEulerDiscreteScheduler': {
    #             'num_train_timesteps': 1000,
    #             'shift': 3.0,
    #             'use_dynamic_shifting': False,
    #             'base_shift': 0.5,
    #             'max_shift': 1.15,
    #             'base_image_seq_len': 256,
    #             'max_image_seq_len': 4096,
    #             'invert_sigmas': False,
    #         },
    #         'FlowMatchHeunDiscreteScheduler': {
    #             'num_train_timesteps': 1000,
    #             'shift': 3.0,
    #         }
    #     }
        
    def execute(self,
                pipeline,
                prompt,
                width,
                height,
                seed,
                latents_in,
                scheduler,
                steps,
                cfg,
                denoise_range,
                shift,
                use_dynamic_shifting,
                device):

        generator = torch.Generator(device=device).manual_seed(seed)

        # 1. Create the scheduler
        if ( pipeline.scheduler.__class__.__name__ != scheduler ):
            if scheduler == 'FlowMatchHeunDiscreteScheduler':
                from diffusers import FlowMatchHeunDiscreteScheduler as SchedulerCls
                use_dynamic_shifting = False # not supported by Heun
            else:
                from diffusers import FlowMatchEulerDiscreteScheduler as SchedulerCls
        else:
            SchedulerCls = pipeline.scheduler.__class__

        scheduler_config = pipeline.scheduler.config
        mu = None
        if use_dynamic_shifting:
            mu = calculate_mu(width, height,
                            patch_size=2,
                            base_image_seq_len=scheduler_config['base_image_seq_len'],
                            max_image_seq_len=scheduler_config['max_image_seq_len'],
                            base_shift=scheduler_config['base_shift'],
                            max_shift=scheduler_config['max_shift'])

        sampling_scheduler = SchedulerCls.from_config(scheduler_config, shift=shift, use_dynamic_shifting=use_dynamic_shifting)

        # 2. Prepare the prompts
        positive = { 'prompt_embeds': prompt['prompt_embeds'], 'pooled_prompt_embeds': prompt['pooled_prompt_embeds'] }
        negative = None

        if 'negative_prompt_embeds' in prompt:
            negative = { 'prompt_embeds': prompt['negative_prompt_embeds'], 'pooled_prompt_embeds': prompt['negative_pooled_prompt_embeds'] }

        if not negative:
            negative = { 'prompt_embeds': torch.zeros_like(positive['prompt_embeds']), 'pooled_prompt_embeds': torch.zeros_like(positive['pooled_prompt_embeds']) }
        
        # Ensure both prompt embeddings have the same length
        if positive['prompt_embeds'].shape[1] > negative['prompt_embeds'].shape[1]:
            negative['prompt_embeds'] = torch.nn.functional.pad(negative['prompt_embeds'], (0, 0, 0, positive['prompt_embeds'].shape[1] - negative['prompt_embeds'].shape[1]))
        elif positive['prompt_embeds'].shape[1] < negative['prompt_embeds'].shape[1]:
            positive['prompt_embeds'] = torch.nn.functional.pad(positive['prompt_embeds'], (0, 0, 0, negative['prompt_embeds'].shape[1] - positive['prompt_embeds'].shape[1]))

        # 3. Create a dummy VAE
        dummy_vae = AutoencoderKL(
            in_channels=3,
            out_channels=3,
            down_block_types=['DownEncoderBlock2D', 'DownEncoderBlock2D', 'DownEncoderBlock2D', 'DownEncoderBlock2D'],
            up_block_types=['UpDecoderBlock2D', 'UpDecoderBlock2D', 'UpDecoderBlock2D', 'UpDecoderBlock2D'],
            block_out_channels=[128, 256, 512, 512],
            layers_per_block=2,
            latent_channels=16,
        ).to(device)

        # 4. Run the denoise loop
        pipelineCls = StableDiffusion3Pipeline if latents_in is None else StableDiffusion3Img2ImgPipeline

        sampling_pipe = pipelineCls.from_pretrained(
            pipeline.config._name_or_path,
            transformer=pipeline.transformer,
            text_encoder=None,
            text_encoder_2=None,
            text_encoder_3=None,
            tokenizer=None,
            tokenizer_2=None,
            tokenizer_3=None,
            scheduler=sampling_scheduler,
            vae=dummy_vae,
            local_files_only=True,
        )

        sampling_config = {
            'generator': generator,
            'prompt_embeds': positive['prompt_embeds'].to(device, dtype=pipeline.transformer.dtype),
            'pooled_prompt_embeds': positive['pooled_prompt_embeds'].to(device, dtype=pipeline.transformer.dtype),
            'negative_prompt_embeds': negative['prompt_embeds'].to(device, dtype=pipeline.transformer.dtype),
            'negative_pooled_prompt_embeds': negative['pooled_prompt_embeds'].to(device, dtype=pipeline.transformer.dtype),
            'width': width,
            'height': height,
            'guidance_scale': cfg,
            'num_inference_steps': steps,
            'output_type': "latent",
            'callback_on_step_end': self.pipe_callback,
            'mu': mu,
        }

        if latents_in is not None:
            sampling_config['width'] = None
            sampling_config['height'] = None
            sampling_config['image'] = latents_in
            sampling_config['strength'] = 1 - (denoise_range[0] or 0)

        self.mm_load(pipeline.transformer, device)
        latents = self.mm_inference(
            lambda: sampling_pipe(**sampling_config).images,
            device,
            exclude=pipeline.transformer
        )
        latents = latents.to('cpu')

        del sampling_pipe, sampling_config, dummy_vae

        return { 'latents': latents, 'pipeline_out': pipeline }


================================================================================
FILE: ./modules/StableDiffusion3/__init__.py
================================================================================

from utils.torch_utils import device_list, default_device, str_to_dtype
from utils.hf_utils import list_local_models

MODULE_MAP = {
    'SD3PipelineLoader': {
        'label': 'SD3 Pipeline Loader',
        'category': 'loaders',
        'params': {
            'transformer': {
                'label': 'Transformer',
                'type': 'SD3Transformer2DModel',
                'display': 'output',
            },
            'text_encoders': {
                'label': 'Text Encoders',
                'type': 'SD3TextEncoders',
                'display': 'output',
            },
            'vae': {
                'label': 'VAE',
                'type': 'VAE',
                'display': 'output',
            },
            'pipeline': {
                'label': 'SD3 Pipeline',
                'type': 'pipeline',
                'display': 'output',
            },
            'model_id': {
                'label': 'Model ID',
                'type': 'string',
                'options': list_local_models(filters={"_class_name": r"Diffusion3Pipeline$"}),
                'display': 'autocomplete',
                'no_validation': True,
                'default': 'stabilityai/stable-diffusion-3.5-large',
            },
            'dtype': {
                'label': 'Dtype',
                'type': 'string',
                'options': ['auto', 'float32', 'float16', 'bfloat16'],
                'default': 'bfloat16',
                'postProcess': str_to_dtype,
            },
            'load_t5': {
                'label': 'Load T5 Encoder',
                'type': 'boolean',
                'default': True,
            },
            'transformer_in': {
                'label': 'Transformer',
                'type': 'SD3Transformer2DModel',
                'display': 'input',
            },
            'text_encoders_in': {
                'label': 'Text Encoders',
                'type': 'SD3TextEncoders',
                'display': 'input',
            },
            'vae_in': {
                'label': 'VAE',
                'type': 'VAE',
                'display': 'input',
            },
        },
    },

    # 'SD3TransformerLoader': {
    #     'label': 'SD3 Transformer loader',
    #     'description': 'Load the Transformer of an SD3 model',
    #     'category': 'samplers',
    #     'params': {
    #         'model': {
    #             'label': 'Transformer',
    #             'type': 'SD3Transformer2DModel',
    #             'display': 'output',
    #         },
    #         'model_id': {
    #             'label': 'Model ID',
    #             'type': 'string',
    #             'options': list_local_models(),
    #             'display': 'autocomplete',
    #             'no_validation': True,
    #             'default': 'stabilityai/stable-diffusion-3.5-large',
    #         },
    #         'dtype': {
    #             'label': 'dtype',
    #             'options': ['auto', 'float32', 'float16', 'bfloat16'],
    #             'default': 'bfloat16',
    #             'postProcess': str_to_dtype,
    #         },
    #         'device': {
    #             'label': 'Device',
    #             'type': 'string',
    #             'options': device_list,
    #             'default': default_device,
    #         },
    #     },
    # },

    # 'SD3TextEncodersLoader': {
    #     'label': 'SD3 Text Encoders Loader',
    #     'description': 'Load both the CLIP and T5 Text Encoders',
    #     'category': 'text-encoders',
    #     'params': {
    #         'model': {
    #             'label': 'SD3 Encoders',
    #             'display': 'output',
    #             'type': 'SD3TextEncoders',
    #         },
    #         'model_id': {
    #             'label': 'Model ID',
    #             'type': 'string',
    #             'options': list_local_models(),
    #             'display': 'autocomplete',
    #             'no_validation': True,
    #             'default': 'stabilityai/stable-diffusion-3.5-large',
    #         },
    #         'dtype': {
    #             'label': 'Dtype',
    #             'type': 'string',
    #             'options': ['auto', 'float32', 'float16', 'bfloat16'],
    #             'default': 'bfloat16',
    #         },
    #         'device': {
    #             'label': 'Device',
    #             'type': 'string',
    #             'options': device_list,
    #             'default': default_device,
    #         },
    #         'load_t5': {
    #             'label': 'Load T5 Encoder',
    #             'type': 'boolean',
    #             'default': True,
    #         },
    #     },
    # },

    'SD3PromptEncoder': {
        'label': 'SD3 Prompt Encoder',
        'category': 'text-encoders',
        'params': {
            'text_encoders': {
                'label': 'SD3 Encoders | SD3 Pipeline',
                'display': 'input',
                'type': ['SD3TextEncoders', 'pipeline'],
            },
            'embeds': {
                'label': 'Embeddings',
                'display': 'output',
                'type': 'SD3Embeddings',
            },
            'prompt': {
                'label': 'Prompt',
                'type': 'string',
                'display': 'textarea',
            },
            'negative_prompt': {
                'label': 'Negative Prompt',
                'type': 'string',
                'display': 'textarea',
            },
            'prompt_2': {
                'label': 'Prompt CLIP G',
                'type': 'string',
                'display': 'textarea',
                'group': { 'key': 'extra_prompts', 'label': 'Extra Prompts', 'display': 'collapse' },
            },
            'prompt_3': {
                'label': 'Prompt T5',
                'type': 'string',
                'display': 'textarea',
                'group': 'extra_prompts',
            },
            'negative_prompt_2': {
                'label': 'Negative CLIP G',
                'type': 'string',
                'display': 'textarea',
                'group': 'extra_prompts',
            },
            'negative_prompt_3': {
                'label': 'Negative T5',
                'type': 'string',
                'display': 'textarea',
                'group': 'extra_prompts',
            },
            'noise_clip': {
                'label': 'Clip Noise Pos',
                'type': 'float',
                'default': 0.0,
                'min': 0,
                'max': 1,
                'step': 0.01,
                'display': 'slider',
                'group': { 'key': 'noise', 'label': 'Noise', 'display': 'collapse' },
            },
            'noise_negative_clip': {
                'label': 'ClipNoise Neg',
                'type': 'float',
                'default': 0.0,
                'min': 0,
                'max': 1,
                'step': 0.01,
                'display': 'slider',
                'group': 'noise',
            },
            'noise_t5': {
                'label': 'T5 Noise Pos',
                'type': 'float',
                'default': 0.0,
                'min': 0,
                'max': 1,
                'step': 0.01,
                'display': 'slider',
                'group': 'noise',
            },
            'noise_negative_t5': {
                'label': 'T5 Noise Neg',
                'type': 'float',
                'default': 0.0,
                'min': 0,
                'max': 1,
                'step': 0.01,
                'display': 'slider',
                'group': 'noise',
            },
            'device': {
                'label': 'Device',
                'type': 'string',
                'options': device_list,
                'default': default_device,
            },
        },
    },

    'SD3Sampler': {
        'label': 'SD3 Sampler',
        'category': 'samplers',
        'style': {
            'maxWidth': '360px',
        },
        'params': {
            'pipeline': {
                'label': 'Transformer | Pipeline',
                'display': 'input',
                'type': ['SD3Transformer2DModel', 'pipeline'],
            },
            'prompt': {
                'label': 'Prompt',
                'display': 'input',
                'type': ['SD3Embeddings', 'embeddings'],
            },
            'latents_in': {
                'label': 'Latents',
                'display': 'input',
                'type': 'latent',
                'onChange': { 'action': 'disable', 'target': { 'connected': ['dimensions_group'], 'disconnected': ['denoise'] } },
            },
            'pipeline_out': {
                'label': 'Pipeline',
                'display': 'output',
                'type': 'pipeline',
            },
            'latents': {
                'label': 'Latents',
                'type': 'latent',
                'display': 'output',
            },
            'width': {
                'label': 'Width',
                'type': 'int',
                'display': 'text',
                'default': 1024,
                'min': 8,
                'max': 8192,
                'step': 8,
                'group': 'dimensions',
            },
            'height': {
                'label': 'Height',
                'type': 'int',
                'display': 'text',
                'default': 1024,
                'min': 8,
                'max': 8192,
                'step': 8,
                'group': 'dimensions',
            },
            'resolution_picker': {
                'label': 'Resolution',
                'display': 'ui',
                'type': 'dropdownIcon',
                'options': [
                    { 'label': ' 720×1280 (9:16)', 'value': [720, 1280] },
                    { 'label': ' 768×1344 (0.57)', 'value': [768, 1344] },
                    { 'label': ' 768×1280 (3:5)', 'value': [768, 1280] },
                    { 'label': ' 832×1152 (3:4)', 'value': [832, 1152] },
                    { 'label': '1024×1024 (1:1)', 'value': [1024, 1024] },
                    { 'label': ' 1152×832 (4:3)', 'value': [1152, 832] },
                    { 'label': ' 1280×768 (5:3)', 'value': [1280, 768] },
                    { 'label': ' 1344×768 (1.75)', 'value': [1344, 768] },
                    { 'label': ' 1280×720 (16:9)', 'value': [1280, 720] },
                ],
                'onChange': { 'action': 'set', 'target': ['width', 'height'] },
                'group': 'dimensions',
            },
            'seed': {
                'label': 'Seed',
                'type': 'int',
                'default': 0,
                'min': 0,
                'display': 'random',
            },
            'steps': {
                'label': 'Steps',
                'type': 'int',
                'default': 30,
                'min': 1,
                'max': 1000,
            },
            'cfg': {
                'label': 'Guidance',
                'type': 'float',
                'default': 5,
                'min': 0,
                'max': 100,
            },
            'denoise_range': {
                'label': 'Denoise Range',
                'type': 'float',
                'display': 'range',
                'default': [0, 1],
                'min': 0,
                'max': 1,
                'step': 0.01,
            },
            'scheduler': {
                'label': 'Scheduler',
                'display': 'select',
                'type': ['string', 'scheduler'],
                'options': {
                    'FlowMatchEulerDiscreteScheduler': 'Flow Match Euler Discrete',
                    'FlowMatchHeunDiscreteScheduler': 'Flow Match Heun Discrete',
                },
                'default': 'FlowMatchEulerDiscreteScheduler',
            },
            'shift': {
                'label': 'Shift',
                'type': 'float',
                'default': 3.0,
                'min': 0,
                'max': 12,
                'step': 0.05,
                'group': { 'key': 'scheduler', 'label': 'Scheduler options', 'display': 'collapse' },
            },
            'use_dynamic_shifting': {
                'label': 'Use dynamic shifting',
                'type': 'boolean',
                'default': False,
                'group': 'scheduler',
            },
            'device': {
                'label': 'Device',
                'type': 'string',
                'options': device_list,
                'default': default_device,
            },
        },
    },
}

quantization_params = {
    'quantization': {
        'label': 'Quantization',
        'options': {
            'none': 'None',
            'quanto': 'Quanto',
            'torchao': 'TorchAO',
        },
        'default': 'none',
        'onChange': { 'action': 'show', 'target': { 'none': None, 'quanto': 'quanto_group', 'torchao': 'torchao_group' } },
    },

    # Quanto Quantization
    'quanto_weights': {
        'label': 'Weights',
        'options': ['int2', 'int4', 'int8', 'float8'],
        'default': 'float8',
        'group': { 'key': 'quanto', 'label': 'Quanto Quantization', 'display': 'group', 'direction': 'column' },
    },
    'quanto_activations': {
        'label': 'Activations',
        'options': ['none', 'int2', 'int4', 'int8', 'float8'],
        'default': 'none',
        'group': 'quanto'
    },
    'quanto_exclude': {
        'label': 'Exclude blocks',
        'description': 'Comma separated list of block names to exclude from quantization',
        'type': 'string',
        'default': '',
        'group': 'quanto'
    },

    # TorchAO Quantization
    'torchao_weights': {
        'label': 'Weights',
        'options': {
            'int8_weight_only': 'int8 weight',
            'int4_weight_only': 'int4 weight',
            'int8_dynamic_activation_int8_weight': 'int8 weight + activation',
        },
        'default': 'int8_weight_only',
        'group': { 'key': 'torchao', 'label': 'TorchAO Quantization', 'display': 'group', 'direction': 'column' },
    },
    'torchao_individual_layers': {
        'label': 'Quantize each layer individually',
        'type': 'boolean',
        'default': False,
        'group': 'torchao'
    },
}

#MODULE_MAP['SD3PipelineLoader']['params'].update(quantization_params)
#MODULE_MAP['SD3TextEncodersLoader']['params'].update(quantization_params)


================================================================================
FILE: ./modules/StableDiffusion3/blocks.py
================================================================================


SD3_BLOCKS = [
    "pos_embed.proj",
    "time_text_embed.timestep_embedder.linear_1",
    "time_text_embed.timestep_embedder.linear_2",
    "time_text_embed.text_embedder.linear_1",
    "time_text_embed.text_embedder.linear_2",
    "context_embedder",
    "transformer_blocks.0.norm1.linear",
    "transformer_blocks.0.norm1_context.linear",
    "transformer_blocks.0.attn.to_q",
    "transformer_blocks.0.attn.to_k",
    "transformer_blocks.0.attn.to_v",
    "transformer_blocks.0.attn.add_k_proj",
    "transformer_blocks.0.attn.add_v_proj",
    "transformer_blocks.0.attn.add_q_proj",
    "transformer_blocks.0.attn.to_out.0",
    "transformer_blocks.0.attn.to_add_out",
    "transformer_blocks.0.ff.net.0.proj",
    "transformer_blocks.0.ff.net.2",
    "transformer_blocks.0.ff_context.net.0.proj",
    "transformer_blocks.0.ff_context.net.2",
    "transformer_blocks.1.norm1.linear",
    "transformer_blocks.1.norm1_context.linear",
    "transformer_blocks.1.attn.to_q",
    "transformer_blocks.1.attn.to_k",
    "transformer_blocks.1.attn.to_v",
    "transformer_blocks.1.attn.add_k_proj",
    "transformer_blocks.1.attn.add_v_proj",
    "transformer_blocks.1.attn.add_q_proj",
    "transformer_blocks.1.attn.to_out.0",
    "transformer_blocks.1.attn.to_add_out",
    "transformer_blocks.1.ff.net.0.proj",
    "transformer_blocks.1.ff.net.2",
    "transformer_blocks.1.ff_context.net.0.proj",
    "transformer_blocks.1.ff_context.net.2",
    "transformer_blocks.2.norm1.linear",
    "transformer_blocks.2.norm1_context.linear",
    "transformer_blocks.2.attn.to_q",
    "transformer_blocks.2.attn.to_k",
    "transformer_blocks.2.attn.to_v",
    "transformer_blocks.2.attn.add_k_proj",
    "transformer_blocks.2.attn.add_v_proj",
    "transformer_blocks.2.attn.add_q_proj",
    "transformer_blocks.2.attn.to_out.0",
    "transformer_blocks.2.attn.to_add_out",
    "transformer_blocks.2.ff.net.0.proj",
    "transformer_blocks.2.ff.net.2",
    "transformer_blocks.2.ff_context.net.0.proj",
    "transformer_blocks.2.ff_context.net.2",
    "transformer_blocks.3.norm1.linear",
    "transformer_blocks.3.norm1_context.linear",
    "transformer_blocks.3.attn.to_q",
    "transformer_blocks.3.attn.to_k",
    "transformer_blocks.3.attn.to_v",
    "transformer_blocks.3.attn.add_k_proj",
    "transformer_blocks.3.attn.add_v_proj",
    "transformer_blocks.3.attn.add_q_proj",
    "transformer_blocks.3.attn.to_out.0",
    "transformer_blocks.3.attn.to_add_out",
    "transformer_blocks.3.ff.net.0.proj",
    "transformer_blocks.3.ff.net.2",
    "transformer_blocks.3.ff_context.net.0.proj",
    "transformer_blocks.3.ff_context.net.2",
    "transformer_blocks.4.norm1.linear",
    "transformer_blocks.4.norm1_context.linear",
    "transformer_blocks.4.attn.to_q",
    "transformer_blocks.4.attn.to_k",
    "transformer_blocks.4.attn.to_v",
    "transformer_blocks.4.attn.add_k_proj",
    "transformer_blocks.4.attn.add_v_proj",
    "transformer_blocks.4.attn.add_q_proj",
    "transformer_blocks.4.attn.to_out.0",
    "transformer_blocks.4.attn.to_add_out",
    "transformer_blocks.4.ff.net.0.proj",
    "transformer_blocks.4.ff.net.2",
    "transformer_blocks.4.ff_context.net.0.proj",
    "transformer_blocks.4.ff_context.net.2",
    "transformer_blocks.5.norm1.linear",
    "transformer_blocks.5.norm1_context.linear",
    "transformer_blocks.5.attn.to_q",
    "transformer_blocks.5.attn.to_k",
    "transformer_blocks.5.attn.to_v",
    "transformer_blocks.5.attn.add_k_proj",
    "transformer_blocks.5.attn.add_v_proj",
    "transformer_blocks.5.attn.add_q_proj",
    "transformer_blocks.5.attn.to_out.0",
    "transformer_blocks.5.attn.to_add_out",
    "transformer_blocks.5.ff.net.0.proj",
    "transformer_blocks.5.ff.net.2",
    "transformer_blocks.5.ff_context.net.0.proj",
    "transformer_blocks.5.ff_context.net.2",
    "transformer_blocks.6.norm1.linear",
    "transformer_blocks.6.norm1_context.linear",
    "transformer_blocks.6.attn.to_q",
    "transformer_blocks.6.attn.to_k",
    "transformer_blocks.6.attn.to_v",
    "transformer_blocks.6.attn.add_k_proj",
    "transformer_blocks.6.attn.add_v_proj",
    "transformer_blocks.6.attn.add_q_proj",
    "transformer_blocks.6.attn.to_out.0",
    "transformer_blocks.6.attn.to_add_out",
    "transformer_blocks.6.ff.net.0.proj",
    "transformer_blocks.6.ff.net.2",
    "transformer_blocks.6.ff_context.net.0.proj",
    "transformer_blocks.6.ff_context.net.2",
    "transformer_blocks.7.norm1.linear",
    "transformer_blocks.7.norm1_context.linear",
    "transformer_blocks.7.attn.to_q",
    "transformer_blocks.7.attn.to_k",
    "transformer_blocks.7.attn.to_v",
    "transformer_blocks.7.attn.add_k_proj",
    "transformer_blocks.7.attn.add_v_proj",
    "transformer_blocks.7.attn.add_q_proj",
    "transformer_blocks.7.attn.to_out.0",
    "transformer_blocks.7.attn.to_add_out",
    "transformer_blocks.7.ff.net.0.proj",
    "transformer_blocks.7.ff.net.2",
    "transformer_blocks.7.ff_context.net.0.proj",
    "transformer_blocks.7.ff_context.net.2",
    "transformer_blocks.8.norm1.linear",
    "transformer_blocks.8.norm1_context.linear",
    "transformer_blocks.8.attn.to_q",
    "transformer_blocks.8.attn.to_k",
    "transformer_blocks.8.attn.to_v",
    "transformer_blocks.8.attn.add_k_proj",
    "transformer_blocks.8.attn.add_v_proj",
    "transformer_blocks.8.attn.add_q_proj",
    "transformer_blocks.8.attn.to_out.0",
    "transformer_blocks.8.attn.to_add_out",
    "transformer_blocks.8.ff.net.0.proj",
    "transformer_blocks.8.ff.net.2",
    "transformer_blocks.8.ff_context.net.0.proj",
    "transformer_blocks.8.ff_context.net.2",
    "transformer_blocks.9.norm1.linear",
    "transformer_blocks.9.norm1_context.linear",
    "transformer_blocks.9.attn.to_q",
    "transformer_blocks.9.attn.to_k",
    "transformer_blocks.9.attn.to_v",
    "transformer_blocks.9.attn.add_k_proj",
    "transformer_blocks.9.attn.add_v_proj",
    "transformer_blocks.9.attn.add_q_proj",
    "transformer_blocks.9.attn.to_out.0",
    "transformer_blocks.9.attn.to_add_out",
    "transformer_blocks.9.ff.net.0.proj",
    "transformer_blocks.9.ff.net.2",
    "transformer_blocks.9.ff_context.net.0.proj",
    "transformer_blocks.9.ff_context.net.2",
    "transformer_blocks.10.norm1.linear",
    "transformer_blocks.10.norm1_context.linear",
    "transformer_blocks.10.attn.to_q",
    "transformer_blocks.10.attn.to_k",
    "transformer_blocks.10.attn.to_v",
    "transformer_blocks.10.attn.add_k_proj",
    "transformer_blocks.10.attn.add_v_proj",
    "transformer_blocks.10.attn.add_q_proj",
    "transformer_blocks.10.attn.to_out.0",
    "transformer_blocks.10.attn.to_add_out",
    "transformer_blocks.10.ff.net.0.proj",
    "transformer_blocks.10.ff.net.2",
    "transformer_blocks.10.ff_context.net.0.proj",
    "transformer_blocks.10.ff_context.net.2",
    "transformer_blocks.11.norm1.linear",
    "transformer_blocks.11.norm1_context.linear",
    "transformer_blocks.11.attn.to_q",
    "transformer_blocks.11.attn.to_k",
    "transformer_blocks.11.attn.to_v",
    "transformer_blocks.11.attn.add_k_proj",
    "transformer_blocks.11.attn.add_v_proj",
    "transformer_blocks.11.attn.add_q_proj",
    "transformer_blocks.11.attn.to_out.0",
    "transformer_blocks.11.attn.to_add_out",
    "transformer_blocks.11.ff.net.0.proj",
    "transformer_blocks.11.ff.net.2",
    "transformer_blocks.11.ff_context.net.0.proj",
    "transformer_blocks.11.ff_context.net.2",
    "transformer_blocks.12.norm1.linear",
    "transformer_blocks.12.norm1_context.linear",
    "transformer_blocks.12.attn.to_q",
    "transformer_blocks.12.attn.to_k",
    "transformer_blocks.12.attn.to_v",
    "transformer_blocks.12.attn.add_k_proj",
    "transformer_blocks.12.attn.add_v_proj",
    "transformer_blocks.12.attn.add_q_proj",
    "transformer_blocks.12.attn.to_out.0",
    "transformer_blocks.12.attn.to_add_out",
    "transformer_blocks.12.ff.net.0.proj",
    "transformer_blocks.12.ff.net.2",
    "transformer_blocks.12.ff_context.net.0.proj",
    "transformer_blocks.12.ff_context.net.2",
    "transformer_blocks.13.norm1.linear",
    "transformer_blocks.13.norm1_context.linear",
    "transformer_blocks.13.attn.to_q",
    "transformer_blocks.13.attn.to_k",
    "transformer_blocks.13.attn.to_v",
    "transformer_blocks.13.attn.add_k_proj",
    "transformer_blocks.13.attn.add_v_proj",
    "transformer_blocks.13.attn.add_q_proj",
    "transformer_blocks.13.attn.to_out.0",
    "transformer_blocks.13.attn.to_add_out",
    "transformer_blocks.13.ff.net.0.proj",
    "transformer_blocks.13.ff.net.2",
    "transformer_blocks.13.ff_context.net.0.proj",
    "transformer_blocks.13.ff_context.net.2",
    "transformer_blocks.14.norm1.linear",
    "transformer_blocks.14.norm1_context.linear",
    "transformer_blocks.14.attn.to_q",
    "transformer_blocks.14.attn.to_k",
    "transformer_blocks.14.attn.to_v",
    "transformer_blocks.14.attn.add_k_proj",
    "transformer_blocks.14.attn.add_v_proj",
    "transformer_blocks.14.attn.add_q_proj",
    "transformer_blocks.14.attn.to_out.0",
    "transformer_blocks.14.attn.to_add_out",
    "transformer_blocks.14.ff.net.0.proj",
    "transformer_blocks.14.ff.net.2",
    "transformer_blocks.14.ff_context.net.0.proj",
    "transformer_blocks.14.ff_context.net.2",
    "transformer_blocks.15.norm1.linear",
    "transformer_blocks.15.norm1_context.linear",
    "transformer_blocks.15.attn.to_q",
    "transformer_blocks.15.attn.to_k",
    "transformer_blocks.15.attn.to_v",
    "transformer_blocks.15.attn.add_k_proj",
    "transformer_blocks.15.attn.add_v_proj",
    "transformer_blocks.15.attn.add_q_proj",
    "transformer_blocks.15.attn.to_out.0",
    "transformer_blocks.15.attn.to_add_out",
    "transformer_blocks.15.ff.net.0.proj",
    "transformer_blocks.15.ff.net.2",
    "transformer_blocks.15.ff_context.net.0.proj",
    "transformer_blocks.15.ff_context.net.2",
    "transformer_blocks.16.norm1.linear",
    "transformer_blocks.16.norm1_context.linear",
    "transformer_blocks.16.attn.to_q",
    "transformer_blocks.16.attn.to_k",
    "transformer_blocks.16.attn.to_v",
    "transformer_blocks.16.attn.add_k_proj",
    "transformer_blocks.16.attn.add_v_proj",
    "transformer_blocks.16.attn.add_q_proj",
    "transformer_blocks.16.attn.to_out.0",
    "transformer_blocks.16.attn.to_add_out",
    "transformer_blocks.16.ff.net.0.proj",
    "transformer_blocks.16.ff.net.2",
    "transformer_blocks.16.ff_context.net.0.proj",
    "transformer_blocks.16.ff_context.net.2",
    "transformer_blocks.17.norm1.linear",
    "transformer_blocks.17.norm1_context.linear",
    "transformer_blocks.17.attn.to_q",
    "transformer_blocks.17.attn.to_k",
    "transformer_blocks.17.attn.to_v",
    "transformer_blocks.17.attn.add_k_proj",
    "transformer_blocks.17.attn.add_v_proj",
    "transformer_blocks.17.attn.add_q_proj",
    "transformer_blocks.17.attn.to_out.0",
    "transformer_blocks.17.attn.to_add_out",
    "transformer_blocks.17.ff.net.0.proj",
    "transformer_blocks.17.ff.net.2",
    "transformer_blocks.17.ff_context.net.0.proj",
    "transformer_blocks.17.ff_context.net.2",
    "transformer_blocks.18.norm1.linear",
    "transformer_blocks.18.norm1_context.linear",
    "transformer_blocks.18.attn.to_q",
    "transformer_blocks.18.attn.to_k",
    "transformer_blocks.18.attn.to_v",
    "transformer_blocks.18.attn.add_k_proj",
    "transformer_blocks.18.attn.add_v_proj",
    "transformer_blocks.18.attn.add_q_proj",
    "transformer_blocks.18.attn.to_out.0",
    "transformer_blocks.18.attn.to_add_out",
    "transformer_blocks.18.ff.net.0.proj",
    "transformer_blocks.18.ff.net.2",
    "transformer_blocks.18.ff_context.net.0.proj",
    "transformer_blocks.18.ff_context.net.2",
    "transformer_blocks.19.norm1.linear",
    "transformer_blocks.19.norm1_context.linear",
    "transformer_blocks.19.attn.to_q",
    "transformer_blocks.19.attn.to_k",
    "transformer_blocks.19.attn.to_v",
    "transformer_blocks.19.attn.add_k_proj",
    "transformer_blocks.19.attn.add_v_proj",
    "transformer_blocks.19.attn.add_q_proj",
    "transformer_blocks.19.attn.to_out.0",
    "transformer_blocks.19.attn.to_add_out",
    "transformer_blocks.19.ff.net.0.proj",
    "transformer_blocks.19.ff.net.2",
    "transformer_blocks.19.ff_context.net.0.proj",
    "transformer_blocks.19.ff_context.net.2",
    "transformer_blocks.20.norm1.linear",
    "transformer_blocks.20.norm1_context.linear",
    "transformer_blocks.20.attn.to_q",
    "transformer_blocks.20.attn.to_k",
    "transformer_blocks.20.attn.to_v",
    "transformer_blocks.20.attn.add_k_proj",
    "transformer_blocks.20.attn.add_v_proj",
    "transformer_blocks.20.attn.add_q_proj",
    "transformer_blocks.20.attn.to_out.0",
    "transformer_blocks.20.attn.to_add_out",
    "transformer_blocks.20.ff.net.0.proj",
    "transformer_blocks.20.ff.net.2",
    "transformer_blocks.20.ff_context.net.0.proj",
    "transformer_blocks.20.ff_context.net.2",
    "transformer_blocks.21.norm1.linear",
    "transformer_blocks.21.norm1_context.linear",
    "transformer_blocks.21.attn.to_q",
    "transformer_blocks.21.attn.to_k",
    "transformer_blocks.21.attn.to_v",
    "transformer_blocks.21.attn.add_k_proj",
    "transformer_blocks.21.attn.add_v_proj",
    "transformer_blocks.21.attn.add_q_proj",
    "transformer_blocks.21.attn.to_out.0",
    "transformer_blocks.21.attn.to_add_out",
    "transformer_blocks.21.ff.net.0.proj",
    "transformer_blocks.21.ff.net.2",
    "transformer_blocks.21.ff_context.net.0.proj",
    "transformer_blocks.21.ff_context.net.2",
    "transformer_blocks.22.norm1.linear",
    "transformer_blocks.22.norm1_context.linear",
    "transformer_blocks.22.attn.to_q",
    "transformer_blocks.22.attn.to_k",
    "transformer_blocks.22.attn.to_v",
    "transformer_blocks.22.attn.add_k_proj",
    "transformer_blocks.22.attn.add_v_proj",
    "transformer_blocks.22.attn.add_q_proj",
    "transformer_blocks.22.attn.to_out.0",
    "transformer_blocks.22.attn.to_add_out",
    "transformer_blocks.22.ff.net.0.proj",
    "transformer_blocks.22.ff.net.2",
    "transformer_blocks.22.ff_context.net.0.proj",
    "transformer_blocks.22.ff_context.net.2",
    "transformer_blocks.23.norm1.linear",
    "transformer_blocks.23.norm1_context.linear",
    "transformer_blocks.23.attn.to_q",
    "transformer_blocks.23.attn.to_k",
    "transformer_blocks.23.attn.to_v",
    "transformer_blocks.23.attn.add_k_proj",
    "transformer_blocks.23.attn.add_v_proj",
    "transformer_blocks.23.attn.add_q_proj",
    "transformer_blocks.23.attn.to_out.0",
    "transformer_blocks.23.attn.to_add_out",
    "transformer_blocks.23.ff.net.0.proj",
    "transformer_blocks.23.ff.net.2",
    "transformer_blocks.23.ff_context.net.0.proj",
    "transformer_blocks.23.ff_context.net.2",
    "transformer_blocks.24.norm1.linear",
    "transformer_blocks.24.norm1_context.linear",
    "transformer_blocks.24.attn.to_q",
    "transformer_blocks.24.attn.to_k",
    "transformer_blocks.24.attn.to_v",
    "transformer_blocks.24.attn.add_k_proj",
    "transformer_blocks.24.attn.add_v_proj",
    "transformer_blocks.24.attn.add_q_proj",
    "transformer_blocks.24.attn.to_out.0",
    "transformer_blocks.24.attn.to_add_out",
    "transformer_blocks.24.ff.net.0.proj",
    "transformer_blocks.24.ff.net.2",
    "transformer_blocks.24.ff_context.net.0.proj",
    "transformer_blocks.24.ff_context.net.2",
    "transformer_blocks.25.norm1.linear",
    "transformer_blocks.25.norm1_context.linear",
    "transformer_blocks.25.attn.to_q",
    "transformer_blocks.25.attn.to_k",
    "transformer_blocks.25.attn.to_v",
    "transformer_blocks.25.attn.add_k_proj",
    "transformer_blocks.25.attn.add_v_proj",
    "transformer_blocks.25.attn.add_q_proj",
    "transformer_blocks.25.attn.to_out.0",
    "transformer_blocks.25.attn.to_add_out",
    "transformer_blocks.25.ff.net.0.proj",
    "transformer_blocks.25.ff.net.2",
    "transformer_blocks.25.ff_context.net.0.proj",
    "transformer_blocks.25.ff_context.net.2",
    "transformer_blocks.26.norm1.linear",
    "transformer_blocks.26.norm1_context.linear",
    "transformer_blocks.26.attn.to_q",
    "transformer_blocks.26.attn.to_k",
    "transformer_blocks.26.attn.to_v",
    "transformer_blocks.26.attn.add_k_proj",
    "transformer_blocks.26.attn.add_v_proj",
    "transformer_blocks.26.attn.add_q_proj",
    "transformer_blocks.26.attn.to_out.0",
    "transformer_blocks.26.attn.to_add_out",
    "transformer_blocks.26.ff.net.0.proj",
    "transformer_blocks.26.ff.net.2",
    "transformer_blocks.26.ff_context.net.0.proj",
    "transformer_blocks.26.ff_context.net.2",
    "transformer_blocks.27.norm1.linear",
    "transformer_blocks.27.norm1_context.linear",
    "transformer_blocks.27.attn.to_q",
    "transformer_blocks.27.attn.to_k",
    "transformer_blocks.27.attn.to_v",
    "transformer_blocks.27.attn.add_k_proj",
    "transformer_blocks.27.attn.add_v_proj",
    "transformer_blocks.27.attn.add_q_proj",
    "transformer_blocks.27.attn.to_out.0",
    "transformer_blocks.27.attn.to_add_out",
    "transformer_blocks.27.ff.net.0.proj",
    "transformer_blocks.27.ff.net.2",
    "transformer_blocks.27.ff_context.net.0.proj",
    "transformer_blocks.27.ff_context.net.2",
    "transformer_blocks.28.norm1.linear",
    "transformer_blocks.28.norm1_context.linear",
    "transformer_blocks.28.attn.to_q",
    "transformer_blocks.28.attn.to_k",
    "transformer_blocks.28.attn.to_v",
    "transformer_blocks.28.attn.add_k_proj",
    "transformer_blocks.28.attn.add_v_proj",
    "transformer_blocks.28.attn.add_q_proj",
    "transformer_blocks.28.attn.to_out.0",
    "transformer_blocks.28.attn.to_add_out",
    "transformer_blocks.28.ff.net.0.proj",
    "transformer_blocks.28.ff.net.2",
    "transformer_blocks.28.ff_context.net.0.proj",
    "transformer_blocks.28.ff_context.net.2",
    "transformer_blocks.29.norm1.linear",
    "transformer_blocks.29.norm1_context.linear",
    "transformer_blocks.29.attn.to_q",
    "transformer_blocks.29.attn.to_k",
    "transformer_blocks.29.attn.to_v",
    "transformer_blocks.29.attn.add_k_proj",
    "transformer_blocks.29.attn.add_v_proj",
    "transformer_blocks.29.attn.add_q_proj",
    "transformer_blocks.29.attn.to_out.0",
    "transformer_blocks.29.attn.to_add_out",
    "transformer_blocks.29.ff.net.0.proj",
    "transformer_blocks.29.ff.net.2",
    "transformer_blocks.29.ff_context.net.0.proj",
    "transformer_blocks.29.ff_context.net.2",
    "transformer_blocks.30.norm1.linear",
    "transformer_blocks.30.norm1_context.linear",
    "transformer_blocks.30.attn.to_q",
    "transformer_blocks.30.attn.to_k",
    "transformer_blocks.30.attn.to_v",
    "transformer_blocks.30.attn.add_k_proj",
    "transformer_blocks.30.attn.add_v_proj",
    "transformer_blocks.30.attn.add_q_proj",
    "transformer_blocks.30.attn.to_out.0",
    "transformer_blocks.30.attn.to_add_out",
    "transformer_blocks.30.ff.net.0.proj",
    "transformer_blocks.30.ff.net.2",
    "transformer_blocks.30.ff_context.net.0.proj",
    "transformer_blocks.30.ff_context.net.2",
    "transformer_blocks.31.norm1.linear",
    "transformer_blocks.31.norm1_context.linear",
    "transformer_blocks.31.attn.to_q",
    "transformer_blocks.31.attn.to_k",
    "transformer_blocks.31.attn.to_v",
    "transformer_blocks.31.attn.add_k_proj",
    "transformer_blocks.31.attn.add_v_proj",
    "transformer_blocks.31.attn.add_q_proj",
    "transformer_blocks.31.attn.to_out.0",
    "transformer_blocks.31.attn.to_add_out",
    "transformer_blocks.31.ff.net.0.proj",
    "transformer_blocks.31.ff.net.2",
    "transformer_blocks.31.ff_context.net.0.proj",
    "transformer_blocks.31.ff_context.net.2",
    "transformer_blocks.32.norm1.linear",
    "transformer_blocks.32.norm1_context.linear",
    "transformer_blocks.32.attn.to_q",
    "transformer_blocks.32.attn.to_k",
    "transformer_blocks.32.attn.to_v",
    "transformer_blocks.32.attn.add_k_proj",
    "transformer_blocks.32.attn.add_v_proj",
    "transformer_blocks.32.attn.add_q_proj",
    "transformer_blocks.32.attn.to_out.0",
    "transformer_blocks.32.attn.to_add_out",
    "transformer_blocks.32.ff.net.0.proj",
    "transformer_blocks.32.ff.net.2",
    "transformer_blocks.32.ff_context.net.0.proj",
    "transformer_blocks.32.ff_context.net.2",
    "transformer_blocks.33.norm1.linear",
    "transformer_blocks.33.norm1_context.linear",
    "transformer_blocks.33.attn.to_q",
    "transformer_blocks.33.attn.to_k",
    "transformer_blocks.33.attn.to_v",
    "transformer_blocks.33.attn.add_k_proj",
    "transformer_blocks.33.attn.add_v_proj",
    "transformer_blocks.33.attn.add_q_proj",
    "transformer_blocks.33.attn.to_out.0",
    "transformer_blocks.33.attn.to_add_out",
    "transformer_blocks.33.ff.net.0.proj",
    "transformer_blocks.33.ff.net.2",
    "transformer_blocks.33.ff_context.net.0.proj",
    "transformer_blocks.33.ff_context.net.2",
    "transformer_blocks.34.norm1.linear",
    "transformer_blocks.34.norm1_context.linear",
    "transformer_blocks.34.attn.to_q",
    "transformer_blocks.34.attn.to_k",
    "transformer_blocks.34.attn.to_v",
    "transformer_blocks.34.attn.add_k_proj",
    "transformer_blocks.34.attn.add_v_proj",
    "transformer_blocks.34.attn.add_q_proj",
    "transformer_blocks.34.attn.to_out.0",
    "transformer_blocks.34.attn.to_add_out",
    "transformer_blocks.34.ff.net.0.proj",
    "transformer_blocks.34.ff.net.2",
    "transformer_blocks.34.ff_context.net.0.proj",
    "transformer_blocks.34.ff_context.net.2",
    "transformer_blocks.35.norm1.linear",
    "transformer_blocks.35.norm1_context.linear",
    "transformer_blocks.35.attn.to_q",
    "transformer_blocks.35.attn.to_k",
    "transformer_blocks.35.attn.to_v",
    "transformer_blocks.35.attn.add_k_proj",
    "transformer_blocks.35.attn.add_v_proj",
    "transformer_blocks.35.attn.add_q_proj",
    "transformer_blocks.35.attn.to_out.0",
    "transformer_blocks.35.attn.to_add_out",
    "transformer_blocks.35.ff.net.0.proj",
    "transformer_blocks.35.ff.net.2",
    "transformer_blocks.35.ff_context.net.0.proj",
    "transformer_blocks.35.ff_context.net.2",
    "transformer_blocks.36.norm1.linear",
    "transformer_blocks.36.norm1_context.linear",
    "transformer_blocks.36.attn.to_q",
    "transformer_blocks.36.attn.to_k",
    "transformer_blocks.36.attn.to_v",
    "transformer_blocks.36.attn.add_k_proj",
    "transformer_blocks.36.attn.add_v_proj",
    "transformer_blocks.36.attn.add_q_proj",
    "transformer_blocks.36.attn.to_out.0",
    "transformer_blocks.36.attn.to_add_out",
    "transformer_blocks.36.ff.net.0.proj",
    "transformer_blocks.36.ff.net.2",
    "transformer_blocks.36.ff_context.net.0.proj",
    "transformer_blocks.36.ff_context.net.2",
    "transformer_blocks.37.norm1.linear",
    "transformer_blocks.37.norm1_context.linear",
    "transformer_blocks.37.attn.to_q",
    "transformer_blocks.37.attn.to_k",
    "transformer_blocks.37.attn.to_v",
    "transformer_blocks.37.attn.add_k_proj",
    "transformer_blocks.37.attn.add_v_proj",
    "transformer_blocks.37.attn.add_q_proj",
    "transformer_blocks.37.attn.to_out.0",
    "transformer_blocks.37.ff.net.0.proj",
    "transformer_blocks.37.ff.net.2",
    "norm_out.linear",
    "proj_out",
]

================================================================================
FILE: ./modules/Clip/Clip.py
================================================================================

from transformers import CLIPTextModel, CLIPTextModelWithProjection, CLIPTokenizer
from huggingface_hub import list_repo_files
from mellon.NodeBase import NodeBase

class CLIPTextEncoderLoader(NodeBase):
    def execute(self, model_id, dtype, device):
        files = list_repo_files(model_id)
        text_encoder = None
        tokenizer = None
        text_encoder_2 = None
        tokenizer_2 = None

        # for SD1.5, SD2 and SDXL load the text encoder and tokenizer from the subfolder
        if any('text_encoder/' in file for file in files):
            text_encoder = CLIPTextModelWithProjection.from_pretrained(model_id, subfolder="text_encoder", torch_dtype=dtype)
            tokenizer = CLIPTokenizer.from_pretrained(model_id, subfolder="tokenizer", torch_dtype=dtype)

            # for SDXL load the secondary text encoder and tokenizer from the subfolder
            if any('text_encoder_2/' in file for file in files):
                text_encoder_2 = CLIPTextModelWithProjection.from_pretrained(model_id, subfolder="text_encoder_2", torch_dtype=dtype)
                tokenizer_2 = CLIPTokenizer.from_pretrained(model_id, subfolder="tokenizer_2", torch_dtype=dtype)

        
        # if no encoder was found, try to load the encoder from the root
        else:
            text_encoder = CLIPTextModelWithProjection.from_pretrained(model_id, torch_dtype=dtype)
            tokenizer = CLIPTokenizer.from_pretrained(model_id, torch_dtype=dtype)

        return { 'clip_text_encoders': { 'text_encoder': text_encoder, 'tokenizer': tokenizer, 'text_encoder_2': text_encoder_2, 'tokenizer_2': tokenizer_2 , 'device': device }}


================================================================================
FILE: ./modules/Clip/__init__.py
================================================================================

from utils.torch_utils import device_list, default_device

MODULE_MAP = {
    'CLIPTextEncoderLoader': {
        'label': 'Load CLIP Text Encoders',
        'description': 'Load CLIP Text and Tokenizer encoders',
        'category': 'clip',
        'params': {
            'clip_text_encoders': {
                'label': 'Text Encoders',
                'display': 'output',
                'type': 'CLIPTextEncoders',
            },
            'model_id': {
                'label': 'Model ID',
                'type': 'string',
            },
            'dtype': {
                'label': 'Dtype',
                'type': 'string',
                'options': ['auto', 'float32', 'float16', 'bfloat16', 'float8_e4m3fn'],
                'default': 'auto',
            },
            'device': {
                'label': 'Device',
                'type': 'string',
                'options': device_list,
                'default': default_device,
            },
        },
    },
}

================================================================================
FILE: ./modules/DiffusionPipeline/DiffusionPipeline.py
================================================================================

from config import config
from utils.hf_utils import list_local_models
from utils.torch_utils import device_list
from mellon.NodeBase import NodeBase
from diffusers import DiffusionPipeline
import torch

HF_TOKEN = config.hf['token']

class DiffusionPipelineLoader(NodeBase):
    def execute(self,
                model_id,
                online_status,
                dtype,
                offload_strategy,
                variant,
                revision,
                device,
                use_safetensors,
                ):
        
        is_local = model_id in list_local_models()
        local_files_only = online_status == 'Local files only' or (online_status == 'Connect if needed' and is_local)
        token = HF_TOKEN

        pipeline = DiffusionPipeline.from_pretrained(
            model_id,
            token=token,
            local_files_only=local_files_only,
            torch_dtype=dtype,
            use_safetensors=use_safetensors,
            revision=revision if revision else None,
            variant=variant if variant else None,
        )

        device = device_list[device]['device'] if device in device_list else 'cuda'

        if offload_strategy == 'Model offload (diffusers)':
            pipeline.enable_model_cpu_offload(device=device)
            device = None
        elif offload_strategy == 'Sequential offload (diffusers)':
            pipeline.enable_sequential_cpu_offload(device=device)
            device = None

        return { 'diffusion_pipeline': { 'pipeline': pipeline, 'device': device } }

class DiffusionPipelineSampler(NodeBase):
    def execute(
            self,
            diffusion_pipeline,
            seed,
            prompt,
            steps,
            cfg,
            width,
            height,
        ):
        pipeline = diffusion_pipeline['pipeline']
        device = diffusion_pipeline['device']

        if device:
            pipeline.to(device)

        generator = torch.Generator(device=device).manual_seed(seed)

        images = pipeline(
            prompt=prompt,
            num_inference_steps=steps,
            guidance_scale=cfg,
            width=width,
            height=height,
            generator=generator,
        )

        return { 'images': images[0] }





================================================================================
FILE: ./modules/DiffusionPipeline/__init__.py
================================================================================

from utils.torch_utils import device_list, default_device, str_to_dtype
from utils.hf_utils import list_local_models

MODULE_MAP = {
    'DiffusionPipelineLoader': {
        'label': 'Diffusion Pipeline Loader',
        'params': {
            'diffusion_pipeline': {
                'label': 'Pipeline',
                'display': 'output',
                'type': 'DiffusionPipeline',
            },
            'model_id': {
                'label': 'Model ID',
                'type': 'string',
                'options': list_local_models(),
                'display': 'autocomplete',
                'no_validation': True,
                'default': '',
            },
            'online_status': {
                'label': 'Online Status',
                'type': 'string',
                'options': [ 'Always online', 'Connect if needed', 'Local files only' ],
                'default': 'Connect if needed',
            },
            'dtype': {
                'label': 'Dtype',
                'type': 'string',
                'options': [ 'auto', 'float32', 'float16', 'bfloat16', 'float8_e4m3fn' ],
                'default': 'bfloat16',
                'postProcess': str_to_dtype,
            },
            'offload_strategy': {
                'label': 'Offload Strategy',
                'type': 'string',
                'options': [ 'None', 'Offload as needed (Mellon)', 'Model offload (Diffusers)', 'Sequential offload (Diffusers)' ],
                'default': 'Offload as needed (Mellon)',
            },
            'variant': {
                'label': 'Variant',
                'type': 'string',
                'default': '',
                'group': { 'key': 'more_options', 'label': 'More Options', 'display': 'collapse' },
            },
            'revision': {
                'label': 'Revision',
                'type': 'string',
                'default': '',
                'group': 'more_options',
            },
            'device': {
                'label': 'Device',
                'type': 'string',
                'options': device_list,
                'default': default_device,
                'group': 'more_options',
            },
            'use_safetensors': {
                'label': 'Use safetensors',
                'type': 'boolean',
                'default': False,
                'group': 'more_options',
            },
        },
    },

    'DiffusionPipelineSampler': {
        'label': 'Diffusion Pipeline Sampler',
        'params': {
            'diffusion_pipeline': {
                'label': 'Pipeline',
                'type': 'DiffusionPipeline',
                'display': 'input',
            },
            'seed': {
                'label': 'Seed',
                'type': 'int',
                'display': 'number',
                'default': 42,
                'min': 0,
                #'max': 2**32 - 1,
            },
            'width': {
                'label': 'Width',
                'type': 'int',
                'display': 'text',
                'default': 1024,
                'min': 8,
                'max': 8192,
                'step': 8,
                'group': 'dimensions',
            },
            'height': {
                'label': 'Height',
                'type': 'int',
                'display': 'text',
                'default': 1024,
                'min': 8,
                'max': 8192,
                'step': 8,
                'group': 'dimensions',
            },
            'resolution_picker': {
                'label': 'Resolution',
                'display': 'ui',
                'type': 'dropdownIcon',
                'options': [
                    { 'label': ' 720×1280 (9:16)', 'value': [720, 1280] },
                    { 'label': ' 768×1344 (0.57)', 'value': [768, 1344] },
                    { 'label': ' 768×1280 (3:5)', 'value': [768, 1280] },
                    { 'label': ' 832×1152 (3:4)', 'value': [832, 1152] },
                    { 'label': '1024×1024 (1:1)', 'value': [1024, 1024] },
                    { 'label': '  768×768 (1:1)', 'value': [768, 768] },
                    { 'label': '  512×512 (1:1)', 'value': [512, 512] },
                    { 'label': ' 1152×832 (4:3)', 'value': [1152, 832] },
                    { 'label': ' 1280×768 (5:3)', 'value': [1280, 768] },
                    { 'label': ' 1344×768 (1.75)', 'value': [1344, 768] },
                    { 'label': ' 1280×720 (16:9)', 'value': [1280, 720] },
                ],
                'onChange': { 'action': 'set', 'target': ['width', 'height'] },
                'group': 'dimensions',
            },
            'prompt': {
                'label': 'Prompt',
                'type': 'string',
                'display': 'textarea',
            },
            'steps': {
                'label': 'Steps',
                'type': 'int',
                'default': 25,
                'min': 1,
                'max': 1000,
            },
            'cfg': {
                'label': 'CFG',
                'type': 'float',
                'default': 7.0,
                'min': 0,
                'max': 100,
                'step': 0.1,
            },
            'images': {
                'label': 'Images',
                'type': 'image',
                'display': 'output',
            },
        },
    },
}


================================================================================
FILE: ./modules/BasicImage/BasicImage.py
================================================================================

from PIL import Image
import torch
from utils.torch_utils import toTensor, toPIL
from mellon.NodeBase import NodeBase
from modules.VAE.VAE import VAEDecode

class Preview(VAEDecode):
    def execute(self, images, vae, device):
        if isinstance(images, torch.Tensor):
            if not vae:
                raise ValueError("VAE is required to decode latents")

            if hasattr(vae, 'vae'):
                vae = vae.vae

            self.mm_load(vae, device)
            images = self.mm_inference(
                lambda: self.vae_decode(vae, images),
                device,
                exclude=vae,
            )

        if not isinstance(images, list):
            images = [images]

        return {
            'images_out': images,
            'width': images[0].width,
            'height': images[0].height
        }


class LoadImage(NodeBase):
    def execute(self, path):
        return { 'images': Image.open(path) }


class SaveImage(NodeBase):
    def execute(self, images: list):
        # save all the images in the list
        for i, image in enumerate(images):
            image.save(f"image_{i}.webp")

        return

class Resize(NodeBase):
    def execute(self, images, width, height, method, resample):
        if width == 0 and height == 0:
            return { 'images_out': images, 'width': ow, 'height': oh }

        resample = resample.upper()
        if method == 'stretch':
            images = images.resize((max(width, 1), max(height, 1)), resample=Image.Resampling[resample])
        elif method == 'fit':
            from PIL.ImageOps import fit
            images = fit(images, (max(width, 1), max(height, 1)), method=Image.Resampling[resample])
        elif method == 'pad':
            from PIL.ImageOps import pad
            images = pad(images, (max(width, 1), max(height, 1)), Image.Resampling[resample])
        elif method == 'keep aspect ratio':
            ow, oh = images.size
            print(f"Original size: {ow}x{oh}")
            if width == 0:
                scale = height / oh
                width = int(ow * scale)
            elif height == 0:
                scale = width / ow
                height = int(oh * scale)
            else:
                scale = min(width / ow, height / oh)
                new_width = int(ow * scale)
                new_height = int(oh * scale)
                # prevent rounding errors
                if height / oh < width / ow:
                    new_height = height
                elif width / ow < height / oh:
                    new_width = width

            images = images.resize((max(new_width, 1), max(new_height, 1)), resample=Image.Resampling[resample])

        return { 'images_out': images,
                 'width': images.width,
                 'height': images.height }

class ScaleBy(NodeBase):
    def execute(self, images, factor, resample):
        images = images.resize((max(int(images.width * factor), 1), max(int(images.height * factor), 1)), resample=Image.Resampling[resample.upper()])
        return { 'images_out': images,
                 'width': images.width,
                 'height': images.height }

class ResizeToDivisible(NodeBase):
    def execute(self, images, divisible_by):
        from PIL.ImageOps import fit
        divisible_by = int(max(1, divisible_by))
        width, height = images.size
        width = width // divisible_by * divisible_by
        height = height // divisible_by * divisible_by
        images = fit(images, (width, height), method=Image.Resampling.LANCZOS)
        return { 'images_out': images,
                 'width': width,
                 'height': height }

# NOT implemented
class BlendImages(NodeBase):
    def execute(self, source: Image.Image, target: Image.Image, amount: float):
        source = toTensor(source)
        target = toTensor(target)
        blend = source * amount + target * (1 - amount)
        blend = toPIL(blend)

        return { 'blend': blend }


================================================================================
FILE: ./modules/BasicImage/__init__.py
================================================================================

from utils.torch_utils import device_list, default_device

MODULE_MAP = {
    'Preview': {
        'label': 'Preview Image',
        'description': 'Preview an image',
        'category': 'image',
        'params': {
            'vae': {
                'label': 'VAE | Pipeline',
                'display': 'input',
                'type': ['pipeline', 'vae'],
                'description': 'VAE to decode latents. Required only if input images are latents.',
            },
            'images': {
                'label': 'Images | Latents',
                'display': 'input',
                'type': ['image', 'latent'],
            },
            'images_out': {
                'label': 'Images',
                'display': 'output',
                'type': 'image',
            },
            'width': {
                'label': 'Width',
                'type': 'int',
                'display': 'output',
            },
            'height': {
                'label': 'Height',
                'type': 'int',
                'display': 'output',
            },
            'preview': {
                'label': 'Preview',
                'display': 'ui',
                'source': 'images_out',
                'type': 'image',
            },
            'device': {
                'label': 'Device',
                'type': 'string',
                'options': device_list,
                'default': default_device,
            },
        },
    },

    'SaveImage': {
        'label': 'Save Image',
        'description': 'Save an image',
        'category': 'image',
        'params': {
            'images': {
                'label': 'Images',
                'display': 'input',
                'type': 'image',
            },
        },
    },

    'LoadImage': {
        'label': 'Load Image',
        'description': 'Load an image from path',
        'category': 'image',
        'params': {
            'path': {
                'label': 'Path',
                'type': 'string',
            },
            'images': {
                'label': 'Image',
                'display': 'output',
                'type': 'image',
            },
        },
    },

    'ResizeToDivisible': {
        'label': 'Resize to Divisible',
        'description': 'Resize an image to be divisible by a given number',
        'category': 'image',
        'style': {
            'maxWidth': 300,
        },
        'params': {
            'images': {
                'label': 'Images',
                'display': 'input',
                'type': 'image',
            },
            'images_out': {
                'label': 'Images',
                'display': 'output',
                'type': 'image',
            },
            'width': {
                'label': 'Width',
                'display': 'output',
                'type': 'int',
            },
            'height': {
                'label': 'Height',
                'display': 'output',
                'type': 'int',
            },
            'divisible_by': {
                'label': 'Divisible By',
                'type': 'int',
                'default': 8,
                'min': 1
            },
        },
    },

    'Resize': {
        'label': 'Resize',
        'description': 'Resize an image',
        'category': 'image',
        'params': {
            'images': {
                'label': 'Images',
                'display': 'input',
                'type': 'image',
            },
            'images_out': {
                'label': 'Images',
                'display': 'output',
                'type': 'image',
            },
            'new_width': {
                'label': 'Width',
                'display': 'output',
                'type': 'int',
            },
            'new_height': {
                'label': 'Height',
                'display': 'output',
                'type': 'int',
            },
            'width': {
                'label': 'Width',
                'type': 'int',
                'default': 1024,
                'min': 0,
            },
            'height': {
                'label': 'Height',
                'type': 'int',
                'default': 1024,
                'min': 0,
            },
            'method': {
                'label': 'Method',
                'type': 'string',
                'options': ['stretch', 'keep aspect ratio', 'fit', 'pad'],
                'default': 'stretch',
            },
            'resample': {
                'label': 'Resample',
                'type': 'string',
                'options': ['nearest', 'box', 'bilinear', 'hamming', 'bicubic', 'lanczos'],
                'default': 'bicubic',
            },
        },
    },

    'ScaleBy': {
        'label': 'Scale By',
        'description': 'Scale an image by a given factor',
        'category': 'image',
        'style': {
            'maxWidth': 300,
        },
        'params': {
            'images': {
                'label': 'Images',
                'display': 'input',
                'type': 'image',
            },
            'images_out': {
                'label': 'Images',
                'display': 'output',
                'type': 'image',
            },
            'factor': {
                'label': 'Factor',
                'type': 'float',
                'default': 1.0,
                'min': 0,
                'max': 32,
                'step': 0.05,
            },
            'resample': {
                'label': 'Resample',
                'type': 'string',
                'options': ['nearest', 'box', 'bilinear', 'hamming', 'bicubic', 'lanczos'],
                'default': 'bicubic',
            },
        },
    },

    'BlendImages': {
        'label': 'Blend Images',
        'description': 'Blend two images',
        'category': 'image',
        'params': {
            'source': {
                'label': 'Source',
                'display': 'input',
                'type': 'image',
            },
            'target': {
                'label': 'Target',
                'display': 'input',
                'type': 'image',
            },
            'amount': {
                'label': 'Amount',
                'type': 'float',
                'display': 'slider',
                'default': 0.5,
                'min': 0,
                'max': 1,
            },
            'blend': {
                'label': 'Blend',
                'display': 'output',
                'type': 'image',
            },
        },
    },
}


================================================================================
FILE: ./modules/SigLIP/SigLIP.py
================================================================================


from mellon.NodeBase import NodeBase
from transformers import AutoProcessor, SiglipVisionModel

class SigLIPLoader(NodeBase):
    def execute(self, model_id, dtype, device):
        model = SiglipVisionModel.from_pretrained(model_id, torch_dtype=dtype)
        processor = AutoProcessor.from_pretrained(model_id)

        model.eval() # TODO: is this necessary? I don't see it used anywhere but the guys at InstantX do it

        return { 'siglip_encoders': { 'processor': processor, 'model': model, 'device': device } }


================================================================================
FILE: ./modules/SigLIP/__init__.py
================================================================================

from utils.torch_utils import device_list, default_device

MODULE_MAP = {
    'SigLIPLoader': {
        'label': 'SigLIP Model Loader',
        'description': 'Load the SigLIP model',
        'params': {
            'siglip_encoders': {
                'label': 'SigLIP Encoders',
                'display': 'output',
                'type': 'SigLIPEncoders',
            },
            'model_id': {
                'label': 'Model ID',
                'type': 'string',
                'default': 'google/siglip-so400m-patch14-384',
            },
            'dtype': {
                'label': 'Dtype',
                'type': 'string',
                'options': [ 'auto', 'float32', 'float16', 'bfloat16', 'float8_e4m3fn' ],
                'default': 'auto',
            },
            'device': {
                'label': 'Device',
                'type': 'string',
                'options': device_list,
                'default': default_device,
            },
        },
    },
}


================================================================================
FILE: ./modules/ModularDiffusers/ModularDiffusers.py
================================================================================

from mellon.NodeBase import NodeBase
from utils.diffusers_utils import get_clip_prompt_embeds

from diffusers import (
    ControlNetModel,
    StableDiffusionXLModularPipeline,
    StableDiffusionXLPipeline,
)
from diffusers.pipelines.modular_pipeline_builder import SequentialPipelineBlocks
from diffusers.pipelines.stable_diffusion_xl.pipeline_stable_diffusion_xl_modular import (
    StableDiffusionXLAutoDenoiseStep,
    StableDiffusionXLAutoPrepareAdditionalConditioningStep,
    StableDiffusionXLAutoPrepareLatentsStep,
    StableDiffusionXLAutoSetTimestepsStep,
    StableDiffusionXLDecodeLatentsStep,
    StableDiffusionXLInputStep,
    StableDiffusionXLTextEncoderStep,
    StableDiffusionXLVAEEncoderStep,
)

import torch

class PipelineLoader(NodeBase):
    def execute(self, model_id, variant, dtype):
        pipeline = StableDiffusionXLPipeline.from_pretrained(
            model_id, variant=variant, torch_dtype=dtype
        )
        return {
            "pipeline": {
                "pipeline": pipeline,
                "unet": self.mm_add(pipeline.unet, priority=3),
                "text_encoder": self.mm_add(pipeline.text_encoder, priority=2),
                "text_encoder_2": self.mm_add(pipeline.text_encoder_2, priority=2),
                "vae": self.mm_add(pipeline.vae, priority=3),
            }
            # "unet": pipeline.unet,
            # "text_encoders": {
            #     "text_encoder": pipeline.text_encoder,
            #     "text_encoder_2": pipeline.text_encoder_2,
            #     "tokenizer": pipeline.tokenizer,
            #     "tokenizer_2": pipeline.tokenizer_2,
            # },
            # "vae": pipeline.vae,
            # "scheduler": pipeline.scheduler,
        }

class EncodePrompts(NodeBase):
    def execute(self, models, positive_prompt, negative_prompt, device):
        if not 'pipeline' in models and not 'text_encoder' in models:
            raise ValueError("No pipeline or text_encoders found in models")

        text_encoder = models['text_encoder'] if 'text_encoder' in models else models['pipeline'].text_encoder
        text_encoder_2 = models['text_encoder_2'] if 'text_encoder_2' in models else models['pipeline'].text_encoder_2
        tokenizer = models['tokenizer'] if 'tokenizer' in models else models['pipeline'].tokenizer
        tokenizer_2 = models['tokenizer_2'] if 'tokenizer_2' in models else models['pipeline'].tokenizer_2

        def encode(positive_prompt, negative_prompt, text_encoder, tokenizer, device, clip_skip=None, noise=0.0):
            text_encoder = self.mm_get(text_encoder).to(device)
            prompt_embeds, pooled_prompt_embeds = get_clip_prompt_embeds(positive_prompt, tokenizer, text_encoder, clip_skip=clip_skip, noise=noise)
            negative_prompt_embeds, negative_pooled_prompt_embeds = get_clip_prompt_embeds(negative_prompt, tokenizer, text_encoder, clip_skip=clip_skip, noise=noise)
            return (prompt_embeds, negative_prompt_embeds, pooled_prompt_embeds, negative_pooled_prompt_embeds)

        prompt_embeds, negative_prompt_embeds, _, _ = self.mm_try(
            lambda: encode(positive_prompt, negative_prompt, text_encoder, tokenizer, device),
            device,
            exclude=text_encoder
        )

        prompt_embeds_2, negative_prompt_embeds_2, pooled_prompt_embeds_2, negative_pooled_prompt_embeds_2 = self.mm_try(
            lambda: encode(positive_prompt, negative_prompt, text_encoder_2, tokenizer_2, device),
            device,
            exclude=text_encoder_2
        )
        
        prompt_embeds = torch.cat([prompt_embeds, prompt_embeds_2], dim=-1).to('cpu')
        negative_prompt_embeds = torch.cat([negative_prompt_embeds, negative_prompt_embeds_2], dim=-1).to('cpu')
        pooled_prompt_embeds = pooled_prompt_embeds_2.to('cpu')
        negative_pooled_prompt_embeds = negative_pooled_prompt_embeds_2.to('cpu')
        del prompt_embeds_2, negative_prompt_embeds_2, pooled_prompt_embeds_2, negative_pooled_prompt_embeds_2

        if prompt_embeds.shape[1] > negative_prompt_embeds.shape[1]:
            negative_prompt_embeds = torch.nn.functional.pad(negative_prompt_embeds, (0, 0, 0, prompt_embeds.shape[1] - negative_prompt_embeds.shape[1]))
        elif prompt_embeds.shape[1] < negative_prompt_embeds.shape[1]:
            prompt_embeds = torch.nn.functional.pad(prompt_embeds, (0, 0, 0, negative_prompt_embeds.shape[1] - prompt_embeds.shape[1]))
        
        return {"embeddings": {
            "prompt_embeds": prompt_embeds,
            "negative_prompt_embeds": negative_prompt_embeds,
            "pooled_prompt_embeds": pooled_prompt_embeds,
            "negative_pooled_prompt_embeds": negative_pooled_prompt_embeds,
        }}

class DenoiseLoop(NodeBase):
    def execute(
        self,
        pipeline,
        scheduler,
        embeddings,
        steps,
        cfg,
        seed,
        height,
        width,
        strength,
        image_latents,
        guider,
        device,
    ):
        class StableDiffusionXLMainSteps(SequentialPipelineBlocks):
            block_classes = [
                StableDiffusionXLInputStep,
                StableDiffusionXLAutoSetTimestepsStep,
                StableDiffusionXLAutoPrepareLatentsStep,
                StableDiffusionXLAutoPrepareAdditionalConditioningStep,
                StableDiffusionXLAutoDenoiseStep,
            ]
            block_prefixes = [
                "input",
                "set_timesteps",
                "prepare_latents",
                "prepare_add_cond",
                "denoise",
            ]

        sdxl_workflow = StableDiffusionXLMainSteps()

        generator = torch.Generator(device="cuda").manual_seed(seed)
        pipeline = pipeline['pipeline']
        unet = pipeline.unet

        # Load the scheduler
        scheduler_cls = getattr(__import__('diffusers', fromlist=[scheduler]), scheduler)
        scheduler = scheduler_cls.from_config(pipeline.scheduler.config)

        modules_kwargs = {
            "unet": unet,
            "scheduler": scheduler,
        }

        embeddings["prompt_embeds"] = embeddings["prompt_embeds"].to(device)
        embeddings["negative_prompt_embeds"] = embeddings["negative_prompt_embeds"].to(device)
        embeddings["pooled_prompt_embeds"] = embeddings["pooled_prompt_embeds"].to(device)
        embeddings["negative_pooled_prompt_embeds"] = embeddings["negative_pooled_prompt_embeds"].to(device)

        denoise_kwargs = {
            **embeddings,
            "generator": generator,
            "guidance_scale": cfg,
            "height": height,
            "width": width,
        }

        if guider is not None:
            modules_kwargs["guider"] = guider["guider"]
            denoise_kwargs["guider_kwargs"] = {"pag_scale": guider["scale"]}

        sdxl_workflow.update_states(**modules_kwargs)
        sdxl_node = StableDiffusionXLModularPipeline()
        sdxl_node.add_blocks(sdxl_workflow)

        sdxl_node.to(device)

        if image_latents is not None:
            denoise_kwargs["image"] = image_latents
            denoise_kwargs["strength"] = strength
            denoise_kwargs["num_inference_steps"] = round(steps / strength)
        else:
            denoise_kwargs["num_inference_steps"] = steps

        state_text2img = sdxl_node.run_blocks(**denoise_kwargs)

        latents = state_text2img.get_intermediate("latents")

        sdxl_node.to('cpu')
        latents.to('cpu')

        embeddings["prompt_embeds"] = embeddings["prompt_embeds"].to('cpu')
        embeddings["negative_prompt_embeds"] = embeddings["negative_prompt_embeds"].to('cpu')
        embeddings["pooled_prompt_embeds"] = embeddings["pooled_prompt_embeds"].to('cpu')
        embeddings["negative_pooled_prompt_embeds"] = embeddings["negative_pooled_prompt_embeds"].to('cpu')

        return {"latents": latents}

================================================================================
FILE: ./modules/ModularDiffusers/__init__.py
================================================================================

from utils.hf_utils import list_local_models
from utils.torch_utils import default_device, device_list, str_to_dtype
import torch

MODULE_MAP = {
    "PipelineLoader": {
        "label": "Model Loader",
        "category": "Modular Diffusers",
        "params": {
            "model_id": {
                "label": "Model ID",
                "options": list_local_models(),
                "display": "autocomplete",
                "no_validation": True,
                "default": "stabilityai/stable-diffusion-xl-base-1.0",
            },
            "pipeline": {
                "label": "Pipeline",
                "display": "output",
                "type": "pipeline",
            },
            "variant": {
                "label": "Variant",
                "options": ["[unset]", "fp32", "fp16"],
                "postProcess": lambda variant, params: variant
                if variant != "[unset]"
                else None,
                "default": "fp16",
            },
            "dtype": {
                "label": "Dtype",
                "type": "string",
                "options": ["auto", "float32", "float16", "bfloat16"],
                "default": "bfloat16" if torch.cuda.is_available() and torch.cuda.is_bf16_supported() else "float16",
                "postProcess": str_to_dtype,
            },
            # "unet": {
            #     "label": "Unet",
            #     "display": "output",
            #     "type": "unet",
            # },
            # "text_encoders": {
            #     "label": "Text Encoders",
            #     "display": "output",
            #     "type": "text_encoders",
            # },
            # "vae": {
            #     "label": "Vae",
            #     "display": "output",
            #     "type": "vae",
            # },
            # "scheduler": {
            #     "label": "Scheduler",
            #     "display": "output",
            #     "type": "scheduler",
            # },
        },
    },
    "EncodePrompts": {
        "label": "Encode Prompts",
        "category": "Modular Diffusers",
        "params": {
            "models": {
                "label": "Pipeline | Text Encoders",
                "display": "input",
                "type": ["text_encoders", "pipeline"],
            },
            "embeddings": {
                "label": "Embeddings",
                "display": "output",
                "type": "prompt_embeddings",
            },
            "positive_prompt": {
                "label": "Positive Prompt",
                "type": "string",
                "display": "textarea",
            },
            "negative_prompt": {
                "label": "Negative Prompt",
                "type": "string",
                "display": "textarea",
            },
            "device": {
                "label": "Device",
                "type": "string",
                "options": device_list,
                "default": default_device,
            },
        },
    },

    "DenoiseLoop": {
        "label": "Denoise Loop",
        "category": "Modular Diffusers",
        "params": {
            "pipeline": {
                "label": "Pipeline",
                "display": "input",
                "type": ["pipeline", "unet"],
            },
            "embeddings": {
                "label": "Embeddings",
                "display": "input",
                "type": "prompt_embeddings",
            },
            "latents": {
                "label": "Latents",
                "type": "latent",
                "display": "output",
            },
            'scheduler': {
                'label': 'Scheduler',
                'display': 'select',
                'type': ['string', 'scheduler'],
                'options': {
                    'DDIMScheduler': 'DDIM',
                    'DDPMScheduler': 'DDPM',
                    'DEISMultistepScheduler': 'DEIS Multistep',
                    'DPMSolverSinglestepScheduler': 'DPMSolver Singlestep',
                    'DPMSolverMultistepScheduler': 'DPMSolver Multistep',
                    'DPMSolverSDEScheduler': 'DPMSolver SDE',
                    'EDMEulerScheduler': 'EDM Euler',
                    'EulerDiscreteScheduler': 'Euler Discrete',
                    'EulerAncestralDiscreteScheduler': 'Euler Ancestral',
                    'HeunDiscreteScheduler': 'Heun Discrete',
                    'KDPM2DiscreteScheduler': 'KDPM2 Discrete',
                    'KDPM2AncestralDiscreteScheduler': 'KDPM2 Ancestral',
                    'LMSDiscreteScheduler': 'LMS Discrete',
                    'PNDMScheduler': 'PNDM',
                    'UniPCMultistepScheduler': 'UniPC Multistep',
                },
                'default': 'EulerDiscreteScheduler',
            },
            "cfg": {
                "label": "Guidance",
                "type": "float",
                "display": "slider",
                "default": 7.0,
                "min": 0,
                "max": 20,
            },
            "steps": {
                "label": "Steps",
                "type": "int",
                "default": 25,
                "min": 1,
                "max": 1000,
            },
            "seed": {
                "label": "Seed",
                "type": "int",
                "default": 0,
                "min": 0,
                "display": "random",
            },
            "width": {
                "label": "Width",
                "type": "int",
                "display": "text",
                "default": 1024,
                "min": 8,
                "max": 8192,
                "step": 8,
                "group": "dimensions",
            },
            "height": {
                "label": "Height",
                "type": "int",
                "display": "text",
                "default": 1024,
                "min": 8,
                "max": 8192,
                "step": 8,
                "group": "dimensions",
            },
            "image_latents": {
                "label": "Image Latents",
                "display": "input",
                "type": "image_latents",
            },
            "strength": {
                "label": "Strength",
                "type": "float",
                "display": "slider",
                "default": 0.5,
                "min": 0,
                "max": 1,
            },
            "guider": {
                "label": "Optional Guider",
                "type": "guider",
                "display": "input",
            },
            "device": {
                "label": "Device",
                "type": "string",
                "options": device_list,
                "default": default_device,
            },
        },
    },
}


================================================================================
FILE: ./modules/StableDiffusion/StableDiffusion.py
================================================================================

import torch
from transformers import CLIPTextModel, CLIPTokenizer
from diffusers import StableDiffusionPipeline, UNet2DConditionModel, AutoencoderKL
from utils.torch_utils import device_list, toPIL
from mellon.NodeBase import NodeBase
from utils.hf_utils import is_local_files_only
from config import config

HF_TOKEN = config.hf['token']

class UnetLoader(NodeBase):
    def execute(self, model_id, dtype, device, **kwargs):
        local_files_only = is_local_files_only(model_id)
        
        model = UNet2DConditionModel.from_pretrained(
            model_id,
            torch_dtype=dtype,
            subfolder="unet",
            token=HF_TOKEN,
            local_files_only=local_files_only
        )

        mm_id = self.mm_add(model, priority=3)
        
        return { 'model': { 'unet': mm_id, 'device': device, 'model_id': model_id }}




























class LoadUNet(NodeBase):
    def execute(self, model_id, variant, dtype, use_safetensors, device):
        model = UNet2DConditionModel.from_pretrained(
            model_id,
            torch_dtype=dtype,
            variant=variant,
            use_safetensors=use_safetensors,
            subfolder="unet",
        )      
 
        return { 'unet': { 'model': model, 'device': device }}

class LoadTextEncoder(NodeBase):
    def execute(self, model_id, device):
        # This is a CLIP encoder helper specific to the Stable Diffusion pipeline, 
        # we assume the encoder to be clip-vit-large-patch14 otherwise we try to
        # load the models from the subfolder of the main model_id repository.

        text_encoder = CLIPTextModel.from_pretrained(model_id, subfolder="text_encoder" if not model_id.endswith("clip-vit-large-patch14") else '')
        tokenizer = CLIPTokenizer.from_pretrained(model_id, subfolder="tokenizer" if not model_id.endswith("clip-vit-large-patch14") else '')

        return { 'clip': { 'text_encoder': text_encoder, 'tokenizer': tokenizer, 'device': device } }

class TextEncoder(NodeBase):
    def execute(self, prompt, clip):
        device = clip['device']
        text_encoder = clip['text_encoder'].to(device)
        inputs = clip['tokenizer'](prompt, return_tensors="pt").input_ids.to(device)

        #with torch.no_grad(): which one!?
        with torch.inference_mode():
            text_embeddings = text_encoder(inputs).last_hidden_state

        # clean up
        clip['text_encoder'] = clip['text_encoder'].to('cpu')
        inputs = inputs.to('cpu')
        inputs = None

        return { 'embeds': text_embeddings.cpu() }

class SDSampler(NodeBase):
    def execute(self, unet, positive, negative, seed, latents_in, width, height, steps, cfg):
        # TODO: add support for latents_in

        model_id = unet['model'].config['_name_or_path']
        device = unet['device']

        dummy_vae = AutoencoderKL(
            in_channels=3,
            out_channels=3,
            down_block_types=['DownEncoderBlock2D', 'DownEncoderBlock2D', 'DownEncoderBlock2D', 'DownEncoderBlock2D'],
            up_block_types=['UpDecoderBlock2D', 'UpDecoderBlock2D', 'UpDecoderBlock2D', 'UpDecoderBlock2D'],
            block_out_channels=[128, 256, 512, 512],
            layers_per_block=2,
            latent_channels=4,
        ) # TODO: do we need any more (or less) values for a dummy vae?

        # TODO: does this really load only the config?
        pipe = StableDiffusionPipeline.from_pretrained(
            model_id,
            unet=unet['model'],
            text_encoder=None,
            tokenizer=None,
            vae=dummy_vae
        ).to(device)

        #latents_in = latents_in.to(unet['device'])

        # Pad embeddings to same length
        # TODO: am I doing this right? should we pad to maximum length?
        if negative is not None and positive.shape[1] != negative.shape[1]:
            max_length = max(positive.shape[1], negative.shape[1])
            if positive.shape[1] < max_length:
                positive = torch.nn.functional.pad(positive, (0, 0, 0, max_length - positive.shape[1]))
            else:
                negative = torch.nn.functional.pad(negative, (0, 0, 0, max_length - negative.shape[1]))

        #with torch.no_grad():
        with torch.inference_mode():
            latents = pipe(
                generator=torch.Generator(device=device).manual_seed(seed),
                prompt_embeds=positive.to(device),
                negative_prompt_embeds=negative.to(device) if negative is not None else None,
                #latents=latents_in,
                width=width,
                height=height,
                guidance_scale=cfg,
                num_inference_steps=steps,
                output_type="latent",
            ).images

        #pipe = pipe.to('cpu')
        latents = latents.to('cpu')
        del pipe, positive, negative

        return { 'latents': latents }


================================================================================
FILE: ./modules/StableDiffusion/__init__.py
================================================================================

from utils.hf_utils import list_local_models
from utils.torch_utils import device_list, default_device, str_to_dtype

list_local_models()

MODULE_MAP = {
    'UnetLoader': {
        'label': 'UNet Loader',
        'description': 'Load the UNet of a Stable Diffusion model',
        'category': 'samplers',
        'params': {
            'model': {
                'label': 'UNet',
                'type': 'UNet2DConditionModel',
                'display': 'output',
            },
            'model_id': {
                'label': 'Model ID',
                'type': 'string',
                'options': list_local_models(filters={'_class_name': r"StableDiffusionPipeline" }),
                'display': 'autocomplete',
                'no_validation': True,
                #'default': 'stabilityai/stable-diffusion-3.5-large',
            },
            'dtype': {
                'label': 'dtype',
                'options': ['auto', 'float32', 'float16', 'bfloat16'],
                'default': 'bfloat16',
                'postProcess': str_to_dtype,
            },
            'device': {
                'label': 'Device',
                'type': 'string',
                'options': device_list,
                'default': default_device,
            },
        },
    }
}

================================================================================
FILE: ./modules/VAE/VAE.py
================================================================================

import torch
from diffusers import AutoencoderKL
from mellon.NodeBase import NodeBase
from utils.hf_utils import is_local_files_only
from utils.torch_utils import toPIL, toLatent
from diffusers.models.attention_processor import AttnProcessor2_0, XFormersAttnProcessor

class LoadVAE(NodeBase):
    #is_compiled = False
    
    def execute(self, model_id):
        #if not compile and self.is_compiled:
        #    self.mm_unload(vae)

        vae = AutoencoderKL.from_pretrained(
            model_id, 
            subfolder="vae", 
            local_files_only=is_local_files_only(model_id),
        )

        vae._mm_id = self.mm_add(vae, priority=2)

        """
        if compile:
            # we free up all the GPU memory to perform the intensive compilation
            memory_manager.unload_all(exclude=vae)

            torch._inductor.config.conv_1x1_as_mm = True
            torch._inductor.config.coordinate_descent_tuning = True
            torch._inductor.config.epilogue_fusion = False
            torch._inductor.config.coordinate_descent_check_all_directions = True

            compiled = self.mm_load(vae, device=device).to(memory_format=torch.channels_last)
            compiled.decode = torch.compile(compiled.decode, mode='max-autotune', fullgraph=True)
            self.mm_update(vae, model=compiled)
            del compiled
            memory_flush(rest=True)
            self.is_compiled = True
        """

        return { 'model': vae }

class VAEEncode(NodeBase):
    def execute(self, model, images, divisible_by, device):
        vae = model.vae if hasattr(model, 'vae') else model
        if divisible_by > 1:
            from modules.BasicImage.BasicImage import ResizeToDivisible
            images = ResizeToDivisible()(images=images, divisible_by=divisible_by)['images_out']
        
        self.mm_load(vae, device)
        latents = self.mm_inference(
            lambda: self.encode(vae, images),
            device,
            exclude=vae
        )
        latents = latents.to('cpu')
        return { 'latents': latents }
    
    def encode(self, model, images):
        images = toLatent(images).to(model.device, dtype=model.dtype)
        latents = model.encode(images).latent_dist.sample()
        latents = latents * model.config.scaling_factor
        return latents

class VAEDecode(NodeBase):
    def execute(self, model, latents, device):
        vae = model.vae if hasattr(model, 'vae') else model
        self.mm_load(vae, device)
        images = self.mm_inference(
            lambda: self.vae_decode(vae, latents),
            device,
            exclude=vae
        )

        return { 'images': images }
    
    def vae_decode(self, model, latents):
        dtype = model.dtype
        
        if dtype == torch.float16 and model.config.force_upcast:
            self.upcast_vae(model)

        if hasattr(model, 'post_quant_conv') and hasattr(model.post_quant_conv, 'parameters'):
            latents = latents.to(dtype=next(iter(model.post_quant_conv.parameters())).dtype)
        else:
            latents = latents.to(dtype=model.dtype)

        latents = 1 / model.config['scaling_factor'] * latents
        images = model.decode(latents.to(model.device), return_dict=False)[0]
        del latents, model
        images = images / 2 + 0.5
        images = toPIL(images.to('cpu'))
        return images
    
    def upcast_vae(self, model):
        dtype = model.dtype
        if torch.cuda.is_available() and torch.cuda.is_bf16_supported():
            new_dtype = torch.bfloat16
        else:
            new_dtype = torch.float32

        model.to(dtype=new_dtype)
        use_torch_2_0_or_xformers = isinstance(
            model.decoder.mid_block.attentions[0].processor,
            (
                AttnProcessor2_0,
                XFormersAttnProcessor,
            ),
        )
        # if xformers or torch_2_0 is used attention block does not need
        # to be in float32 which can save lots of memory
        if use_torch_2_0_or_xformers:
            model.post_quant_conv.to(dtype)
            model.decoder.conv_in.to(dtype)
            model.decoder.mid_block.to(dtype)


================================================================================
FILE: ./modules/VAE/__init__.py
================================================================================

from utils.torch_utils import device_list, default_device
from utils.hf_utils import list_local_models
MODULE_MAP = {
    'LoadVAE': {
        'label': 'VAE Loader',
        'description': 'Load the VAE of a Stable Diffusion model',
        'category': 'vae',
        'params': {
            'model': {
                'label': 'VAE',
                'display': 'output',
                'type': 'vae',
            },
            'model_id': {
                'label': 'Model ID',
                'type': 'string',
                'options': list_local_models(),
                'display': 'autocomplete',
                'no_validation': True,
            },
        },
    },
    'VAEEncode': {
        'label': 'VAE Encode',
        'description': 'Encode an image into the latent space',
        'category': 'vae',
        'style': {
            'maxWidth': 300,
        },
        'params': {
            'model': {
                'label': 'VAE | Pipeline',
                'type': ['vae', 'pipeline'],
                'display': 'input',
            },
            'images': {
                'label': 'Images',
                'type': 'image',
                'display': 'input',
            },
            'latents': {
                'label': 'Latents',
                'type': 'latent',
                'display': 'output',
            },
            'divisible_by': {
                'label': 'Divisible By',
                'type': 'int',
                'default': 8,
                'display': 'slider',
                'min': 1,
            },
            'device': {
                'label': 'Device',
                'type': 'string',
                'options': device_list,
                'default': default_device,
            },
        },
    },
    'VAEDecode': {
        'label': 'VAE Decode',
        'description': 'Decode a latent space into an image',
        'category': 'vae',
        'params': {
            'model': {
                'label': 'VAE | Pipeline',
                'type': ['vae', 'pipeline'],
                'display': 'input',
            },
            'latents': {
                'label': 'Latents',
                'type': 'latent',
                'display': 'input',
            },
            'images': {
                'label': 'Images',
                'type': 'image',
                'display': 'output',
            },
            'device': {
                'label': 'Device',
                'type': 'string',
                'options': device_list,
                'default': default_device,
            },
        },
    },
}


================================================================================
FILE: ./custom/__init__.py
================================================================================



================================================================================
FILE: ./custom/HelloWorld/__init__.py
================================================================================

from utils.torch_utils import device_list, default_device, str_to_dtype
from utils.hf_utils import list_local_models

MODULE_MAP = {
    'HelloWorldAgain': {
        'label': 'HelloWorld',
        'category': 'HelloWorld',
        'type': 'tool',
        'params': {
            'color': {
                'label': 'Color',
                'display': 'color',                
            },
            'pipeline': {
                'label': 'Color',
                'type': 'pipeline',
                'display': 'output',
            },
        }
    }
}

================================================================================
FILE: ./client/LICENSE
================================================================================

                                 Apache License
                           Version 2.0, January 2004
                        http://www.apache.org/licenses/

   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION

   1. Definitions.

      "License" shall mean the terms and conditions for use, reproduction,
      and distribution as defined by Sections 1 through 9 of this document.

      "Licensor" shall mean the copyright owner or entity authorized by
      the copyright owner that is granting the License.

      "Legal Entity" shall mean the union of the acting entity and all
      other entities that control, are controlled by, or are under common
      control with that entity. For the purposes of this definition,
      "control" means (i) the power, direct or indirect, to cause the
      direction or management of such entity, whether by contract or
      otherwise, or (ii) ownership of fifty percent (50%) or more of the
      outstanding shares, or (iii) beneficial ownership of such entity.

      "You" (or "Your") shall mean an individual or Legal Entity
      exercising permissions granted by this License.

      "Source" form shall mean the preferred form for making modifications,
      including but not limited to software source code, documentation
      source, and configuration files.

      "Object" form shall mean any form resulting from mechanical
      transformation or translation of a Source form, including but
      not limited to compiled object code, generated documentation,
      and conversions to other media types.

      "Work" shall mean the work of authorship, whether in Source or
      Object form, made available under the License, as indicated by a
      copyright notice that is included in or attached to the work
      (an example is provided in the Appendix below).

      "Derivative Works" shall mean any work, whether in Source or Object
      form, that is based on (or derived from) the Work and for which the
      editorial revisions, annotations, elaborations, or other modifications
      represent, as a whole, an original work of authorship. For the purposes
      of this License, Derivative Works shall not include works that remain
      separable from, or merely link (or bind by name) to the interfaces of,
      the Work and Derivative Works thereof.

      "Contribution" shall mean any work of authorship, including
      the original version of the Work and any modifications or additions
      to that Work or Derivative Works thereof, that is intentionally
      submitted to Licensor for inclusion in the Work by the copyright owner
      or by an individual or Legal Entity authorized to submit on behalf of
      the copyright owner. For the purposes of this definition, "submitted"
      means any form of electronic, verbal, or written communication sent
      to the Licensor or its representatives, including but not limited to
      communication on electronic mailing lists, source code control systems,
      and issue tracking systems that are managed by, or on behalf of, the
      Licensor for the purpose of discussing and improving the Work, but
      excluding communication that is conspicuously marked or otherwise
      designated in writing by the copyright owner as "Not a Contribution."

      "Contributor" shall mean Licensor and any individual or Legal Entity
      on behalf of whom a Contribution has been received by Licensor and
      subsequently incorporated within the Work.

   2. Grant of Copyright License. Subject to the terms and conditions of
      this License, each Contributor hereby grants to You a perpetual,
      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
      copyright license to reproduce, prepare Derivative Works of,
      publicly display, publicly perform, sublicense, and distribute the
      Work and such Derivative Works in Source or Object form.

   3. Grant of Patent License. Subject to the terms and conditions of
      this License, each Contributor hereby grants to You a perpetual,
      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
      (except as stated in this section) patent license to make, have made,
      use, offer to sell, sell, import, and otherwise transfer the Work,
      where such license applies only to those patent claims licensable
      by such Contributor that are necessarily infringed by their
      Contribution(s) alone or by combination of their Contribution(s)
      with the Work to which such Contribution(s) was submitted. If You
      institute patent litigation against any entity (including a
      cross-claim or counterclaim in a lawsuit) alleging that the Work
      or a Contribution incorporated within the Work constitutes direct
      or contributory patent infringement, then any patent licenses
      granted to You under this License for that Work shall terminate
      as of the date such litigation is filed.

   4. Redistribution. You may reproduce and distribute copies of the
      Work or Derivative Works thereof in any medium, with or without
      modifications, and in Source or Object form, provided that You
      meet the following conditions:

      (a) You must give any other recipients of the Work or
          Derivative Works a copy of this License; and

      (b) You must cause any modified files to carry prominent notices
          stating that You changed the files; and

      (c) You must retain, in the Source form of any Derivative Works
          that You distribute, all copyright, patent, trademark, and
          attribution notices from the Source form of the Work,
          excluding those notices that do not pertain to any part of
          the Derivative Works; and

      (d) If the Work includes a "NOTICE" text file as part of its
          distribution, then any Derivative Works that You distribute must
          include a readable copy of the attribution notices contained
          within such NOTICE file, excluding those notices that do not
          pertain to any part of the Derivative Works, in at least one
          of the following places: within a NOTICE text file distributed
          as part of the Derivative Works; within the Source form or
          documentation, if provided along with the Derivative Works; or,
          within a display generated by the Derivative Works, if and
          wherever such third-party notices normally appear. The contents
          of the NOTICE file are for informational purposes only and
          do not modify the License. You may add Your own attribution
          notices within Derivative Works that You distribute, alongside
          or as an addendum to the NOTICE text from the Work, provided
          that such additional attribution notices cannot be construed
          as modifying the License.

      You may add Your own copyright statement to Your modifications and
      may provide additional or different license terms and conditions
      for use, reproduction, or distribution of Your modifications, or
      for any such Derivative Works as a whole, provided Your use,
      reproduction, and distribution of the Work otherwise complies with
      the conditions stated in this License.

   5. Submission of Contributions. Unless You explicitly state otherwise,
      any Contribution intentionally submitted for inclusion in the Work
      by You to the Licensor shall be under the terms and conditions of
      this License, without any additional terms or conditions.
      Notwithstanding the above, nothing herein shall supersede or modify
      the terms of any separate license agreement you may have executed
      with Licensor regarding such Contributions.

   6. Trademarks. This License does not grant permission to use the trade
      names, trademarks, service marks, or product names of the Licensor,
      except as required for reasonable and customary use in describing the
      origin of the Work and reproducing the content of the NOTICE file.

   7. Disclaimer of Warranty. Unless required by applicable law or
      agreed to in writing, Licensor provides the Work (and each
      Contributor provides its Contributions) on an "AS IS" BASIS,
      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
      implied, including, without limitation, any warranties or conditions
      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
      PARTICULAR PURPOSE. You are solely responsible for determining the
      appropriateness of using or redistributing the Work and assume any
      risks associated with Your exercise of permissions under this License.

   8. Limitation of Liability. In no event and under no legal theory,
      whether in tort (including negligence), contract, or otherwise,
      unless required by applicable law (such as deliberate and grossly
      negligent acts) or agreed to in writing, shall any Contributor be
      liable to You for damages, including any direct, indirect, special,
      incidental, or consequential damages of any character arising as a
      result of this License or out of the use or inability to use the
      Work (including but not limited to damages for loss of goodwill,
      work stoppage, computer failure or malfunction, or any and all
      other commercial damages or losses), even if such Contributor
      has been advised of the possibility of such damages.

   9. Accepting Warranty or Additional Liability. While redistributing
      the Work or Derivative Works thereof, You may choose to offer,
      and charge a fee for, acceptance of support, warranty, indemnity,
      or other liability obligations and/or rights consistent with this
      License. However, in accepting such obligations, You may act only
      on Your own behalf and on Your sole responsibility, not on behalf
      of any other Contributor, and only if You agree to indemnify,
      defend, and hold each Contributor harmless for any liability
      incurred by, or claims asserted against, such Contributor by reason
      of your accepting any such warranty or additional liability.

   END OF TERMS AND CONDITIONS

   APPENDIX: How to apply the Apache License to your work.

      To apply the Apache License to your work, attach the following
      boilerplate notice, with the fields enclosed by brackets "[]"
      replaced with your own identifying information. (Don't include
      the brackets!)  The text should be enclosed in the appropriate
      comment syntax for the file format. We also recommend that a
      file or class name and description of purpose be included on the
      same "printed page" as the copyright notice for easier
      identification within third-party archives.

   Copyright [yyyy] [name of copyright owner]

   Licensed under the Apache License, Version 2.0 (the "License");
   you may not use this file except in compliance with the License.
   You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.


================================================================================
FILE: ./client/README.md
================================================================================

# Mellon Client

This is the development client for the [Mellon](https://github.com/cubiq/Mellon) engine. It is built with [ReactFlow](https://reactflow.dev/), [Typescript](https://www.typescriptlang.org/), [Vite](https://vitejs.dev/) and [MUI](https://mui.com/).

> [!CAUTION]
> This is mostly a proof of concept and not a production ready application. **DO NOT USE** unless you know what you are doing. Things will change often.

## Install

```bash
git clone https://github.com/cubiq/Mellon-client.git
cd Mellon-client
npm install
```

Then create a `.env.development` file and put the server address in it, like so (change the address/port if needed):

```
VITE_SERVER_ADDRESS=127.0.0.1:8080
```

Rename `vite.config.example.ts` to `vite.config.ts` and customize it if needed. For example if your vite installation is on a remote host you could add a `server` section:

```
  server: {
    hmr: true,
    watch: {
      usePolling: true,
    },
    host: '0.0.0.0',
    port: 5173,
    strictPort: true,
  },
```

Then you can start the development server with:

```bash
npm run dev
```

When done you need to run `npm run build` and copy the compiled directory into the `web` folder of [Mellon](https://github.com/cubiq/Mellon) server.

## Contact

I'm not a React, Typescript, ReactFlow or MUI expert (first time using all of them together). I just hacked this together. Any help would be appreciated.

At this stage the best way to contact me regarding the project is via [X/Twitter](https://x.com/cubiq) or [discord](https://latent.vision/discord).

================================================================================
FILE: ./client/config.ts
================================================================================

const config = {
  serverAddress: import.meta.env.VITE_SERVER_ADDRESS || window.location.origin.split('://')[1],
};

export default config;


================================================================================
FILE: ./client/eslint.config.js
================================================================================

import js from '@eslint/js'
import globals from 'globals'
import reactHooks from 'eslint-plugin-react-hooks'
import reactRefresh from 'eslint-plugin-react-refresh'
import tseslint from 'typescript-eslint'

export default tseslint.config(
  { ignores: ['dist'] },
  {
    extends: [js.configs.recommended, ...tseslint.configs.recommended],
    files: ['**/*.{ts,tsx}'],
    languageOptions: {
      ecmaVersion: 2020,
      globals: globals.browser,
    },
    plugins: {
      'react-hooks': reactHooks,
      'react-refresh': reactRefresh,
    },
    rules: {
      ...reactHooks.configs.recommended.rules,
      'react-refresh/only-export-components': [
        'warn',
        { allowConstantExport: true },
      ],
    },
  },
)


================================================================================
FILE: ./client/index.html
================================================================================

<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <link rel="icon" type="image/svg+xml" href="/assets/mellon.svg" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Mellon</title>
  </head>
  <body>
    <div id="root"></div>
    <script type="module" src="/src/main.tsx"></script>
  </body>
</html>


================================================================================
FILE: ./client/tsconfig.app.tsbuildinfo
================================================================================

{"root":["./src/App.tsx","./src/main.tsx","./src/vite-env.d.ts","./src/components/ActionBar.tsx","./src/components/CustomNode.tsx","./src/components/CustomNumberInput.tsx","./src/components/NodeContent.tsx","./src/components/ToolBar.tsx","./src/components/WebsocketContext.tsx","./src/components/fields/AccordionField.tsx","./src/components/fields/AutocompleteField.tsx","./src/components/fields/CustomField.tsx","./src/components/fields/GroupField.tsx","./src/components/fields/HandleField.tsx","./src/components/fields/IconToggleField.tsx","./src/components/fields/NumberField.tsx","./src/components/fields/RangeField.tsx","./src/components/fields/SelectField.tsx","./src/components/fields/TagsField.tsx","./src/components/fields/TextField.tsx","./src/components/fields/TextareaField.tsx","./src/components/fields/ToggleField.tsx","./src/components/fields/UIDropdownIcon.tsx","./src/components/fields/UIImageField.tsx","./src/components/fields/UIThreeField.tsx","./src/components/fields/UIThreePreview.tsx","./src/components/utils/deepEqual.ts","./src/components/utils/groupParams.ts","./src/stores/nodeRegistryStore.ts","./src/stores/nodeStore.ts","./src/stores/websocketStore.ts"],"version":"5.7.3"}

================================================================================
FILE: ./client/tsconfig.node.tsbuildinfo
================================================================================

{"root":["./vite.config.ts"],"version":"5.7.3"}

================================================================================
FILE: ./client/vite.config.example.ts
================================================================================

import { defineConfig } from 'vite'
import react from '@vitejs/plugin-react'

// https://vite.dev/config/
export default defineConfig({
  plugins: [react()],
  build: {
    chunkSizeWarningLimit: 2000,
    rollupOptions: {
      output: {
        manualChunks: {
          'three-fiber': ['@react-three/fiber', '@react-three/drei', 'three'],
        },
      },
    },
  },
})


================================================================================
FILE: ./client/src/App.tsx
================================================================================

import { useEffect } from 'react';
import { 
  ReactFlow,
  //Controls,
  Background,
  BackgroundVariant,
  NodeOrigin,
  useReactFlow,
  Connection,
  IsValidConnection,
  Viewport
} from '@xyflow/react';
import { shallow } from 'zustand/shallow';
import { useNodeState, NodeState, CustomNodeType, getLocalStorageKey } from './stores/nodeStore';
import { useNodeRegistryState, NodeRegistryState } from './stores/nodeRegistryStore';
import { useWebsocketState, WebsocketState } from './stores/websocketStore';

import { nanoid } from 'nanoid';

import config from '../config';
import CustomNode from './components/CustomNode';

import '@xyflow/react/dist/base.css';
import './app.css';

const nodeTypes = {
  custom: CustomNode,
};

const selectNodeState = (state: NodeState) => ({
  nodes: state.nodes,
  edges: state.edges,
  onNodesChange: state.onNodesChange,
  onEdgesChange: state.onEdgesChange,
  onEdgeDoubleClick: state.onEdgeDoubleClick,
  onConnect: state.onConnect,
  addNode: state.addNode,
  getParam: state.getParam,
  loadWorkflowFromStorage: state.loadWorkflowFromStorage,
});

const selectNodeRegistryState = (state: NodeRegistryState) => ({
  nodeRegistry: state.nodeRegistry,
  updateNodeRegistry: state.updateNodeRegistry,
});

const selectWebsocketState = (state: WebsocketState) => ({
  connect: state.connect,
});

const nodeOrigin: NodeOrigin = [0, 0];

export default function App() {
  const {
    nodes,
    edges,
    onNodesChange,
    onEdgesChange,
    onEdgeDoubleClick,
    onConnect,
    addNode,
    getParam,
    loadWorkflowFromStorage,
  } = useNodeState(selectNodeState, shallow);
  const { nodeRegistry, updateNodeRegistry } = useNodeRegistryState(selectNodeRegistryState, shallow);
  const { connect: connectWebsocket } = useWebsocketState(selectWebsocketState, shallow);
  const { screenToFlowPosition, setViewport } = useReactFlow();

  useEffect(() => {
    // Load workflow from localStorage and initialize other services
    loadWorkflowFromStorage();
    updateNodeRegistry();
    connectWebsocket('ws://' + config.serverAddress + '/ws');
  }, []);

  // Save viewport position when it changes
  const onMoveEnd = (_: MouseEvent | TouchEvent | null, viewport: Viewport) => {
    const { mode } = useNodeState.getState();
    const key = getLocalStorageKey(mode);
    const stored = localStorage.getItem(key) || '{}';
    const data = JSON.parse(stored);
    data.viewport = viewport;
    localStorage.setItem(key, JSON.stringify(data));
  };
  
  // TODO: probably need to use useCallback
  const onWorkflowDrop = (event: React.DragEvent<HTMLDivElement>) => {
    event.preventDefault();
    const file = event.dataTransfer.files[0];
    if (file?.type !== 'application/json') return;

    const reader = new FileReader();
    reader.onload = (e) => {
      const flow = JSON.parse(e.target?.result as string);
      // Set default type if not present
      if (!flow.type) {
        flow.type = 'workflow';
      }

      // Store the workflow in the appropriate localStorage key
      const key = getLocalStorageKey(flow.type);
      localStorage.setItem(key, JSON.stringify(flow));
      
      // Now load it through the store which will handle setting the mode
      loadWorkflowFromStorage(flow.type);
    };
    reader.readAsText(file);
  };

  // Handle drag and drop
  const onDragOver = (event: React.DragEvent<HTMLDivElement>) => {
    event.preventDefault();

    if (event.dataTransfer.types.includes('Files')) {
      event.dataTransfer.dropEffect = 'copy';
      return;
    }
    event.dataTransfer.dropEffect = 'move';
  }

  const onDrop = (event: React.DragEvent<HTMLDivElement>) => {
    event.preventDefault();

    // Handle workflow file drops
    if (event.dataTransfer.files.length > 0) {
      onWorkflowDrop(event);
      return;
    }

    if (!nodeRegistry) return;

    const key = event.dataTransfer.getData('text/plain');
    if (!key || !nodeRegistry[key]) return;

    const nodeData = nodeRegistry[key];

    const position = screenToFlowPosition({
      x: event.clientX,
      y: event.clientY,
    });

    const newNode = {
      id: nanoid(),
      type: 'custom', // for now we only have custom type
      position,
      data: nodeData,
    };

    addNode(newNode as CustomNodeType);
  }

  const isValidConnection = (connection: Connection) => {
    if (!connection.sourceHandle || !connection.targetHandle) return false;

    // prevent self-loops
    if (connection.source === connection.target) return false;

    let sourceType = getParam(connection.source, connection.sourceHandle, 'type');
    let targetType = getParam(connection.target, connection.targetHandle, 'type');
    sourceType = Array.isArray(sourceType) ? sourceType : [sourceType];
    sourceType.push('any');
    targetType = Array.isArray(targetType) ? targetType : [targetType];

    if (!sourceType.some((type: string) => targetType.includes(type))) return false;

    return true;
  }

  // Get stored viewport or use defaults
  const defaultViewport = (() => {
    const { mode } = useNodeState.getState();
    const key = getLocalStorageKey(mode);
    const stored = localStorage.getItem(key);
    if (stored) {
      const { viewport } = JSON.parse(stored);
      if (viewport) {
        return viewport;
      }
    }
    return { x: 0, y: 0, zoom: 1 };
  })();

  return (
    <ReactFlow
      nodes={nodes}
      edges={edges}
      nodeTypes={nodeTypes}
      onNodesChange={onNodesChange}
      onEdgesChange={onEdgesChange}
      onEdgeDoubleClick={(_, edge) => onEdgeDoubleClick(edge.id)}
      isValidConnection={isValidConnection as IsValidConnection}
      onConnect={onConnect}
      nodeOrigin={nodeOrigin}
      onDragOver={onDragOver}
      onDrop={onDrop}
      onMoveEnd={onMoveEnd}
      edgesReconnectable={true}
      defaultViewport={defaultViewport}
      minZoom={0.1}
      maxZoom={1.2}
      //connectionRadius={18}
      //fitView
      proOptions={{hideAttribution: true}}
      deleteKeyCode={['Backspace', 'Delete']}      
    >
      {/* <Controls position="bottom-right" /> */}
      <Background variant={BackgroundVariant.Dots} gap={16} size={1} color="rgba(255, 255, 255, 0.3)" />
    </ReactFlow>
  );
}


================================================================================
FILE: ./client/src/main.tsx
================================================================================

import { StrictMode } from 'react'
import { createRoot } from 'react-dom/client'
import {ReactFlowProvider } from '@xyflow/react'

import { createTheme, ThemeProvider } from '@mui/material/styles';
import CssBaseline from '@mui/material/CssBaseline';
import "@fontsource/jetbrains-mono/latin-400.css";
import "@fontsource/jetbrains-mono/latin-700.css";
import "@fontsource/inter/latin-400.css";
import "@fontsource/inter/latin-500.css";
import "@fontsource/inter/latin-600.css";

import { WebSocketProvider } from './components/WebsocketContext';
import { useNodeState } from './stores/nodeStore';
import { getThemeOptions } from './theme/themeConfig';

function ThemedApp() {
  const mode = useNodeState(state => state.mode);
  const theme = createTheme(getThemeOptions(mode));

  return (
    <ThemeProvider theme={theme}>
      <CssBaseline />
      <ReactFlowProvider>
        <Box sx={{
          display: 'flex',
          flexDirection: 'column',
          height: '100vh',
          width: '100vw',
          overflow: 'hidden',
        }}
        className={theme.palette.mode === 'light' ? 'light-mode' : 'dark-mode'}
        >
          <ActionBar />
          <Box sx={{
            display: 'flex',
            flex: 1,
            minHeight: 0,
            height: '100%',
          }}>
            <ToolBar />
            <Box sx={{ flex: 1, height: '100%' }}>
              <WebSocketProvider>
                <App />          
              </WebSocketProvider>
            </Box>
          </Box>
        </Box>
      </ReactFlowProvider>
    </ThemeProvider>
  );
}

import App from './App.tsx'
import Box from '@mui/material/Box';
import ToolBar from './components/ToolBar.tsx';
import ActionBar from './components/ActionBar.tsx';

createRoot(document.getElementById('root')!).render(
  <StrictMode>
    <ThemedApp />
  </StrictMode>
);


================================================================================
FILE: ./client/src/vite-env.d.ts
================================================================================

/// <reference types="vite/client" />


================================================================================
FILE: ./client/src/stores/nodeRegistryStore.ts
================================================================================

import { createWithEqualityFn } from 'zustand/traditional';
import config from '../../config';

type NodeType = {
    [key: string]: {
        label: string
        module: string
        action: string
        category: string
        type?: string
        params?: { [key: string]: any }
    }
}

export type NodeRegistryState = {
    nodeRegistry: NodeType;
    updateNodeRegistry: () => Promise<void>;
}

export const useNodeRegistryState = createWithEqualityFn<NodeRegistryState>((set) => ({
    nodeRegistry: {},
    updateNodeRegistry: async () => {
        try {
            const response = await fetch('http://' + config.serverAddress + '/nodes')
            const data = await response.json()
            set({ nodeRegistry: data })
        } catch (error) {
            console.error('Can\'t connect to route `/nodes`', error)
        }
    },
}))

================================================================================
FILE: ./client/src/stores/nodeStore.ts
================================================================================

import {
    Edge,
    Node,
    OnConnect,
    NodeChange,
    EdgeChange,
    OnNodesChange,
    OnEdgesChange,
    applyNodeChanges,
    applyEdgeChanges,
    Connection,
    getOutgoers,
} from '@xyflow/react';
import { createWithEqualityFn } from 'zustand/traditional';
import { nanoid } from 'nanoid';

import config from '../../config';

export type WorkflowType = 'workflow' | 'tool';

export type GroupParams = {
    key: string;
    display: 'group' | 'collapse';
    label?: string;
    hidden?: boolean;
    disabled?: boolean;
    open?: boolean;
    direction?: 'row' | 'column';
}

export type NodeParams = {
    type?: string | string[];
    label?: string;
    display?: string;
    value?: any;
    spawn?: boolean;     // if true, can be an array input
    options?: any;
    default?: any;
    description?: string;
    source?: string;     // e.g. for custom components
    min?: number;
    max?: number;
    step?: number;
    group?: GroupParams;
    style?: { [key: string]: string };
    no_validation?: boolean;
    disabled?: boolean;
    hidden?: boolean;
    onChange?: any;
    icon?: string;
};

export type NodeData = {
    module: string;
    action: string;
    category: string;
    label?: string;
    description?: string;
    style?: { [key: string]: string };
    resizable?: boolean;
    groups?: { [key: string]: { disabled?: boolean; hidden?: boolean; open?: boolean } };
    params: { [key: string]: NodeParams };
    cache?: boolean;
    time?: number;
    memory?: number;
};

type StoredWorkflow = {
    type?: WorkflowType;
    nodes: CustomNodeType[];
    edges: Edge[];
    viewport?: { x: number; y: number; zoom: number };
};

export type CustomNodeType = Node<NodeData, 'custom'>;

type APINodeData = {
    module: string;
    action: string;
    params: {
        [key: string]: {
            sourceId?: string;
            sourceKey?: string;
            value?: any;
            display?: string;
            type?: string | string[];
        };
    };
};

type GraphExport = {
    sid: string;
    nodes: { [key: string]: APINodeData };
    paths: string[][];
};

function buildPath(currentId: string, nodes: CustomNodeType[], edges: Edge[], visited = new Set<string>()): string[] {
    if (visited.has(currentId)) return [];
    visited.add(currentId);

    const node = nodes.find(n => n.id === currentId);
    if (!node) return [];

    // find all incoming edges
    const incomingEdges = edges.filter(e => e.target === currentId);
    if (incomingEdges.length === 0) {
        return [currentId];
    }

    const paths: string[][] = [];
    for (const edge of incomingEdges) {
        const subPath = buildPath(edge.source, nodes, edges, new Set<string>(visited));
        paths.push(subPath);
    }

    // flatten them and then add current
    const combined = ([] as string[]).concat(...paths, [currentId]);
    return combined;
}

function formatAPIData(node: CustomNodeType, edges: Edge[]): APINodeData {
    const inputEdges = edges.filter(e => e.target === node.id);
    const params: APINodeData['params'] = {};

    for (const [key, param] of Object.entries(node.data.params)) {
        if (param.display === 'output') continue;

        const edge = inputEdges.find(ed => ed.targetHandle === key);
        params[key] = {
            sourceId: edge?.source || undefined,
            sourceKey: edge?.sourceHandle || undefined,
            value: param.value,
            display: param.display,
            type: param.type
        };
    }

    return {
        module: node.data.module,
        action: node.data.action,
        params
    };
}

export function getLocalStorageKey(mode: WorkflowType): string {
    return mode === 'workflow' ? 'workflow' : 'tool';
}

const LAST_MODE_KEY = 'last-mode';

export type NodeState = {
    nodes: CustomNodeType[];
    edges: Edge[];
    mode: WorkflowType;

    onNodesChange: OnNodesChange<CustomNodeType>;
    onEdgesChange: OnEdgesChange;
    onConnect: OnConnect;
    onEdgeDoubleClick: (id: string) => void;

    addNode: (node: CustomNodeType) => void;
    setParamValue: (id: string, key: string, value: any) => void;
    setParam: (id: string, param: string, value: any, pkey?: keyof NodeParams) => void;
    getParam: (id: string, param: string, pkey: keyof NodeParams) => any;

    setNodeExecuted: (id: string, cache: boolean, time: number, memory: number) => void;

    loadWorkflowFromStorage: (mode?: WorkflowType) => void;
    updateLocalStorage: () => void;
    exportGraph: (sid: string) => GraphExport;
};

export const useNodeState = createWithEqualityFn<NodeState>((set, get) => ({
    nodes: [],
    edges: [],
    mode: (() => {
        const lastMode = localStorage.getItem(LAST_MODE_KEY);
        return (lastMode === 'workflow' || lastMode === 'tool') ? lastMode : 'workflow';
    })(),  // initialize with last mode or default to 'workflow'

    loadWorkflowFromStorage: (overrideMode) => {
        const currentMode = overrideMode ?? get().mode;
        const key = getLocalStorageKey(currentMode);
        const stored = localStorage.getItem(key);

        if (stored) {
            const data: StoredWorkflow = JSON.parse(stored);
            set({
                nodes: data.nodes || [],
                edges: data.edges || [],
                mode: data.type ?? currentMode
            });
            // Save the current mode as the last active mode
            localStorage.setItem(LAST_MODE_KEY, currentMode);
        } else {
            set({ nodes: [], edges: [] });
        }
    },

    onNodesChange: async (changes) => {
        const newNodes = applyNodeChanges(changes, get().nodes);
        set({ nodes: newNodes });
        get().updateLocalStorage();

        // delete the server cache for the deleted nodes
        if (changes.some(change => change.type === 'remove')) {
            const nodeIds = changes.filter(change => change.type === 'remove').map(change => change.id);
            try {
                await fetch('http://' + config.serverAddress + '/clearNodeCache', {
                    method: 'DELETE',
                    body: JSON.stringify({ nodeId: nodeIds }),
                });
            } catch (error) {
                console.error('Can\'t connect to server to clear cache:', error);
            }
        }
    },

    onEdgesChange: (changes) => {
        const newEdges = applyEdgeChanges(changes, get().edges);

        // Handle array disconnections
        const removedEdges = changes.filter(change => change.type === 'remove');
        for (const removedEdge of removedEdges) {
            const edge = get().edges.find(e => e.id === removedEdge.id);
            const spawnHandle = get().getParam(edge?.target!, edge?.targetHandle!, 'spawn');
            if (edge && spawnHandle) {
                set({
                    nodes: get().nodes.map(node => {
                        if (node.id === edge.target) {
                            const { [edge.targetHandle!]: _, ...remainingParams } = node.data.params;
                            return {
                                ...node,
                                data: {
                                    ...node.data,
                                    params: remainingParams
                                }
                            };
                        }
                        return node;
                    })
                });
            }
        }

        set({ edges: newEdges });
        get().updateLocalStorage();
    },

    onEdgeDoubleClick: (id) => {
        const edgeChange: EdgeChange = { id, type: 'remove' };
        get().onEdgesChange([edgeChange]);
    },

    onConnect: (conn) => {
        const filteredEdges = get().edges.filter(e => !(e.target === conn.target && e.targetHandle === conn.targetHandle));
        const handleColor = '#aaaaaa';
        const newEdge: Edge = {
            ...conn,
            id: nanoid(),
            style: { stroke: handleColor },
        };
        set({ edges: [...filteredEdges, newEdge] });
        get().updateLocalStorage();
    },

    addNode: (node) => {
        // Set initial values for parameters
        if (node.data?.params) {
            Object.keys(node.data.params).forEach(key => {
                const param = node.data.params[key];
                node.data.params[key] = {
                    ...param,
                    value: param.value ?? param.default
                };
            });
        }
        const newNodes = [...get().nodes, node];
        set({ nodes: newNodes });
        get().updateLocalStorage();
    },

    setParamValue: (id, key, value) => {
        set({
            nodes: get().nodes.map(n => {
                if (n.id !== id) return n;
                return {
                    ...n,
                    data: {
                        ...n.data,
                        params: {
                            ...n.data.params,
                            [key]: {
                                ...n.data.params[key],
                                value
                            }
                        }
                    }
                };
            })
        });
        get().updateLocalStorage();
    },

    setParam: (id, param, value, pkey) => {
        set({
            nodes: get().nodes.map(n => {
                if (n.id !== id) return n;

                if (!pkey || pkey === 'value') {
                    return {
                        ...n,
                        data: {
                            ...n.data,
                            params: {
                                ...n.data.params,
                                [param]: {
                                    ...n.data.params[param],
                                    value
                                }
                            }
                        }
                    };
                } else if (pkey === 'group') {
                    return {
                        ...n,
                        data: {
                            ...n.data,
                            groups: {
                                ...n.data.groups,
                                [param]: {
                                    ...(n.data.groups?.[param] || {}),
                                    ...value
                                }
                            }
                        }
                    };
                } else {
                    return {
                        ...n,
                        data: {
                            ...n.data,
                            params: {
                                ...n.data.params,
                                [param]: {
                                    ...n.data.params[param],
                                    [pkey]: value
                                }
                            }
                        }
                    };
                }
            })
        });
        get().updateLocalStorage();
    },

    getParam: (id, param, pkey) => {
        const node = get().nodes.find(n => n.id === id);
        if (!node) return undefined;
        return node.data.params[param]?.[pkey];
    },

    setNodeExecuted: (id, cache, time, memory) => {
        set({
            nodes: get().nodes.map(n => {
                if (n.id === id) {
                    return {
                        ...n,
                        data: { ...n.data, cache, time, memory }
                    };
                }
                return n;
            })
        });
    },

    exportGraph: (sid) => {
        const { nodes, edges, mode } = get();
        const outputNodes = nodes.filter(n => getOutgoers(n, nodes, edges).length === 0);
        const paths = outputNodes.map(n => buildPath(n.id, nodes, edges));
        const lookup: { [id: string]: APINodeData } = {};

        for (const node of nodes) {
            lookup[node.id] = formatAPIData(node, edges);
        }

        return {
            sid,
            type: mode,
            nodes: lookup,
            paths
        };
    },

    updateLocalStorage: () => {
        const { nodes, edges, mode } = get();
        const key = getLocalStorageKey(mode);

        const stored = localStorage.getItem(key);
        let viewport = { x: 0, y: 0, zoom: 1 };
        if (stored) {
            const parsed = JSON.parse(stored);
            if (parsed.viewport) viewport = parsed.viewport;
        }

        const data: StoredWorkflow = {
            type: mode,
            nodes,
            edges,
            viewport
        };
        localStorage.setItem(key, JSON.stringify(data));
        // Save the current mode as the last active mode
        localStorage.setItem(LAST_MODE_KEY, mode);
    },
}));


================================================================================
FILE: ./client/src/stores/websocketStore.ts
================================================================================

import { createWithEqualityFn } from 'zustand/traditional';
import { useNodeState } from './nodeStore';
import { nanoid } from 'nanoid';

/*
const selectNodeState = (state: NodeState) => ({
    nodes: state.nodes,
    setParamValue: state.setParamValue,
});
*/
type NodeProgress = {
    value: number;
    type: 'determinate' | 'indeterminate' | 'disabled';
};

export type WebsocketState = {
    address: string | null;
    sid: string | null;
    socket: WebSocket | null;
    isConnected: boolean;
    reconnectTimer: NodeJS.Timeout | undefined;

    connect: (addr?: string) => void;
    disconnect: () => void;

    threeData: Record<string, string>;
    updateThreeData: (nodeId: string, key: string, value: string) => void;

    nodeProgress: Record<string, NodeProgress>;
    updateNodeProgress: (nodeId: string, progress: number) => void;
}

export const useWebsocketState = createWithEqualityFn<WebsocketState>((set, get) => ({
    address: null,
    sid: null,
    socket: null,
    isConnected: false,
    reconnectTimer: undefined,

    nodeProgress: {},
    updateNodeProgress: (nodeId: string, progress: number) => {
        set((state) => ({
            nodeProgress: {
                ...state.nodeProgress,
                [nodeId]: {
                    value: progress < 0 ? 0 : progress,
                    type: progress === -1 ? 'indeterminate' : progress === -2 ? 'disabled' : 'determinate'
                }
            }
        }));
    },

    threeData: {},
    updateThreeData: (nodeId: string, key: string, value: string) => {
        set((state) => ({
            threeData: {
                ...state.threeData,
                [`${nodeId}-${key}`]: value
            }
        }));
    },

    connect: async (addr?: string) => {
        const { reconnectTimer } = get();
        if (reconnectTimer) {
            clearTimeout(reconnectTimer);
            set({ reconnectTimer: undefined });
        }
    
        let { address, sid, socket } = get();

        if (socket) {
            console.info('WebSocket already created.');
            return;
        }

        if (!address && !addr) {
            console.error('Cannot connect to WebSocket. No address specified.');
            return;
        }

        if (addr && addr !== address) {
            address = addr;
            set({ address });
        }

        if (!sid) {
            sid = nanoid(10);
            set({ sid });
        }

        const protocol = window.location.protocol === 'https:' ? 'wss://' : 'ws://';
        socket = new WebSocket(`${protocol}${address}/ws?sid=${sid}`);
        set({ socket });

        const onOpen = () => {
            set({ isConnected: true, reconnectTimer: undefined });
            console.info('WebSocket connection established');
        };

        const onClose = () => {
            clearTimeout(get().reconnectTimer); // just to be sure
            set({ socket: null, isConnected: false, reconnectTimer: undefined });
            console.info('WebSocket connection closed');

            const timer = setTimeout(() => {
                console.info('Trying to reconnect...');
                get().connect();
            }, 500);

            set({ reconnectTimer: timer });
        };

        const onMessage = (event: MessageEvent) => {
            //const { setNodeExecuted } = useNodeState((state: NodeState) => ({ setNodeExecuted: state.setNodeExecuted }), shallow);
            const message = JSON.parse(event.data);

            if (message.type === 'welcome') {
                if (!message.sid) {
                    console.error('Invalid welcome message.');
                    return;
                }
                if (message.sid !== sid) {
                    console.info('Session ID mismatch. Updating.', message.sid, sid);
                    set({ sid: message.sid });
                }
                console.info('WebSocket connection established');
            }
            else if (message.type === 'progress') {
                if (!message.progress || !message.nodeId ) {
                    return;
                }
                get().updateNodeProgress(message.nodeId, message.progress);
            }
            else if (message.type === 'image') {
                if (!message.nodeId || !message.key || !message.data) {
                    console.error('Invalid image message. Ignoring.');
                    return;
                }
                useNodeState.getState().setParam(message.nodeId, message.key, message.data);

                // update the image in the UI, without storing it in the node state
                // memory efficient, but not doesn't survive a page reload
                // const el = document.querySelector(`#${CSS.escape(message.nodeId)} [data-key="${message.key}"] img`);
                // if (el) {
                //     el.setAttribute('src', `data:image/webp;base64,${message.data}`);
                // }
            }
            else if (message.type === '3d') {
                if (!message.data || !message.nodeId || !message.key) {
                    console.error('Invalid 3D model message. Ignoring.');
                    return;
                }
                const dataUrl = `data:model/gltf-binary;base64,${message.data}`;
                get().updateThreeData(message.nodeId, message.key, dataUrl);
                    
                // For blob data
                // const blob = new Blob([message.data], { type: 'model/gltf-binary' });
                // const url = URL.createObjectURL(blob);
                // el.setAttribute('url', url);
            }
            else if (message.type === 'executed') {
                console.info('executed', message);
                if (!message.nodeId) {
                    console.error('Invalid executed message. Ignoring.');
                    return;
                }
                useNodeState.getState().setNodeExecuted(message.nodeId, true, message.time || 0, message.memory || 0);
                get().updateNodeProgress(message.nodeId, -2);

                // if ('updateValues' in message) {
                //     Object.entries(message.updateValues).forEach(([k, v]) => {
                //         useNodeState.getState().setParamValue(message.nodeId, k, v);
                //     });
                // }
            }
            else if (message.type === 'updateValues') {
                if (!message.nodeId || !message.key || !message.value) {
                    console.error('Invalid updateValues message. Ignoring.');
                    return;
                }
                useNodeState.getState().setParamValue(message.nodeId, message.key, message.value);
            }
            else if (message.type === 'error') {
                console.error('Error:', message.error);
                set({ nodeProgress: {} });
            }
        };

        //const onError = (event: Event) => {
        //    console.error('WebSocket error:', event);
        //};

        socket.addEventListener('open', onOpen);
        socket.addEventListener('close', onClose);
        socket.addEventListener('message', onMessage);
        //socket.addEventListener('error', onError);
    },
    disconnect: async () => {
        const { reconnectTimer } = get();
        if (reconnectTimer) {
            clearTimeout(reconnectTimer);
        }
        set((state) => {
            if (state.socket) {
                state.socket.close();
            }
            return ({
                socket: null,
                isConnected: false,
                reconnectTimer: undefined,
            });
        });
    },
    destroy: async () => {
        get().disconnect();
        set({ address: null, sid: null });
    },
}))


================================================================================
FILE: ./client/src/components/ActionBar.tsx
================================================================================

import { useCallback } from 'react'
import { useReactFlow } from '@xyflow/react'
import { useTheme } from '@mui/material/styles'
import Box from '@mui/material/Box'
import Typography from '@mui/material/Typography'
import Button from '@mui/material/Button'
import Stack from '@mui/material/Stack'
import Tooltip from '@mui/material/Tooltip'
//import IconButton from '@mui/material/IconButton'

//import WifiIcon from '@mui/icons-material/Wifi';
import { shallow } from 'zustand/shallow'
import { NodeState, useNodeState } from '../stores/nodeStore'
import { WebsocketState, useWebsocketState } from '../stores/websocketStore'
import config from '../../config';

// Icons
import PlayArrowIcon from '@mui/icons-material/PlayArrow';
import GetAppIcon from '@mui/icons-material/GetApp';
import InsertDriveFileOutlinedIcon from '@mui/icons-material/InsertDriveFileOutlined';
import SvgIcon from '@mui/material/SvgIcon'

export default function AppToolbar() {
  const { setNodes, setEdges, toObject, setViewport } = useReactFlow();
  const theme = useTheme()
  const { exportGraph, mode } = useNodeState((state: NodeState) => ({ 
    exportGraph: state.exportGraph,
    mode: state.mode 
  }), shallow);
  const { sid, isConnected } = useWebsocketState((state: WebsocketState) => ({ sid: state.sid, isConnected: state.isConnected }), shallow);
  
  const onRun = async () => {
    if (!isConnected) {
      console.error('Not connected to WebSocket server');
      return;
    }
    if (mode === 'tool') {
      console.info('No global run in Tool mode. Use node-based triggers.');
      return;
    }

    const graphData = exportGraph(sid ?? '');
    console.info(graphData);

    try {
      await fetch('http://' + config.serverAddress + '/graph', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify(graphData),
      });
    } catch (error) {
      console.error('Error connecting to API server:', error);
    }
  }

  const onExport = useCallback(() => {
    const flow = toObject();
    const data = {
      ...flow,
      type: mode
    };
    const jsonString = JSON.stringify(data, null, 2);

    // Create blob and download
    const blob = new Blob([jsonString], { type: 'application/json' });
    const url = URL.createObjectURL(blob);
    const link = document.createElement('a');
    link.href = url;
    const date = new Date().toISOString().replace(/:/g, '');
    link.download = `${mode === 'tool' ? 'tool' : 'workflow'} - ${date}.json`;
    document.body.appendChild(link);
    link.click();
    document.body.removeChild(link);
    URL.revokeObjectURL(url);
  }, [toObject, mode]);

  const onNew = useCallback(() => {
    // Clear the nodes and edges
    setNodes([]);
    setEdges([]);
    
    // Clear localStorage
    localStorage.removeItem('workflow');
    
    const defaultViewport = { x: 0, y: 0, zoom: 1 };
    localStorage.setItem('workflow', JSON.stringify({ nodes: [], edges: [], viewport: defaultViewport }));
    setViewport(defaultViewport);
  }, [setNodes, setEdges]);

  return (
    <Box sx={{
      backgroundColor: theme.palette.background.paper,
      padding: 1,
      borderBottom: `1px solid ${theme.palette.divider}`,
    }}>
      <Stack
        direction="row"
        spacing={0}
        sx={{ justifyContent: "space-between", alignItems: "center" }}
      >
        <Stack
          direction="row"
          spacing={0}
          sx={{ justifyContent: "space-between", alignItems: "center" }}
        >
          <Box sx={{ display: 'flex', alignItems: 'center', ml: 3 }}>
            <SvgIcon>
              <svg viewBox="0 0 28 12" style={{ width: '40px', height: '100%', marginRight: '4px' }} xmlSpace="preserve" xmlns="http://www.w3.org/2000/svg">
                <path style={{ fill: `${theme.palette.primary.main}` }} d="M1.815 11.95c0-.08.421-.784.936-1.565 1.217-1.848 2.4-5.662 2.161-6.965-.29-1.577-1.831-1.974-3.759-.97-1.334.696-1.513.496-.524-.578C1.682.725 3.286.007 4.807 0 6.57-.008 7.485 1.07 7.149 2.866c-.07.373-.077.665-.052.682.026.018.683-.505 1.368-1.122C10.205.861 11.458.232 13.026.266c2.323.054 2.982 1.899 3.153 2.636l.233 1.008 1.067-1.027C19.471.963 21.347.29 22.372.233c1.025-.058 1.686.18 2.376.915 1.69 1.801 1.441 4.275-.753 7.237-.963 1.3-1.166 1.726-.822 1.724.56.082 2.803-.211 3.602-.475.801-.262 1.16-.602 1.22-.507.047.072-.253.528-.4.695-.388.431-1.228 1.447-3.416 1.87-1.432.276-3.066.272-7.87.011-5.772-.312-8.614-.405-13.131.207-.75.101-1.364.12-1.364.041zM7.704 9.96c5.39-.463 5.243-.537 5.872-1.863 1.538-3.246-.245-6.387-3.297-5.802-1.09.209-2.7 1.904-4.049 4.262a522.55 522.55 0 0 1-1.532 2.666c-.286.489-.418.888-.296.886.123 0 1.609-.004 3.302-.149zm14.219-.594c.924-.558 1.842-2.346 1.842-3.592 0-1.864-1.516-3.591-3.15-3.591-1.511 0-2.565.904-4.441 3.81-.958 1.483-1.918 2.724-2.028 2.877-.328.462.122.959 4.76 1.064 1.702.038 2.42-.209 3.017-.568z"/>
              </svg>
            </SvgIcon>
          </Box>

          <Box sx={{ mr: 3 }}>
            <Typography variant="h6" sx={{ fontSize: '20px', padding: '0px 4px' }}>
              Mellon
            </Typography>
          </Box>

          <Box>
          <Button
              variant="text"
              startIcon={<InsertDriveFileOutlinedIcon />}
              onClick={onNew}
              sx={{ mr: 1 }}  // Add margin between buttons
            >
              New
            </Button>
            <Button
              variant="text"
              startIcon={<GetAppIcon />}
              onClick={onExport}
            >
              Export
            </Button>
          </Box>
        </Stack>
        <Box>
          {mode !== 'tool' && (
            <Tooltip 
              title={mode === 'tool' ? "Global workflow execution is disabled in tool mode. Use node-based triggers instead." : ""}
              placement="top"
            >
              <span>
                <Button
                  variant="contained"
                  startIcon={<PlayArrowIcon />}
                  onClick={onRun}
                  disabled={!isConnected}
                  sx={{
                    background: `linear-gradient(100deg, ${theme.palette.primary.main} 25%, #ff4259 90%)`,
                    '&.Mui-disabled': {
                      background: `linear-gradient(100deg, #6a6a6a, #303030)`,
                      color: '#1a1a1a',
                    }
                  }}
                >
                  Run Workflow
                </Button>
              </span>
            </Tooltip>
          )}
        </Box>
        <Box></Box>
      </Stack>
    </Box>
  )
}


================================================================================
FILE: ./client/src/components/CustomNode.tsx
================================================================================

import { memo } from 'react';
import { NodeProps, NodeResizeControl } from '@xyflow/react';
import { shallow } from 'zustand/shallow';

// MUI components
import { useTheme } from '@mui/material/styles'
import Box from '@mui/material/Box';
import Chip from '@mui/material/Chip';
import Stack from '@mui/material/Stack';

// Icons
import DeleteForeverIcon from '@mui/icons-material/DeleteForever';
import AccessAlarmIcon from '@mui/icons-material/AccessAlarm';
import LinearProgress from '@mui/material/LinearProgress';
import OpenInFullIcon from '@mui/icons-material/OpenInFull';

import config from '../../config';
import { groupParams } from './utils/groupParams';
import { useNodeState, NodeState, CustomNodeType, NodeParams } from '../stores/nodeStore';
import { useWebsocketState } from '../stores/websocketStore';
import NodeContent from './NodeContent';

import { deepEqual } from './utils/deepEqual';

const CustomNode = memo((props: NodeProps<CustomNodeType>) => {
    const theme = useTheme();
    const { setParam, setNodeExecuted } = useNodeState((state: NodeState) => ({
        setParam: state.setParam,
        setNodeExecuted: state.setNodeExecuted
    }), shallow);

    const nodeProgress = useWebsocketState(
        (state) => state.nodeProgress[props.id] || { value: 0, type: 'determinate' },
        shallow
    );

    const onClearCache = async () => {
        const nodeId = props.id;

        try {
            const response = await fetch('http://' + config.serverAddress + '/clearNodeCache', {
                method: 'DELETE',
                body: JSON.stringify({ nodeId }),
            });

            if (response.ok) {
                setNodeExecuted(nodeId, false, 0, 0);
            }
        } catch (error) {
            console.error('Error clearing cache:', error);
        }
    }

    const nodeId = props.id;
    const nodeTitle = props.data.label;

    // format grouped fields
    const fieldList = groupParams(props.data.params);

    //const nodeContent = Object.entries(fieldList).map(([key, data]) => renderNodeContent(nodeId, key, data, setParam));
    const style = props.data.style || {};

    const updateStore = (param: string, value: any, key?: keyof NodeParams) => {
        setParam(nodeId, param, value, key);
    };

    const resizeControl = (
        <NodeResizeControl style={{ backgroundColor: 'transparent', border: 'none' }} minWidth={200} minHeight={8}>
            <OpenInFullIcon sx={{
                position: 'absolute',
                right: '-6px',
                bottom: '-6px',
                transform: 'rotate(90deg)',
                width: '26px',
                height: '26px',
                backgroundColor: theme.palette.background.default,
                borderRadius: '0',
                padding: '2px',
                color: theme.palette.text.secondary,
            }} />
        </NodeResizeControl>
    );

    return (
        <Box
            id={nodeId}
            className={`${props.data.module}-${props.data.action} category-${props.data.category} module-${props.data.module}`}
            sx={{
                position: 'relative',
                boxShadow: 4,
                outlineOffset: '5px',
                borderRadius: '0',
                minWidth: '200px',
                ...style,
            }}
        >
            {props.data.resizable && resizeControl}

            <Box
                component="header"
                sx={{
                    color: theme.palette.mode === 'light' ? theme.palette.text.primary : theme.palette.common.white,
                    padding: 1,
                    borderTopWidth: '6px',
                    borderTopStyle: 'solid',
                    borderTopColor: 'rgba(0, 0, 0)',
                    backgroundColor: theme.palette.background.default,
                    fontSize: theme.palette.mode === 'light' ? '18px' : '18px',
                    fontWeight: theme.palette.mode === 'light' ? 500 : 400,
                    textShadow: theme.palette.mode === 'light' ? 'none' : '0px 2px 0px rgba(0, 0, 0, 0.75)',
                }}
            >
                {nodeTitle}
            </Box>
            <Box sx={{
                backgroundColor: theme.palette.background.paper,
                pl: 1, pr: 1, pt: 1, pb: 0,
                '& > .MuiBox-root': {
                    pb: 1.5,
                },
                '& .MuiAccordionDetails-root > .MuiBox-root': {
                    pb: 1.5,
                },
                '& .MuiStack-root > .MuiBox-root': {
                    pb: 1.5,
                },
                '& .numberField > .MuiBox-root': {
                    pb: 0,
                },
                '& .labelled-group': {
                    pb: 0,
                },
            }}
            >
                <NodeContent
                    fields={fieldList}
                    updateStore={updateStore}
                    groups={props.data.groups}
                />
            </Box>
            <Box
                component="footer"
                sx={{
                    p: 0,
                    backgroundColor: theme.palette.background.default,
                }}
            >
                <Box sx={{ width: '100%' }}>
                    <LinearProgress
                        variant={nodeProgress.type === 'indeterminate' ? 'indeterminate' : 'determinate'}
                        color="inherit"
                        value={nodeProgress.value}
                        className={nodeProgress.type === 'disabled' ? 'progress-disabled' : ''}
                        sx={{
                            height: '4px',
                            '&.progress-disabled': {
                                '& .MuiLinearProgress-bar': {
                                    display: 'none',
                                },
                            },
                            '& .MuiLinearProgress-bar1Indeterminate': {
                                background: `repeating-linear-gradient(45deg, ${theme.palette.primary.main} 0, ${theme.palette.primary.main} 20px, ${theme.palette.primary.dark} 20px, ${theme.palette.primary.dark} 40px)`,
                                backgroundSize: '60px 100%',
                                backgroundPosition: '0 0',
                                left: '0', right: '0',
                                animation: 'mellon-progress-ind 1s linear infinite',
                            },
                            '& .MuiLinearProgress-bar1Determinate': {
                                transitionDuration: '80ms',
                                background: `linear-gradient(100deg, ${theme.palette.primary.main} 50%, #ff4259 90%)`,
                            },
                            '& .MuiLinearProgress-bar2Indeterminate': {
                                display: 'none',
                                animation: 'none',
                            },
                         }}
                    />
                </Box>

                <Box sx={{ p: 1 }}>
                    <Stack
                        direction="row"
                        spacing={2}
                        sx={{
                            justifyContent: "space-between",
                            alignItems: "center",
                            pr: props.data.resizable ? 2.5 : 0,
                        }}
                    >
                        <Chip
                            icon={<DeleteForeverIcon />}
                            label="Cache"
                            title="Clear Cache"
                            onClick={onClearCache}
                            disabled={!props.data.cache}
                            color="secondary"
                            variant="filled"
                            sx={{
                                height: '24px',
                                borderRadius: 0.5,
                                fontSize: '12px',
                                span: { padding: '0px 8px 0px 10px' },
                                '& .MuiChip-icon': {
                                    fontSize: '18px',
                                },
                            }}
                        />
                        {/* <Chip
                            icon={<MemoryIcon />}
                            label={props.data.memory ? `${props.data.memory}` : '0Mb'}
                            title="Memory Usage"
                            sx={{
                                color: theme.palette.text.secondary,
                                height: '24px',
                                borderRadius: 0.5,
                                fontSize: '12px',
                                span: { padding: '0px 8px 0px 10px' },
                                backgroundColor: 'rgba(255, 255, 255, 0.1)',
                            }}
                        /> */}
                        <Chip
                            icon={<AccessAlarmIcon />}
                            label={props.data.time ? `${props.data.time}s` : '-'}
                            title="Execution Time"
                            sx={{
                                color: theme.palette.text.secondary,
                                height: '24px',
                                borderRadius: 0.5,
                                fontSize: '12px',
                                span: { padding: '0px 8px 0px 10px' },
                                backgroundColor: 'rgba(255, 255, 255, 0.1)',
                                '& .MuiChip-icon': {
                                    fontSize: '18px',
                                    color: theme.palette.text.secondary,
                                },
                            }}
                        />
                    </Stack>
                </Box>
            </Box>
        </Box>
    );
}, (prevProps, nextProps) => {
    if (prevProps.data.time !== nextProps.data.time) {
        return false;
    }
    if (prevProps.data.cache !== nextProps.data.cache) {
        return false;
    }

    if (!deepEqual(prevProps.data.groups, nextProps.data.groups)) {
        return false;
    }

    const prevParams = prevProps.data.params;
    const nextParams = nextProps.data.params;

    const prevKeys = Object.keys(prevParams);
    const nextKeys = Object.keys(nextParams);

    // Check if the objects have different number of keys
    if (prevKeys.length !== nextKeys.length) {
        return false;
    }

    // Check if all keys match
    if (!prevKeys.every(key => key in nextParams)) {
        return false;
    }

    // Now check the values for each key
    for (const key of prevKeys) {
        const prev = prevParams[key];
        const next = nextParams[key];

        if (!deepEqual(prev.value, next.value) ||
            prev.disabled !== next.disabled ||
            prev.hidden !== next.hidden) {
            return false;
        }
    }

    return true;
});

export default CustomNode;


================================================================================
FILE: ./client/src/components/CustomNumberInput.tsx
================================================================================

import IconButton from '@mui/material/IconButton';
import ChevronLeftIcon from '@mui/icons-material/ChevronLeft';
import ChevronRightIcon from '@mui/icons-material/ChevronRight';
import InputBase from '@mui/material/InputBase';
import Stack from '@mui/material/Stack';
import Box from '@mui/material/Box';
import Typography from '@mui/material/Typography';
import { useTheme } from '@mui/material/styles';
import { useState, useRef, EventHandler, useCallback, useEffect } from 'react';

// TODO: Someone with React expertise should review this code

const CustomNumberInput = ({
    value,
    label = '',
    dataType = 'int',
    slider = false,
    disabled = false,
    onChange,
    min,
    max,
    step,
    style,
    ...props
}: {
    dataKey: string;
    value: string | number;
    label: string;
    dataType?: string;
    slider?: boolean;
    disabled?: boolean;
    onChange: EventHandler<any>;
    min?: number;
    max?: number;
    step?: number;
    style?: { [key: string]: string };
}) => {
    const theme = useTheme();

    const sx = style || {};

    // we display the slider only if we have both min and max values
    const displaySlider = slider && min !== undefined && max !== undefined;

    // min/max normalization
    min = min !== undefined ? min : -Number.MAX_SAFE_INTEGER;
    max = max !== undefined ? max : Number.MAX_SAFE_INTEGER;
    if (min > max) {
        [min, max] = [max, min];
    }

    const minValue = min;
    const maxValue = max;
    const increment = step !== undefined ? step : (dataType === 'float' ? 0.1 : 1);
    const decimals = dataType === 'float' ? (increment.toString().split('.')[1]?.length || 1) : 0;

    const [inputValue, setInputValue] = useState(String(value || 0));
    const [isEditing, setIsEditing] = useState(false);
    const inputRef = useRef<HTMLDivElement>(null);
    const dragTimeoutRef = useRef<NodeJS.Timeout | null>(null);
    const dragStartRef = useRef({ x: 0, value: 0 });
    const isDraggingRef = useRef(false);

    const getBackgroundStyle = (value: number) => {
        if (!displaySlider) return {};

        const sliderPercent = isNaN(Number(value)) ? 0 : ((Number(value) - minValue) / (maxValue - minValue) * 100);
        const baseColor = isDraggingRef.current ? theme.palette.secondary.main : 'rgba(255,255,255,0.25)';
        const hoverColor = theme.palette.secondary.main;

        const gradientStyle = `linear-gradient(to right, ${baseColor} ${sliderPercent}%, rgba(255,255,255,0.1) ${sliderPercent}%)`;

        return {
            background: gradientStyle,
            '&:hover': { background: `linear-gradient(to right, ${hoverColor} ${sliderPercent}%, rgba(255,255,255,0.1) ${sliderPercent}%)` }
        };
    };

    const updateValue = useCallback((value: string | number) => {
        value = Number(value);

        // if the value is invalid, it defaults to the middle of the range
        if (isNaN(value)) {
            value = (maxValue - minValue) / 2;
        }

        const newValue = String(Math.min(maxValue, Math.max(minValue, value)).toFixed(decimals));
        setInputValue(newValue);

        if (!isEditing) {
            onChange(newValue);
        }
    }, [minValue, maxValue, decimals]);

    const handleBlur = useCallback(() => {
        const inputElement = inputRef.current?.querySelector('input');
        setIsEditing(false);

        if (!inputElement) return;

        inputElement.removeEventListener('blur', handleBlur as any);
        inputElement.removeEventListener('keydown', handleKeyDown as any);
        updateValue(inputElement.value);
    }, [updateValue]);

    const handleKeyDown = useCallback((e: React.KeyboardEvent) => {
        const inputElement = inputRef.current?.querySelector('input');

        if (e.key === 'Enter' || e.key === 'Escape') {
            inputElement?.removeEventListener('blur', handleBlur as any);
            inputElement?.removeEventListener('keydown', handleKeyDown as any);

            setIsEditing(false);
            updateValue(inputElement?.value || '');
            inputElement?.blur();
        } else if (e.key === 'ArrowUp') {
            e.preventDefault();
            updateValue(Number(inputElement?.value) + increment);
        } else if (e.key === 'ArrowDown') {
            e.preventDefault();
            updateValue(Number(inputElement?.value) - increment);
        }
    }, [increment, updateValue]);

    const handleMouseMove = useCallback((e: React.MouseEvent) => {
        clearTimeout(dragTimeoutRef.current as any);

        e.preventDefault();
        e.stopPropagation();

        if (!isDraggingRef.current) {
            isDraggingRef.current = true;
        }

        const inputElement = inputRef.current?.querySelector('input');

        // we are dragging, so we remove the focus from the input
        if (document.activeElement === inputElement) {
            inputElement?.blur();
            setIsEditing(false);
        }

        const delta = e.clientX - dragStartRef.current.x;
        const range = maxValue - minValue;
        const steps = range / increment || 100;
        const valueRange = displaySlider ? steps / 300 * delta : delta;
        const newValue = dragStartRef.current.value + valueRange*increment;

        updateValue(newValue);
        //onChange(normalizedValue);
    }, [minValue, maxValue, increment, updateValue]);

    const handleMouseUp = useCallback((e: React.MouseEvent) => {
        clearTimeout(dragTimeoutRef.current as any);
        const inputElement = inputRef.current?.querySelector('input');

        document.removeEventListener('mousemove', handleMouseMove as any);
        document.removeEventListener('mouseup', handleMouseUp as any);
        //inputElement?.removeEventListener('blur', handleBlur as any);
        //inputElement?.removeEventListener('keydown', handleKeyDown as any);

        if (document.activeElement !== inputElement && !isDraggingRef.current && (e.target as HTMLElement).closest('button') === null) {
            // give the focus to the input, unless we are clicking on a left/right button
            inputElement?.focus();
            inputElement?.addEventListener('blur', handleBlur as any);
            inputElement?.addEventListener('keydown', handleKeyDown as any);
            setIsEditing(true);
        } else {
            inputElement?.blur();
            setIsEditing(false);
        }

        isDraggingRef.current = false;
    }, [handleBlur, handleKeyDown]);

    const handleMouseDown = (e: React.MouseEvent) => {
        // Only handle left mouse button
        if (e.button !== 0) {
            e.preventDefault();
            e.stopPropagation();
            return;
        }

        const inputElement = inputRef.current?.querySelector('input');

        // If the input is already focused, act like a standard text field
        // this allows to edit the value by just typing
        if (document.activeElement === inputElement) return;

        (document.activeElement as HTMLElement)?.blur();

        e.preventDefault();
        e.stopPropagation();

        dragStartRef.current = { x: e.clientX, value: Number(inputValue) };

        // we wait 200ms before entering dragging mode
        // a quick click will just focus the input without starting the drag
        dragTimeoutRef.current = setTimeout(() => {
            inputElement?.blur();
            isDraggingRef.current = true;
        }, 200);

        document.addEventListener('mousemove', handleMouseMove as any);
        document.addEventListener('mouseup', handleMouseUp as any);
    };

    const handleChange = (e: React.ChangeEvent<HTMLInputElement>) => {
        //const value = e.target.value;
        setInputValue(e.target.value);
        //onChange(value);
    };

    useEffect(() => {
        setInputValue(String(value));
    }, [value]);

    useEffect(() => {
        return () => {
            clearTimeout(dragTimeoutRef.current as any);
            document.removeEventListener('mousemove', handleMouseMove as any);
            document.removeEventListener('mouseup', handleMouseUp as any);

            const inputElement = inputRef.current?.querySelector('input');
            if (inputElement) {
                inputElement.removeEventListener('blur', handleBlur as any);
                inputElement.removeEventListener('keydown', handleKeyDown as any);
            }
        };
    }, [handleMouseMove, handleMouseUp, handleBlur, handleKeyDown]);

    const field = (
        <Stack
            data-key={props.dataKey}
            direction="row"
            spacing={0.5}
            className={`nodrag customNumberInput${disabled ? ' mellon-disabled' : ''}`}
            onMouseDown={handleMouseDown}
            sx={{
                mb: 0,
                p: 0.5,
                width: '100%',
                justifyContent: 'space-between', alignItems: 'center',
                ...getBackgroundStyle(Number(inputValue)),
                borderRadius: 1,
                overflow: 'hidden',
                userSelect: 'none',
                cursor: 'default',
                outline: isEditing ? `2px solid ${theme.palette.primary.main}` : 'none',
                ...sx,
            }}
        >
            <IconButton
                size="small"
                disableRipple // ripple effect is buggy
                onClick={() => updateValue(Number(inputValue) - increment)}
                sx={{
                    borderRadius: 1,
                    opacity: Number(inputValue) <= minValue ? 0.4 : 1,
                    '&:hover': { background: Number(inputValue) <= minValue ? '' : 'rgba(255,255,255,0.15)' }
                }}
            >
                <ChevronLeftIcon fontSize="small" />
            </IconButton>
            <Box sx={{ maxWidth: '50%'}}>
                <Typography sx={{ fontSize: '14px', textOverflow: 'ellipsis', overflow: 'hidden', whiteSpace: 'nowrap' }} title={label}>{label}</Typography>
            </Box>
            <InputBase
                ref={inputRef}
                value={inputValue}
                onChange={handleChange}
                size="small"
                sx={{ flexGrow: 1 }}
                slotProps={{
                    input: {
                        sx: { textAlign: 'right', padding: 0, cursor: 'default' },
                    },
                }}
            />
            <IconButton
                size="small"
                disableRipple
                onClick={() => updateValue(Number(inputValue) + increment)}
                sx={{
                    borderRadius: 1,
                    opacity: Number(inputValue) >= maxValue ? 0.4 : 1,
                    '&:hover': { background: Number(inputValue) >= maxValue ? '' : 'rgba(255,255,255,0.15)' }
                }}
            >
                <ChevronRightIcon fontSize="small" />
            </IconButton>
        </Stack>
    );

    return field;
};

export default CustomNumberInput;

================================================================================
FILE: ./client/src/components/NodeContent.tsx
================================================================================

import { memo } from "react";
import { NodeParams } from "../stores/nodeStore";
import { deepEqual } from './utils/deepEqual';

// MUI
import { SxProps, Theme } from "@mui/material/styles";

// Custom fields
import AccordionField from "./fields/AccordionField";
import GroupField from "./fields/GroupField";
import HandleField from './fields/HandleField';
import TextField from './fields/TextField';
import ToggleField from "./fields/ToggleField";
import AutocompleteField from "./fields/AutocompleteField";
import SelectField from "./fields/SelectField";
import IconToggleField from "./fields/IconToggleField";
import NumberField from "./fields/NumberField";
import RangeField from "./fields/RangeField";
import TextareaField from "./fields/TextareaField";
import TagsField from "./fields/TagsField";
import CustomField from "./fields/CustomField";
import UIDropdownIcon from "./fields/UIDropdownIcon";
import UIImageField from "./fields/UIImageField";
import UIThreeField from "./fields/UIThreeField";
import ColorPicker from "./fields/ColorPicker";

// These are the props sent to the fields
export type FieldProps = {
    fieldKey: string;
    label?: string;
    fieldType?: string;
    value?: any;
    options?: any;
    dataType?: string;
    style?: SxProps<Theme>;
    disabled?: boolean;
    hidden?: boolean;
    open?: boolean;
    no_validation?: boolean;
    icon?: 'random' | 'none';
    min?: number;
    max?: number;
    step?: number;
    source?: string;
    updateStore?: (param: string, value: any, key?: keyof NodeParams) => void;
    onChangeAction?: { action: string, target?: any };
}

export type GroupProps = {
    fieldKey: string;
    fields: Record<string, NodeParams>;
    updateStore: (param: string, value: any, key?: keyof NodeParams) => void;
    label?: string;
    open?: boolean;
    direction?: 'row' | 'column';
    disabled?: boolean;
    hidden?: boolean;
    style?: SxProps<Theme>;
}

type NodeContentProps = {
    fields: NodeParams;
    updateStore: (param: string, value: any, key?: keyof NodeParams, group?: string) => void;
    groups?: { [key: string]: { disabled?: boolean, hidden?: boolean, open?: boolean } };
    parentDisabled?: boolean; // avoid disabling fields when the parent group is already disabled
}

const NodeContent = (props: NodeContentProps) => {
    //const renderField = (key: string, data: any) => {
    return Object.entries(props.fields).map(([key, data]: [string, any]) => {
        const displayData = (data.display || '').toLowerCase();
        const disabled = props.parentDisabled ? false : data.disabled || false;
        const hidden = data.hidden || false;
        const sxStyle = data.style || {};
        const label = data.label || key;
        
        if (displayData === 'group') {
            const groupDisabled = data.disabled !== undefined ? data.disabled : props.groups?.[key]?.disabled ?? false;
            const groupHidden = data.hidden !== undefined ? data.hidden : props.groups?.[key]?.hidden ?? false;
            console.log('groupHidden', label, data.hidden, groupHidden);

            return (
                <GroupField
                    key={key}
                    fieldKey={key}
                    label={data.label}
                    direction={data.direction}
                    disabled={groupDisabled}
                    hidden={groupHidden}
                    style={sxStyle}
                    updateStore={props.updateStore}
                    fields={data.params}
                />
            )
        }
        
        if (displayData === 'collapse') {
            const open = props.groups?.[key]?.open || data.open || false;
            const groupDisabled = props.groups?.[key]?.disabled || data.disabled || false;
            const groupHidden = props.groups?.[key]?.hidden || data.hidden || false;
            return (
                <AccordionField
                    key={key}
                    fieldKey={key}
                    open={open}
                    label={data.label}
                    disabled={groupDisabled}
                    hidden={groupHidden}
                    style={sxStyle}
                    updateStore={props.updateStore}
                    fields={data.params}
                />
            )
        }

        // Data type can be an array, the array is mostly used for input handles to allow connection to multiple types
        // For node processing we only use the first type, that becomes the main type
        // TODO: should we use an "allowedTypes" property instead?
        const dataType = (Array.isArray(data.type) && data.type.length > 0 ? data.type[0] : data.type || 'string').toLowerCase();

        const fieldType = getFieldType(displayData, dataType, data);
        const fieldValue = data.value === undefined ? data.default || '' : data.value;
        const options = data.options || [];
        const no_validation = data.no_validation || false;
        const onChangeAction = typeof data.onChange === 'string' ? { action: data.onChange } : data.onChange || null;

        const fieldProps: FieldProps = {
            fieldKey: key,
            fieldType: fieldType,
            dataType: dataType,
            label: label,
            value: fieldValue,
            style: sxStyle,
            hidden: hidden,
            disabled: disabled,
            options: options,
            no_validation: no_validation,
            updateStore: props.updateStore,
            onChangeAction: onChangeAction,
            icon: data.icon,
            min: data.min,
            max: data.max,
            step: data.step,
            source: data.source,
        }

        return <FieldMemo key={key} {...fieldProps} />;
    });

    //return Object.entries(props.fields).map(([key, data]: [string, any]) => renderField(key, data));
};

const FieldMemo = memo((props: FieldProps) => {
    switch (props.fieldType) {
        case 'input':
        case 'output':
            return <HandleField {...props} />;
        case 'number':
        case 'slider':
            return <NumberField {...props} />;
        case 'checkbox':
        case 'switch':
            return <ToggleField {...props} />;
        case 'autocomplete':
            return <AutocompleteField {...props} />;
        case 'select':
            return <SelectField {...props} />;
        case 'textarea':
            return <TextareaField {...props} />;
        case 'icontoggle':
            return <IconToggleField {...props} />;
        case 'range':
            return <RangeField {...props} />;
        case 'tags':
            return <TagsField {...props} />;
        case 'custom':
            return <CustomField {...props} />;
        case 'ui_image':
            return <UIImageField {...props} />;
        case 'ui_dropdownicon':
            return <UIDropdownIcon {...props} />;
        case 'ui_3d': // TODO: NOT WORKING, need to find a better way to transmit data to a three.js viewer
            return <UIThreeField {...props} />;
        case 'color':
            return <ColorPicker {...props} />;
        default:
            return <TextField {...props} />;
    }
}, (prevProps, nextProps) => {
    return (
        deepEqual(prevProps.value, nextProps.value) &&
        prevProps.disabled === nextProps.disabled &&
        prevProps.hidden === nextProps.hidden
    );
});

const getFieldType = (displayData: string, dataType: string, data: any) => {
    if (displayData === 'input' || displayData === 'output') {
        return displayData;
    }

    if (dataType === 'boolean') {
        return displayData === 'checkbox' || displayData === 'icontoggle' ? displayData : 'switch';
    }

    if (displayData === 'ui') {
        if (dataType === 'image') {
            return 'ui_image';
        } else if (dataType.toLowerCase() === 'dropdownicon') {
            return 'ui_dropdownicon';
        } else if (dataType.toLowerCase() === '3d') {
            return 'ui_3d';
        }
    }

    if (displayData) {
        return displayData;
    }

    if (data.options && typeof data.options === 'object') {
        return 'select';
    }

    if (dataType === 'int' || dataType === 'integer' || dataType === 'float' || dataType === 'number' ) {
        return displayData === 'slider' ? 'slider' : 'number';
    }

    return 'text';
};

export default NodeContent;

================================================================================
FILE: ./client/src/components/NumberFieldDemo.tsx
================================================================================

import React, { useState } from 'react';
import NumberField from './fields/NumberField';
import Box from '@mui/material/Box';
import Typography from '@mui/material/Typography';
import { NodeParams } from '../stores/nodeStore';

const NumberFieldDemo = () => {
    const [value, setValue] = useState<number>(0);

    const handleUpdate = (_: string, newValue: any) => {
        if (typeof newValue === 'number') {
            setValue(newValue);
        }
    };

    return (
        <Box sx={{ p: 2 }}>
            <Typography variant="h4" gutterBottom>
                Hello World with NumberField
            </Typography>
            <NumberField
                fieldKey="demo"
                fieldType="number"
                dataType="number"
                value={value}
                updateStore={handleUpdate}
                label="Demo Number"
                min={0}
                max={100}
                step={1}
            />
        </Box>
    );
};

export default NumberFieldDemo; 

================================================================================
FILE: ./client/src/components/ToolBar.tsx
================================================================================

import { useMemo, useState, useEffect } from 'react'

import Box from '@mui/material/Box'
import List from '@mui/material/List'
import ListItem from '@mui/material/ListItem'
//import ListItemButton from '@mui/material/ListItemButton'
import ListItemText from '@mui/material/ListItemText'
import Tabs from '@mui/material/Tabs'
import Tab from '@mui/material/Tab'
import AccordionDetails from '@mui/material/AccordionDetails'
import AccordionSummary from '@mui/material/AccordionSummary'
import ToggleButton from '@mui/material/ToggleButton'
import ToggleButtonGroup from '@mui/material/ToggleButtonGroup'
//import Stack from '@mui/material/Stack'
import { useTheme } from '@mui/material/styles'

import { shallow } from 'zustand/shallow';
import { NodeRegistryState, useNodeRegistryState } from '../stores/nodeRegistryStore';
import { useNodeState, NodeState, WorkflowType } from '../stores/nodeStore';

import OutlinedInput from '@mui/material/OutlinedInput'
import SearchIcon from '@mui/icons-material/Search'
import Accordion from '@mui/material/Accordion'
import ExpandMoreIcon from '@mui/icons-material/ExpandMore'

const sidebarWidth = 260

const selectNodeRegistryState = (state: NodeRegistryState) => ({
  nodeRegistry: state.nodeRegistry,
});

const selectNodeState = (state: NodeState) => ({
  mode: state.mode,
  nodes: state.nodes,
  edges: state.edges,
});

const groupBy = (field: string, nodeRegistry: any) => {
  const grouped = Object.entries(nodeRegistry).reduce((acc: any, [key, node]: [string, any]) => {
    const fieldValue = node[field] || 'default';
    if (!acc[fieldValue]) {
      acc[fieldValue] = [];
    }
    acc[fieldValue].push({ key, ...node });
    return acc;
  }, {});

  if (field !== 'module') {
    // Sort nodes within each module alphabetically by label
    Object.keys(grouped).forEach(module => {
      grouped[module].sort((a: any, b: any) => 
        (a.label || a.key).localeCompare(b.label || b.key)
      );
    });
  }

  // Return as sorted object with sorted module names
  return Object.fromEntries(
    Object.entries(grouped).sort(([a], [b]) => a.localeCompare(b))
  );
};

export default function LeftSidebar() {
  const theme = useTheme()
  const { nodeRegistry } = useNodeRegistryState(selectNodeRegistryState, shallow);
  const { mode, nodes, edges } = useNodeState(selectNodeState, shallow);

  const [localMode, setLocalMode] = useState<WorkflowType>(mode);

  // Sync localMode with store mode
  useEffect(() => {
    setLocalMode(mode);
  }, [mode]);

  // handle toggle
  const handleModeChange = (_: any, newMode: WorkflowType | null) => {
    if (!newMode) return; // user clicked same toggle
    
    // 1) Save the old mode
    useNodeState.getState().updateLocalStorage();
    
    // 2) Switch mode in the store
    useNodeState.setState({ mode: newMode });
    setLocalMode(newMode); // keep local UI state in sync

    // 3) Load from the new mode's local storage
    useNodeState.getState().loadWorkflowFromStorage();
  };

  // Local node search state, the code will hide the nodes that don't match the search term instead of removing them from the DOM
  const [searchTerm, setSearchTerm] = useState('')
  const filteredNodes = useMemo(() => {
    const searchTerms = searchTerm.toLowerCase().split(/\s+/).filter(term => term.length > 0);
    if (searchTerms.length === 0) return null;

    return Object.keys(nodeRegistry).filter((key) => {
      const label = nodeRegistry[key].label.toLowerCase();
      return searchTerms.every(term => label.includes(term));
    })
  }, [nodeRegistry, searchTerm])

  // Drag and drop functionality
  const onDragStart = (event: React.DragEvent<HTMLLIElement>, key: string) => {
    event.dataTransfer.setData('text/plain', key);
    event.dataTransfer.effectAllowed = 'move';
  }

  // Tab state
  const [tabValue, setTabValue] = useState(0);
  const handleTabChange = (_: any, newValue: number) => {
    setTabValue(newValue);
  };

  const groupedNodes = useMemo(() => {
    // First filter by mode
    const filteredByMode = Object.fromEntries(
      Object.entries(nodeRegistry).filter(([_, nodeData]) => {
        if (mode === 'tool') {
          return nodeData.type === 'tool';
        } else {
          // "workflow" mode => show nodes with type === "workflow" OR no type
          return !nodeData.type || nodeData.type === 'workflow';
        }
      })
    );

    // Then group the filtered nodes
    const grouped = tabValue === 0 ? groupBy('module', filteredByMode) : groupBy('category', filteredByMode);

    // If there's a search filter, only include nodes that match
    if (filteredNodes) {
      return Object.fromEntries(
        Object.entries(grouped).map(([module, nodes]: [string, any]) => [
          module,
          nodes.filter((node: any) => filteredNodes.includes(node.key))
        ]).filter(([_, nodes]) => nodes.length > 0)
      );
    }

    return grouped;
  }, [nodeRegistry, filteredNodes, tabValue, mode]);

  return (
    <Box
      className="left-sidebar"
      textAlign="center"
      sx={{
        width: sidebarWidth,
        height: '100%',
        display: 'flex',
        flexDirection: 'column',
        backgroundColor: theme.palette.background.paper,
        borderRight: `1px solid ${theme.palette.divider}`,
      }}
    >
      <Box sx={{ p: 1.5, borderBottom: `1px solid ${theme.palette.divider}` }}>
        <ToggleButtonGroup
          value={localMode}
          exclusive
          onChange={handleModeChange}
          size="small"
          fullWidth
          sx={{ mb: 1.5 }}
        >
          <ToggleButton value="workflow">Workflow</ToggleButton>
          <ToggleButton value="tool">Tool</ToggleButton>
        </ToggleButtonGroup>
        <OutlinedInput
          startAdornment={<SearchIcon fontSize="small" sx={{ marginRight: 1 }} />}
          id="main-module-search"
          placeholder="Search"
          size="small"
          value={searchTerm}
          onChange={(e) => setSearchTerm(e.target.value)}
          sx={{ width: '100%', fontSize: '14px' }}
        />
      </Box>
      <Box sx={{ width: '100%' }}>
        <Tabs
          value={tabValue}
          onChange={handleTabChange}
          variant="fullWidth"
          sx={{
            lineHeight: '16px',
            minHeight: 0,
            borderBottom: `1px solid ${theme.palette.divider}`,
            '.MuiButtonBase-root': { textTransform: 'none', lineHeight: '16px', minHeight: 0 }
          }}
        >
          <Tab label="Modules" />
          <Tab label="Categories" />
        </Tabs>
      </Box>
      <Box sx={{
        flex: 1,
        overflowY: 'auto',
        p: 0, m: 0,
      }}>
        <Box sx={{ p: 0, pb: 0, m: 0 }}>
          {Object.entries(groupedNodes).map(([module, nodes]: [string, any]) => (
            <Accordion disableGutters key={module} sx={{
              borderBottom: `1px solid ${theme.palette.divider}`,
              boxShadow: 'none',
              backgroundColor: theme.palette.background.paper,
              fontSize: 12,
              p: 0, m: 0,
              '&:before': {
                backgroundColor: 'transparent',
              },
              '.MuiAccordionSummary-root': {
                backgroundColor: theme.palette.background.paper,
                '&:hover': {
                  backgroundColor: theme.palette.mode === 'light' 
                    ? 'rgba(0, 0, 0, 0.04)' 
                    : 'rgba(255, 255, 255, 0.1)',
                },
              },
              '.MuiAccordionDetails-root': {
                backgroundColor: theme.palette.background.paper,
                padding: '8px 4px',
              },
            }}>
              <AccordionSummary expandIcon={<ExpandMoreIcon />}>{module.replace(/[_-]/g, ' ').replace(/\b\w/g, char => char.toUpperCase())}</AccordionSummary>
              <AccordionDetails>
                <List dense={true} sx={{ p: 1.5, pt: 0, pb: 0, m: 0 }}>
                  {nodes.map((node: any) => (
                    <ListItem
                      key={node.key}
                      draggable
                      className={`${node.key} category-${node.category} module-${node.module}`}
                      onDragStart={(event) => onDragStart(event, node.key)}
                      sx={{
                        outline: `1px solid ${theme.palette.divider}`,
                        borderRadius: 1,
                        boxShadow: 3,
                        m: 0, mb: 1,
                        p: 0.5, pl: 1,
                        borderLeftWidth: '8px',
                        borderLeftStyle: 'solid',
                        cursor: 'grab',
                        display: !filteredNodes || filteredNodes.includes(node.key) ? 'flex' : 'none',
                      }}
                    >
                      <ListItemText primary={node.label || node.key} sx={{ '& .MuiTypography-root': { fontSize: 12 } }} />
                    </ListItem>
                  ))}
                </List>
              </AccordionDetails>
            </Accordion>
          ))}
        </Box>
      </Box>
    </Box>
  )
}


================================================================================
FILE: ./client/src/components/WebsocketContext.tsx
================================================================================

import React, { createContext, useContext } from 'react';
import { WebsocketState, useWebsocketState } from '../stores/websocketStore';

const WebSocketContext = createContext<WebsocketState | null>(null);

export function WebSocketProvider({ children }: { children: React.ReactNode }) {
    const store = useWebsocketState();
    return (
        <WebSocketContext.Provider value={store}>
            {children}
        </WebSocketContext.Provider>
    );
}

export function useWebSocket() {
    const context = useContext(WebSocketContext);
    if (!context) {
        throw new Error('useWebSocket must be used within a WebSocketProvider');
    }
    return context;
}

================================================================================
FILE: ./client/src/components/utils/deepEqual.ts
================================================================================


export const deepEqual = (a: any, b: any): boolean => {
    if (a === b) return true;
    if (a == null || b == null) return false;

    const bothAreObjects = a && b && typeof a === "object" && typeof b === "object";
    return bothAreObjects &&
        Object.keys(a).length === Object.keys(b).length &&
        Object.keys(a).every(key => deepEqual(a[key], b[key]));
};


================================================================================
FILE: ./client/src/components/utils/groupParams.ts
================================================================================

import type { NodeParams, GroupParams } from '../../stores/nodeStore';

interface GroupedParam {
    display: 'group' | 'collapse';
    label: string | null;
    hidden: boolean;
    disabled: boolean;
    open: boolean;
    direction: 'row' | 'column';
    params: Record<string, NodeParams>;
}

const createGroupConfig = (group: GroupParams): GroupParams => {
    if (typeof group === 'string') {
        return { key: `${group}_group`, display: 'group' };
    }
    
    return {
        key: `${group.key || 'untitled'}_group`,
        display: group.display || 'group',
        label: group.label || null,
        hidden: group.hidden || false,
        disabled: group.disabled || false,
        open: group.open || false,
        direction: group.direction || 'row',
    };
};

const createGroupedParam = (config: GroupParams): GroupedParam => ({
    display: config.display || 'group',
    label: config.label || null,
    hidden: config.hidden || false,
    disabled: config.disabled || false,
    open: config.open || false,
    direction: config.direction || 'row',
    params: {},
});

/*
    Group fields by data.params.group.

    Convert group from:
    'seed': { ... }, 'width': { ... group: 'dimensions' }, 'height': { ... group: 'dimensions' }

    To:
    'seed': { ... }, 'dimensions_group': { ... , 'params': { 'width': { ... }, 'height': { ... } } }

    This complication is to keep all fields on the same level and avoid nested objects
*/
export const groupParams = (params: Record<string, NodeParams>): Record<string, NodeParams | GroupedParam> => {
    return Object.entries(params).reduce<Record<string, NodeParams | GroupedParam>>(
        (acc, [key, data]) => {
            if (!data.group) {
                acc[key] = data;
                return acc;
            }

            const groupConfig = createGroupConfig(data.group);

            if (!acc[groupConfig.key]) {
                acc[groupConfig.key] = createGroupedParam(groupConfig);
            }
            
            (acc[groupConfig.key] as GroupedParam).params[key] = data;
            return acc;
        }, 
        {}
    );
};

export type { GroupParams };


================================================================================
FILE: ./client/src/components/fields/AccordionField.tsx
================================================================================

import { styled } from "@mui/material/styles"
import Accordion from "@mui/material/Accordion";
import AccordionSummary from "@mui/material/AccordionSummary";
import AccordionDetails from "@mui/material/AccordionDetails";
import ExpandMoreIcon from '@mui/icons-material/ExpandMore';

import NodeContent from "../NodeContent";

import { GroupProps } from "../NodeContent";

const PlainAccordion = styled(Accordion)(({ theme }) => ({
    boxShadow: 'none',
    border: 0,
    padding: 0,
    margin: 0,
    background: 'transparent',
    borderBottom: `1px solid ${theme.palette.divider}`,
    '&:before': { background: 'transparent' },
    '.MuiAccordionSummary-root': { padding: '0 4px', margin: 0, background: 'transparent', color: theme.palette.text.secondary, minHeight: '0', border: 'none' },
    '.MuiAccordionDetails-root': { padding: 0, margin: 0, border: 'none' },
    '.MuiAccordionSummary-root:hover, .MuiAccordionSummary-root:hover .MuiAccordionSummary-expandIconWrapper': { color: theme.palette.primary.main },
}));

const AccordionField = (
    { fieldKey, label, open, disabled, hidden, style, fields, updateStore }: GroupProps
) => {
    return (
        <PlainAccordion
            data-key={fieldKey}
            disableGutters={true}
            square={true}
            className={`nodrag ${disabled ? 'mellon-disabled' : ''} ${hidden ? 'mellon-hidden' : ''}`}
            expanded={open}
            onChange={(_, expanded) => {
                updateStore(fieldKey, { open: expanded }, 'group');
            }}
            sx={{ ...style }}
        >
            <AccordionSummary expandIcon={<ExpandMoreIcon />}>
                {label || fieldKey}
            </AccordionSummary>
            <AccordionDetails>
                <NodeContent
                    fields={fields}
                    updateStore={updateStore}
                    parentDisabled={disabled}
                />
            </AccordionDetails>
        </PlainAccordion>
    )
}

export default AccordionField;

================================================================================
FILE: ./client/src/components/fields/AutocompleteField.tsx
================================================================================

import Box from "@mui/material/Box";
import Autocomplete from "@mui/material/Autocomplete";
import TextField from "@mui/material/TextField";

import { FieldProps } from "../NodeContent";

const AutocompleteField = ({ fieldKey, value, style, disabled, hidden, label, no_validation, options, updateStore }: FieldProps) => {
    return (
        <Box
            data-key={fieldKey}
            sx={{ minWidth: '320px', ...style }}
            className={`nodrag nowheel ${disabled ? 'mellon-disabled' : ''} ${hidden ? 'mellon-hidden' : ''}`}
        >
            <Autocomplete
                disablePortal
                freeSolo={no_validation}
                options={options}
                renderInput={(params: any) => <TextField {...params} label={label} />}
                onChange={(_, value) => updateStore?.(fieldKey, value)}
                value={value}
                size="small"
                sx={{ '& + .MuiAutocomplete-popper .MuiAutocomplete-option': { fontSize: '12px' } }}
            />
        </Box>
    );
}

export default AutocompleteField;

================================================================================
FILE: ./client/src/components/fields/ColorPicker.tsx
================================================================================

import { Box, Stack, Typography, InputBase } from "@mui/material";
import { useTheme } from "@mui/material/styles";
import { useEffect, useRef, useState } from "react";
import { FieldProps } from "../NodeContent";

interface HSL {
  h: number;
  s: number;
  l: number;
}

function hexToHsl(hex: string): HSL {
  let c = hex.replace("#", "").trim();
  if (c.length === 3) {
    c = c[0] + c[0] + c[1] + c[1] + c[2] + c[2];
  }
  if (!/^[0-9a-fA-F]{6}$/.test(c)) {
    return { h: 0, s: 0, l: 0 };
  }

  const r = parseInt(c.substring(0, 2), 16) / 255;
  const g = parseInt(c.substring(2, 4), 16) / 255;
  const b = parseInt(c.substring(4, 6), 16) / 255;

  const max = Math.max(r, g, b);
  const min = Math.min(r, g, b);
  let h = 0,
    s = 0,
    l = (max + min) / 2;

  const d = max - min;
  if (d !== 0) {
    s = l > 0.5 ? d / (2 - max - min) : d / (max + min);
    switch (max) {
      case r:
        h = (g - b) / d + (g < b ? 6 : 0);
        break;
      case g:
        h = (b - r) / d + 2;
        break;
      case b:
        h = (r - g) / d + 4;
        break;
    }
    h *= 60;
  }
  return { h, s, l };
}

function hslToHex({ h, s, l }: HSL): string {
  h = (h % 360 + 360) % 360;
  const c = (1 - Math.abs(2 * l - 1)) * s;
  const x = c * (1 - Math.abs(((h / 60) % 2) - 1));
  const m = l - c / 2;

  let r = 0,
    g = 0,
    b = 0;
  if (0 <= h && h < 60) {
    r = c;
    g = x;
    b = 0;
  } else if (60 <= h && h < 120) {
    r = x;
    g = c;
    b = 0;
  } else if (120 <= h && h < 180) {
    r = 0;
    g = c;
    b = x;
  } else if (180 <= h && h < 240) {
    r = 0;
    g = x;
    b = c;
  } else if (240 <= h && h < 300) {
    r = x;
    g = 0;
    b = c;
  } else if (300 <= h && h < 360) {
    r = c;
    g = 0;
    b = x;
  }

  const toHex = (v: number) => {
    const hex = Math.round((v + m) * 255).toString(16);
    return hex.length === 1 ? `0${hex}` : hex;
  };

  return `#${toHex(r)}${toHex(g)}${toHex(b)}`;
}

function ColorPicker({
  fieldKey,
  value,
  style,
  disabled,
  hidden,
  label,
  updateStore,
}: FieldProps) {
  const theme = useTheme();
  const [color, setColor] = useState<HSL>(hexToHsl(value as string || "#000000"));
  const pickerRef = useRef<HTMLDivElement>(null);
  const hueRef = useRef<HTMLDivElement>(null);
  const slRef = useRef<HTMLDivElement>(null);

  const handleSLClick = (e: React.MouseEvent) => {
    if (!slRef.current || disabled) return;
    const rect = slRef.current.getBoundingClientRect();
    const x = Math.max(0, Math.min(1, (e.clientX - rect.left) / rect.width));
    const y = Math.max(0, Math.min(1, (e.clientY - rect.top) / rect.height));
    const newColor = { ...color, s: x, l: 1 - y };
    setColor(newColor);
    updateStore?.(fieldKey, hslToHex(newColor));
  };

  const handleHueClick = (e: React.MouseEvent) => {
    if (!hueRef.current || disabled) return;
    const rect = hueRef.current.getBoundingClientRect();
    const x = Math.max(0, Math.min(1, (e.clientX - rect.left) / rect.width));
    const newColor = { ...color, h: x * 360 };
    setColor(newColor);
    updateStore?.(fieldKey, hslToHex(newColor));
  };

  // Update color when the value prop changes
  useEffect(() => {
    setColor(hexToHsl(value as string || "#000000"));
  }, [value]);

  return (
    <Box
      className={`${hidden ? "mellon-hidden" : ""} ${
        disabled ? "mellon-disabled" : ""
      }`}
      ref={pickerRef}
      sx={{ 
        position: "relative",
        ...style,
      }}
    >
      <Stack spacing={1} sx={{ p: 0.5 }}>
        <Stack
          direction="row"
          spacing={1}
          alignItems="center"
          sx={{
            height: 28,
            px: 1,
          }}
        >
          <Box
            sx={{
              width: 20,
              height: 20,
              borderRadius: 0.5,
              backgroundColor: hslToHex(color),
              border: `1px solid ${theme.palette.divider}`,
              flexShrink: 0,
            }}
          />
          <Typography
            sx={{
              fontSize: 13,
              color: theme.palette.text.secondary,
              flexGrow: 1,
              overflow: "hidden",
              textOverflow: "ellipsis",
              whiteSpace: "nowrap",
            }}
          >
            {label}
          </Typography>
          <InputBase
            value={hslToHex(color)}
            size="small"
            sx={{
              width: 72,
              flexShrink: 0,
              input: {
                textAlign: "right",
                fontSize: 13,
                p: 0,
              },
            }}
            onChange={(e) => {
              const newColor = hexToHsl(e.target.value);
              setColor(newColor);
              updateStore?.(fieldKey, hslToHex(newColor));
            }}
          />
        </Stack>

        {/* Saturation/Lightness picker */}
        <Box
          ref={slRef}
          onClick={handleSLClick}
          sx={{
            position: "relative",
            width: "100%",
            height: 120,
            borderRadius: 1,
            cursor: disabled ? "default" : "crosshair",
            background: `
              linear-gradient(to right, #fff 0%, hsl(${color.h}, 100%, 50%) 100%),
              linear-gradient(to bottom, rgba(0,0,0,0) 0%, #000 100%)
            `,
            backgroundBlendMode: "multiply",
            opacity: disabled ? 0.5 : 1,
            userSelect: "none",
          }}
        >
          <Box
            sx={{
              position: "absolute",
              width: 10,
              height: 10,
              border: "2px solid white",
              borderRadius: "50%",
              transform: "translate(-50%, -50%)",
              left: `${color.s * 100}%`,
              top: `${(1 - color.l) * 100}%`,
              pointerEvents: "none",
              boxShadow: "0 0 0 1px rgba(0,0,0,0.3)",
            }}
          />
        </Box>

        {/* Hue slider */}
        <Box
          ref={hueRef}
          onClick={handleHueClick}
          sx={{
            position: "relative",
            width: "100%",
            height: 12,
            borderRadius: 1,
            cursor: disabled ? "default" : "pointer",
            background:
              "linear-gradient(to right, #f00 0%, #ff0 17%, #0f0 33%, #0ff 50%, #00f 67%, #f0f 83%, #f00 100%)",
            opacity: disabled ? 0.5 : 1,
            userSelect: "none",
          }}
        >
          <Box
            sx={{
              position: "absolute",
              width: 4,
              height: 12,
              backgroundColor: "white",
              border: `1px solid ${theme.palette.divider}`,
              transform: "translateX(-50%)",
              left: `${(color.h / 360) * 100}%`,
              pointerEvents: "none",
              boxShadow: "0 0 0 1px rgba(0,0,0,0.3)",
            }}
          />
        </Box>
      </Stack>
    </Box>
  );
}

export default ColorPicker;


================================================================================
FILE: ./client/src/components/fields/CustomField.tsx
================================================================================

import React from "react";
import Box from "@mui/material/Box";
import { useEffect, useState } from "react";
import { FieldProps } from "../NodeContent";
import config from "../../../config";
import { useTheme } from "@mui/material/styles";
import * as MaterialUI from "@mui/material";
import * as MaterialStyles from "@mui/material/styles";

const DynamicComponent = ({ component, props }: { component: string | undefined, props: any }) => {
    const [Comp, setComp] = useState<React.ComponentType<any> | null>(null);
    const w = window as any;
    // Get the ID without .js for window lookup, but keep original path for URL
    const componentId = component?.split('/').pop()?.replace('.js', '');
    if (!component || !componentId) {
        console.error('The component must be in the format of `module/component`');
        return <Box>Error loading component</Box>;
    }

    useEffect(() => {
        // expose React to the custom component
        if (w.React === undefined) {
            w.React = React;
        }

        // expose MaterialUI to the custom component
        if (w.MaterialUI === undefined) {
            w.MaterialUI = {
                ...MaterialUI,
                styles: MaterialStyles
            };
        }

        // Track script instances globally
        if (w.mellonCustomScripts === undefined) {
            w.mellonCustomScripts = new Map();
        }

        const loadComponent = async () => {
            try {
                // check if the script is already loaded
                const existingScript = w.mellonCustomScripts.get(component);
                if (existingScript) {
                    await existingScript;
                } else {
                    const loadPromise = new Promise((resolve, reject) => {
                        const script = document.createElement('script');
                        // Ensure we keep the .js extension in the URL
                        script.src = `http://${config.serverAddress}/custom/${component}${component.endsWith('.js') ? '' : '.js'}`;
                        script.async = true;
                        script.onload = () => {
                            let attempts = 0;
                            const maxAttempts = 5;
                            const checkComponent = () => {
                                const LoadedComponent = w.CustomFieldExample;
                                if (typeof LoadedComponent === 'function') {
                                    resolve(LoadedComponent);
                                } else if (attempts < maxAttempts) {
                                    attempts++;
                                    setTimeout(checkComponent, 100);
                                } else {
                                    reject(new Error(`Component ${componentId} is not a function after ${maxAttempts} attempts`));
                                }
                            };
                            checkComponent();
                        };
                        script.onerror = (event) => {
                            console.error('Error loading component:', event);
                            reject(event);
                        };
                        script.id = componentId;
                        document.body.appendChild(script);
                    });

                    // Wait for script to load
                    w.mellonCustomScripts.set(component, loadPromise);
                    const LoadedComponent = await loadPromise;
                    setComp(() => LoadedComponent as React.ComponentType<any>);
                }
            } catch (error) {
                console.error('Error loading component:', error);
                w.mellonCustomScripts?.delete(component);
            }
        };

        // if the componentId is already in the window, use it
        const existingComponent = w[componentId];
        if (typeof existingComponent === 'function') {
            setComp(() => existingComponent);
        } else {
            loadComponent();
        }

        // Cleanup
        return () => {
            const script = document.getElementById(componentId);
            if (script && !document.querySelector(`[data-component="${componentId}"]`)) {
                document.body.removeChild(script);
                w.mellonCustomScripts?.delete(component);
            }
            // if mellonCustomScripts is empty or undefined we can also remove React from the window
            if (!w.mellonCustomScripts || w.mellonCustomScripts.size === 0) {
                if (w.mellonCustomScripts) {
                    delete w.mellonCustomScripts;
                }
                delete w.React;
                delete w.MaterialUI;
            }
        };
    }, [component, componentId]);

    if (!Comp) {
        return <Box>Loading...</Box>;
    }

    return (
        <Box data-component={componentId}>
            <Comp {...props} />
        </Box>
    );
}

const CustomField = ({ fieldKey, value, style, disabled, hidden, label, updateStore, source }: FieldProps) => {
    const setValue = (v: any) => updateStore?.(fieldKey, v);
    const theme = useTheme();

    return (
        <Box
            data-key={fieldKey}
            className={`nodrag nowheel ${disabled ? 'mellon-disabled' : ''} ${hidden ? 'mellon-hidden' : ''}`}
            sx={{ ...style }}
        >
            <DynamicComponent
                component={source}
                props={{
                    fieldKey,
                    value,
                    label,
                    setValue,
                    theme,
                }}
            />
        </Box>
    );
}

export default CustomField;

================================================================================
FILE: ./client/src/components/fields/GroupField.tsx
================================================================================

import Stack from "@mui/material/Stack";
import Box from "@mui/material/Box";
import Typography from "@mui/material/Typography";
import NodeContent from "../NodeContent";

import { GroupProps } from "../NodeContent";
import { useTheme } from "@mui/material/styles";


const GroupField = (
    { fieldKey, label, direction, disabled, hidden, style, fields, updateStore }: GroupProps
) => {
    const alignItems = direction === 'column' ? 'stretch' : 'center';
    const spacing = direction === 'column' ? 0 : 1;

    const theme = useTheme();

    if (label) {
        return (
            <Box
                data-key={fieldKey}
                sx={{
                    borderBottom: `1px solid ${theme.palette.divider}`,
                    pt: 0.5, pb: 0,
                    ...style,
                }}
                className={`labelled-group ${disabled ? 'mellon-disabled' : ''} ${hidden ? 'mellon-hidden' : ''}`}
            >
                <Typography sx={{ pb: 1, color: theme.palette.text.secondary, textOverflow: 'ellipsis', overflow: 'hidden', whiteSpace: 'nowrap' }}>
                    {label}
                </Typography>
                <Stack
                    direction={direction}
                    spacing={spacing}
                    sx={{
                        '& > .MuiBox-root': { flex: "1" },
                        '& > .flex-auto': { flex: "0 0 auto" },
                        justifyContent: "space-between",
                        alignItems: alignItems,
                    }}
                >
                    <NodeContent
                        fields={fields}
                        updateStore={updateStore}
                        parentDisabled={disabled}
                    />
                </Stack>
            </Box>
        )
    }

    return (
        <Stack
            data-key={fieldKey}
            direction={direction}
            spacing={spacing}
            sx={{
                '& > .MuiBox-root': { flex: "1" },
                '& > .flex-auto': { flex: "0 0 auto" },
                justifyContent: "space-between",
                alignItems: alignItems,
                ...style,
            }}
            className={`${disabled ? 'mellon-disabled' : ''} ${hidden ? 'mellon-hidden' : ''}`}
        >
            <NodeContent
                fields={fields}
                updateStore={updateStore}
                parentDisabled={disabled}
            />
        </Stack>
    )
}

export default GroupField;


================================================================================
FILE: ./client/src/components/fields/HandleField.tsx
================================================================================

import { Handle, Position } from "@xyflow/react";
import Typography from "@mui/material/Typography";
import Box from "@mui/material/Box";
import { FieldProps } from "../NodeContent";

const InputHandle = ({ fieldKey, label, style, disabled, hidden, dataType }: FieldProps) => {
    return (
        <Box
            data-key={fieldKey}
            sx={{ position: 'relative', ...style }}
            className={`${disabled ? 'mellon-disabled' : ''} ${hidden ? 'mellon-hidden' : ''}`}
        >
            <Handle
                id={fieldKey}
                type="target"
                position={Position.Left}
                className={`${dataType}-handle`}
                style={{ marginTop: '-4px' }}
            />
            <Typography sx={{ pl: 1 }}>{label}</Typography>
        </Box>
    )
}

const OutputHandle = ({ fieldKey, label, style, disabled, hidden, dataType }: FieldProps) => {
    return (
        <Box
            data-key={fieldKey}
            sx={{ position: 'relative', ...style }}
            className={`${disabled ? 'mellon-disabled' : ''} ${hidden ? 'mellon-hidden' : ''}`}
        >
            <Handle
                id={fieldKey}
                type="source"
                position={Position.Right}
                className={`${dataType}-handle`}
                style={{ marginTop: '-4px' }}
            />
            <Typography sx={{ textAlign: 'right', pr: 1 }}>{label}</Typography>
        </Box>
    )
}

const HandleField = ({ fieldType, fieldKey, label, style, disabled, hidden, dataType }: FieldProps) => {
    const HandleElement = fieldType === 'input' ? InputHandle : OutputHandle;

    return (
        <HandleElement
            fieldKey={fieldKey}
            label={label}
            style={style}
            disabled={disabled}
            hidden={hidden}
            dataType={dataType}
        />
    );
}

export default HandleField;

================================================================================
FILE: ./client/src/components/fields/IconToggleField.tsx
================================================================================

import { useEffect } from "react";

import Box from "@mui/material/Box";
import Checkbox from "@mui/material/Checkbox";
import { FieldProps } from "../NodeContent";
import { useTheme } from "@mui/material/styles";

import AutoFixHighIcon from '@mui/icons-material/AutoFixHigh';

const IconToggleField = ({ fieldKey, value, style, disabled, hidden, label, icon, onChangeAction, updateStore }: FieldProps) => {
    const theme = useTheme();

    const iconsMap = {
        'random': <AutoFixHighIcon />,
    }

    const MuiIcons = {
        icon: iconsMap[icon as keyof typeof iconsMap],
        checkedIcon: iconsMap[icon as keyof typeof iconsMap],
    }

    const handleDisableAction = (value: boolean, target: any) => {
        const onTrueTargets = Array.isArray(target.true) ? target.true : [target.true];
        const onFalseTargets = Array.isArray(target.false) ? target.false : [target.false];

        onTrueTargets.forEach((field: string) => {
            updateStore?.(field, value, 'disabled');
        });
        onFalseTargets.forEach((field: string) => {
            updateStore?.(field, !value, 'disabled');
        });
    };

    useEffect(() => {
        if (onChangeAction && onChangeAction.action === 'disable') {
            handleDisableAction(value, onChangeAction.target);
        }
    }, [value]);

    return (
        <Box
            data-key={fieldKey}
            className={`flex-auto nodrag ${disabled ? 'mellon-disabled' : ''} ${hidden ? 'mellon-hidden' : ''}`}
            sx={{ ...style }}
        >
            <Checkbox
                size="small"
                {...MuiIcons}
                checked={value}
                title={label}
                onChange={(e) => updateStore?.(fieldKey, e.target.checked)}
                disableRipple
                sx={{
                    p: 1.1,
                    m: 0,
                    border: 1,
                    borderRadius: 1,
                    borderColor: "rgba(255,255,255,0.25)",
                    '&.Mui-checked': {
                        backgroundColor: theme.palette.secondary.main,
                        color: theme.palette.background.paper,
                        borderColor: theme.palette.secondary.main,
                    }
                }}
            />
        </Box>
    )
}

export default IconToggleField;

================================================================================
FILE: ./client/src/components/fields/NumberField.tsx
================================================================================

import Stack from "@mui/material/Stack";
import IconButton from "@mui/material/IconButton";
import Box from "@mui/material/Box";
import Typography from "@mui/material/Typography";
import InputBase from "@mui/material/InputBase";
import ChevronLeftIcon from "@mui/icons-material/ChevronLeft";
import ChevronRightIcon from "@mui/icons-material/ChevronRight";
import { FieldProps } from "../NodeContent";
import { useTheme } from '@mui/material/styles';
import { useEffect, useRef, useState } from "react";

const NumberField = ({
    fieldKey,
    fieldType,
    dataType,
    value,
    style,
    disabled,
    hidden,
    label,
    min,
    max,
    step,
    updateStore,
}: FieldProps) => {
    const theme = useTheme();
    const inputRef = useRef<HTMLInputElement>();
    const dragStartRef = useRef({ x: 0, value: 0 });
    const isDraggingRef = useRef(false);
    const [isEditing, setIsEditing] = useState(false);

    const displaySlider = fieldType === 'slider' && min !== undefined && max !== undefined;
    const minValue = min !== undefined ? min : -Number.MAX_SAFE_INTEGER;
    const maxValue = max !== undefined ? max : Number.MAX_SAFE_INTEGER;
    const decimals = dataType === 'float' ? (step?.toString()?.split('.')?.[1]?.length || 1) : 0;
    const increment = step !== undefined ? step : (dataType === 'float' ? 0.1 : 1);

    const formatValue = (value: number | string) => {
        if ( isEditing ) {
            return value;
        }

        const newValue = isNaN(Number(value)) ? 0 : Number(value);
        return Math.min(maxValue, Math.max(minValue, newValue)).toFixed(decimals)
    };

    const inputValue = formatValue(value || 0); // we use Zustand for the value and it's already memoized

    const getSliderStyle = () => {
        if (!displaySlider) return {};

        const sliderPercent = isNaN(Number(inputValue)) ? 0 : ((Number(inputValue) - minValue) / (maxValue - minValue) * 100);
        const baseColor = 'rgba(255,255,255,0.15)';
        const gradientStyle = `linear-gradient(to right, ${baseColor} ${sliderPercent}%, rgba(255,255,255,0.0) ${sliderPercent}%)`;

        return {
            background: gradientStyle,
        };
    };

    const handleMouseMove = (e: React.MouseEvent) => {
        e.preventDefault();
        e.stopPropagation();

        const delta = e.clientX - dragStartRef.current.x;

        // ignore small movements
        if (Math.abs(delta) < 2) return;

        if (!isDraggingRef.current) {
            isDraggingRef.current = true;
        }

        const inputElement = inputRef.current;

        // we are dragging, so we remove the focus from the input
        if (document.activeElement === inputElement) {
            inputElement?.blur();
            setIsEditing(false);
        }

        const range = maxValue - minValue;
        const steps = range / increment || 100;
        const valueRange = displaySlider ? steps / 250 * delta : delta;
        const newValue = dragStartRef.current.value + valueRange*increment;

        updateStore?.(fieldKey, formatValue(newValue));
    };

    const handleMouseUp = (e: React.MouseEvent) => {
        document.removeEventListener('mousemove', handleMouseMove as any);
        document.removeEventListener('mouseup', handleMouseUp as any);
        
        const currentTarget = (e.target as HTMLElement).closest('.numberField');
        const closestTarget = (e.target as HTMLElement).closest('button');

        if (currentTarget && displaySlider && !isDraggingRef.current && !closestTarget) {
            const rect = currentTarget.getBoundingClientRect();

            const x = e.clientX - rect.left;
            const relPos = Math.max(0, Math.min(1, x / rect.width));
            const newValue = formatValue(minValue + (maxValue - minValue) * relPos);
            updateStore?.(fieldKey, newValue);
        }
        
        isDraggingRef.current = false;
    };

    const handleMouseDown = (e: React.MouseEvent) => {
        e.preventDefault();
        e.stopPropagation();

        // Only handle left mouse button
        if (e.button !== 0) return;

        // if we are already editing, don't do anything
        if (isEditing) return;

        // blur any currently focused element
        (document.activeElement as HTMLElement)?.blur();

        dragStartRef.current = { x: e.clientX, value: Number(inputValue) };

        document.addEventListener('mousemove', handleMouseMove as any);
        document.addEventListener('mouseup', handleMouseUp as any);
    };

    const handleBlur = () => {
        const inputElement = inputRef.current;
        setIsEditing(false);

        if (!inputElement) return;

        if (Number(inputElement.value) !== Number(inputValue)) {
            updateStore?.(fieldKey, formatValue(inputElement.value));
        }

        // trick to force a re-render otherwise the style won't update on blur in some edge cases
        const currentValue = inputElement.value;
        updateStore?.(fieldKey, formatValue(' ' + currentValue));
        updateStore?.(fieldKey, formatValue(currentValue));

        inputElement.removeEventListener('keydown', handleKeyDown as any);
    };

    const handleKeyDown = (e: React.KeyboardEvent) => {
        const inputElement = inputRef.current;

        if (!inputElement) return;

        if (e.key === 'Enter' || e.key === 'Escape') {
            inputElement.removeEventListener('keydown', handleKeyDown as any);

            setIsEditing(false);
            updateStore?.(fieldKey, formatValue(inputElement.value || ''));
            inputElement.blur();
        } else if (e.key === 'ArrowUp') {
            e.preventDefault();
            const newValue = Math.min(maxValue, Math.max(minValue, Number(inputElement.value) + increment)).toFixed(decimals);
            inputElement.value = String(newValue);
            updateStore?.(fieldKey, newValue);
        } else if (e.key === 'ArrowDown') {
            e.preventDefault();
            const newValue = Math.min(maxValue, Math.max(minValue, Number(inputElement.value) - increment)).toFixed(decimals);
            inputElement.value = String(newValue);
            updateStore?.(fieldKey, newValue);
        }
    };

    const handleDoubleClick = (e: React.MouseEvent) => {
        // ignore double clicks on buttons
        if ((e.target as HTMLElement).closest('button')) return;

        const inputElement = inputRef.current;
        if (!inputElement) return;

        inputElement.focus();
        inputElement.select();
        setIsEditing(true);

        inputElement.addEventListener('keydown', handleKeyDown as any);
    };

    useEffect(() => {
        const inputElement = inputRef.current;
        if (inputElement === document.activeElement) {
            inputElement.focus();
            setIsEditing(true);
        } else {
            inputElement?.blur();
            setIsEditing(false);
        }

        return () => {
            document.removeEventListener('mousemove', handleMouseMove as any);
            document.removeEventListener('mouseup', handleMouseUp as any);

            const inputElement = inputRef.current;
            if (inputElement) {
                inputElement.removeEventListener('keydown', handleKeyDown as any);
            }
        };
    }, [isEditing, inputRef]);

    return (
        <Box className={`${hidden ? 'mellon-hidden' : ''} ${disabled ? 'mellon-disabled' : ''}`}>
            <Stack
                data-key={fieldKey}
                direction="row"
                spacing={0.5}
                className={`numberField nodrag`}
                onMouseDown={handleMouseDown}
                onDoubleClick={handleDoubleClick}
                sx={{
                    mb: 0,
                    p: 0.6,
                    width: '100%',
                    justifyContent: 'space-between',
                    alignItems: 'center',
                    borderRadius: 1,
                    overflow: 'hidden',
                    userSelect: 'none',
                    cursor: 'default',
                    outline: isEditing ? `2px solid ${theme.palette.primary.main}` : "1px solid #4f4f4f",
                    '&:hover': {
                        outline: isEditing ? `2px solid ${theme.palette.primary.main}` : `1px solid ${theme.palette.common.white}`,
                    },
                    ...getSliderStyle(),
                    ...style
                }}
            >
                <IconButton
                    size="small"
                    disableRipple // ripple effect is buggy
                    onClick={() => { inputRef.current?.blur(); updateStore?.(fieldKey, formatValue(Number(inputRef.current?.value) - increment)) }}
                    sx={{
                        p: 0.5,
                        borderRadius: 1,
                        opacity: Number(inputValue) <= minValue ? 0.4 : 1,
                        '&:hover': { background: Number(inputValue) <= minValue ? '' : 'rgba(255,255,255,0.15)' }
                    }}
                >
                    <ChevronLeftIcon fontSize="small" />
                </IconButton>
                <Box sx={{ maxWidth: '50%', pointerEvents: 'none' }}>
                    <Typography sx={{ fontSize: 13, color: theme.palette.text.secondary, textOverflow: 'ellipsis', overflow: 'hidden', whiteSpace: 'nowrap' }} title={label}>{label}</Typography>
                </Box>
                <InputBase
                    inputRef={inputRef}
                    value={inputValue}
                    size="small"
                    onChange={(e) => updateStore?.(fieldKey, formatValue(e.target.value))}
                    onBlur={handleBlur}
                    sx={{ flexGrow: 1, pointerEvents: 'none' }}
                    slotProps={{
                        input: {
                            sx: { textAlign: 'right', p: 0, cursor: 'default' },
                        },
                    }}
                />
                <IconButton
                    size="small"
                    disableRipple
                    onClick={() => { inputRef.current?.blur(); updateStore?.(fieldKey, formatValue(Number(inputRef.current?.value) + increment)) }}
                    sx={{
                        p: 0.5,
                        borderRadius: 1,
                        opacity: Number(inputValue) >= maxValue ? 0.4 : 1,
                        '&:hover': { background: Number(inputValue) >= maxValue ? '' : 'rgba(255,255,255,0.15)' }
                    }}
                >
                    <ChevronRightIcon fontSize="small" />
                </IconButton>
            </Stack>
        </Box>
    );
}

export default NumberField;


================================================================================
FILE: ./client/src/components/fields/RangeField.tsx
================================================================================

import Box from "@mui/material/Box"
import Slider from "@mui/material/Slider"
import Typography from "@mui/material/Typography"
import { FieldProps } from "../NodeContent"
import { useTheme } from "@mui/material/styles"

const RangeField = ({ fieldKey, value, style, disabled, hidden, label, min, max, step, updateStore }: FieldProps) => {
    const theme = useTheme();

    return (
        <Box
            key={fieldKey}
            data-key={fieldKey}
            sx={{ pt: 0, pb: 1, pl: 1, pr: 1, ...style }}
            className={`nodrag ${disabled ? 'mellon-disabled' : ''} ${hidden ? 'mellon-hidden' : ''}`}>
            <Typography gutterBottom>{label}</Typography>
            <Slider
                value={value || [0, 1]}
                onChange={(_, newValue) => updateStore?.(fieldKey, newValue)}
                min={min || 0}
                max={max || 1}
                step={step || 0.01}
                valueLabelDisplay="auto"
                color="secondary"
                disableSwap
                sx={{
                    '& .MuiSlider-thumb': {
                        color: theme.palette.secondary.main,
                    },
                }}
            />
        </Box>
    )
}

export default RangeField;

================================================================================
FILE: ./client/src/components/fields/SelectField.tsx
================================================================================

import Box from "@mui/material/Box/Box";
import Select from "@mui/material/Select";
import FormControl from "@mui/material/FormControl";
import InputLabel from "@mui/material/InputLabel";
import { FieldProps } from "../NodeContent";
import { useEffect } from "react";

const SelectField = ({ fieldKey, value, style, disabled, hidden, label, options, updateStore, onChangeAction }: FieldProps) => {

    const handleShowAction = (value: string, optionsMap: object) => {
        Object.entries(optionsMap).forEach(([key, target]: any) => {
            const isHidden = key !== value;

            if (!target) return;

            if (target.endsWith('_group')) {
                console.log('target', target, isHidden);
                updateStore?.(target, { hidden: isHidden }, 'group');
            } else {
                updateStore?.(target, isHidden, 'hidden');
            }
        });

        // const items = Array.isArray(options)
        //     ? options.map((option: any) => ({ key: option.value }))
        //     : Object.keys(options).map(k => ({ key: k }));

        // items.forEach(({ key }: { key: string }) => {
        //     const isHidden = key !== value;

        //     if (!key || key.startsWith('__')) return;

        //     if (key.endsWith("_group")) {
        //         updateStore?.(key, { hidden: isHidden }, 'group');
        //     } else {
        //         updateStore?.(key, isHidden, 'hidden');
        //     }
        // });
    };

    const menuItems = Array.isArray(options) ? (
        options.map((v: any, i: number) => (
            <option key={`${fieldKey}-${i}`} value={v}>{v}</option>
        ))
    ) : (
        Object.entries(options).map(([k, v]: any) => (
            <option key={`${fieldKey}-${k}`} value={k}>
                {typeof v === 'object' ? v.label : v}
            </option>
        ))
    );

    useEffect(() => {
        if (onChangeAction?.action === 'show') {
            handleShowAction(value, onChangeAction?.target);
        }
    }, [value]);

    return (
        <Box
            data-key={fieldKey}
            className={`nodrag ${disabled ? 'mellon-disabled' : ''} ${hidden ? 'mellon-hidden' : ''}`}
            sx={{ ...style }}
        >
            <FormControl fullWidth>
                <InputLabel>{label}</InputLabel>
                <Select
                    fullWidth
                    size="small"
                    label={label}
                    value={value || ''}
                    native
                    onChange={(e) => updateStore?.(fieldKey, e.target.value)}
                >
                    {menuItems}
                </Select>
            </FormControl>
        </Box>
    )
};

export default SelectField;


================================================================================
FILE: ./client/src/components/fields/TagsField.tsx
================================================================================

import Box from "@mui/material/Box";
import Autocomplete from "@mui/material/Autocomplete";
import TextField from "@mui/material/TextField";

import { FieldProps } from "../NodeContent";

const TagsField = ({ fieldKey, value, style, disabled, hidden, label, no_validation, options, updateStore }: FieldProps) => {
    const tags = typeof value === 'string' ? [value] : value || [];

    return (
        <Box
            data-key={fieldKey}
            sx={{ minWidth: '320px', ...style }}
            className={`nodrag ${disabled ? 'mellon-disabled' : ''} ${hidden ? 'mellon-hidden' : ''}`}
        >
            <Autocomplete
                multiple
                disablePortal
                filterSelectedOptions
                handleHomeEndKeys
                freeSolo={no_validation}
                options={options}
                renderInput={(params: any) => <TextField {...params} label={label} />}
                onChange={(_, v) => updateStore?.(fieldKey, v)}
                value={tags}
                size="small"
            />
        </Box>
    )
}

export default TagsField;

================================================================================
FILE: ./client/src/components/fields/TextField.tsx
================================================================================

import Box from "@mui/material/Box";
import MuiTextField from "@mui/material/TextField";
import { FieldProps } from "../NodeContent";

const TextField = ({
    fieldKey,
    value,
    dataType,
    style,
    disabled,
    hidden,
    label,
    updateStore,
}: FieldProps) => {
    return (
        <Box
            data-key={fieldKey}
            sx={{ ...style }}
            className={`${disabled ? 'mellon-disabled' : ''} ${hidden ? 'mellon-hidden' : ''}`}
        >
            <MuiTextField
                onChange={(e) => updateStore?.(fieldKey, e.target.value)}
                variant="outlined"
                type="text"
                size="small"
                fullWidth
                label={label}
                value={value}
                className="nodrag"
                autoComplete="off"
                sx={ (dataType === 'int' || dataType === 'integer' || dataType === 'float' || dataType === 'number') ? { '& input': { textAlign: 'right' } } : {} }
            />
        </Box>
    );
}

export default TextField;

================================================================================
FILE: ./client/src/components/fields/TextareaField.tsx
================================================================================

import Box from "@mui/material/Box";
import { FieldProps } from "../NodeContent";
import { TextField } from "@mui/material";

const TextareaField = ({ fieldKey, value, style, disabled, hidden, label, updateStore }: FieldProps) => {
    return (
        <Box
            key={fieldKey}
            data-key={fieldKey}
            className={`nodrag nowheel ${disabled ? 'mellon-disabled' : ''} ${hidden ? 'mellon-hidden' : ''}`}
            sx={{ minWidth: '320px', ...style }}
        >
            <TextField
                variant="outlined"
                type="text"
                size="small"
                fullWidth
                multiline
                minRows={3}
                maxRows={12}
                label={label}
                value={value}
                onChange={(e) => updateStore?.(fieldKey, e.target.value)}
            />
        </Box>
    );
}

export default TextareaField;

================================================================================
FILE: ./client/src/components/fields/ToggleField.tsx
================================================================================

import Box from "@mui/material/Box";
import Switch from "@mui/material/Switch";
import Checkbox from "@mui/material/Checkbox";
import FormControlLabel from "@mui/material/FormControlLabel";
import FormGroup from "@mui/material/FormGroup";
import { FieldProps } from "../NodeContent";
import { useEffect } from "react";

const ToggleField = ({ fieldType, fieldKey, label, style, disabled, hidden, value, updateStore, onChangeAction }: FieldProps) => {
    const MuiSwitch = fieldType === 'switch' ? Switch : Checkbox;

    const handleDisableAction = (value: boolean, target: any) => {
        const onTrueTargets = Array.isArray(target.true) ? target.true : [target.true];
        const onFalseTargets = Array.isArray(target.false) ? target.false : [target.false];

        onTrueTargets.forEach((field: string) => {
            if (field.endsWith('_group')) {
                updateStore?.(field, { disabled: value }, 'group');
            } else {
                updateStore?.(field, value, 'disabled');
            }
        });
        onFalseTargets.forEach((field: string) => {
            if (field.endsWith('_group')) {
                updateStore?.(field, { disabled: !value }, 'group');
            } else {
                updateStore?.(field, !value, 'disabled');
            }
        });
    };

    useEffect(() => {
        if (onChangeAction?.action === 'disable') {
            handleDisableAction(value, onChangeAction.target);
        }
    }, [value]);

    return (
        <Box
            data-key={fieldKey}
            className={`${disabled ? 'mellon-disabled' : ''} ${hidden ? 'mellon-hidden' : ''}`}
            sx={{ ...style }}
        >
            <FormGroup>
                <FormControlLabel
                    sx={{ m: 0, p: 0 }}
                    control={<MuiSwitch
                        sx={{ mr: 0.5 }}
                        size="small"
                        color="secondary"
                        className="nodrag"
                        checked={value}
                        onChange={(e) => updateStore?.(fieldKey, e.target.checked)}
                    />}
                    label={label}
                />
            </FormGroup>
        </Box>
    );
};


export default ToggleField;


================================================================================
FILE: ./client/src/components/fields/UIDropdownIcon.tsx
================================================================================

import Box from "@mui/material/Box";
import IconButton from "@mui/material/IconButton";
import MoreVertIcon from '@mui/icons-material/MoreVert';
import Menu from "@mui/material/Menu";
import { useTheme } from "@mui/material/styles";

import { FieldProps } from "../NodeContent";
import { useState } from "react";
import Divider from "@mui/material/Divider";
import MenuItem from "@mui/material/MenuItem";

const UIDropdownIcon = ({ fieldKey, style, disabled, hidden, label, options, updateStore, onChangeAction }: FieldProps) => {
    const [anchorEl, setAnchorEl] = useState<null | HTMLElement>(null);
    const open = Boolean(anchorEl);
    const targetFields = Array.isArray(onChangeAction?.target) ? onChangeAction?.target : [onChangeAction?.target];

    const theme = useTheme();

    const handleClick = (event: React.MouseEvent<HTMLButtonElement>) => {
        setAnchorEl(event.currentTarget);
    };
    const handleMenuItemClick = (i: number) => {
        setAnchorEl(null);
        if (i<0) return;

        const targetValue = Array.isArray(options[i].value) ? options[i].value : [options[i].value];

        targetFields.forEach((k: string, i: number) => {
            updateStore?.(k, targetValue[i]);
        });
    };

    return (
        <Box data-key={fieldKey} className={`flex-auto nodrag ${disabled ? 'mellon-disabled' : ''} ${hidden ? 'mellon-hidden' : ''}`} sx={{ ...style }}>
            <IconButton
                onClick={handleClick}
                title={label}
            >
                <MoreVertIcon />
            </IconButton>
            <Menu
                anchorEl={anchorEl}
                open={open}
                onClose={() => handleMenuItemClick(-1)}
                slotProps={{
                    paper: {
                        sx: {
                            maxHeight: '640px',
                            lineHeight: '0',
                            '& li:hover': {
                                backgroundColor: theme.palette.secondary.main,
                            },
                        },
                        elevation: 8,
                    },
                }}
            >
                {options.map((option: any, i: number) => (
                    option.label?.startsWith('---') ? (
                        <Divider key={i} sx={{ borderColor: 'rgba(255, 255, 255, 0.5)' }} />
                    ) : (
                        <MenuItem key={i} sx={{ lineHeight: '1.2', pl: 1, pr: 1 }} onClick={() => handleMenuItemClick(i)}>
                            {option.label}
                        </MenuItem>
                    )
                ))}
            </Menu>
        </Box>
    )
}

export default UIDropdownIcon;

================================================================================
FILE: ./client/src/components/fields/UIImageField.tsx
================================================================================

import { FieldProps } from "../NodeContent";
import config from '../../../config';
import Box from "@mui/material/Box";
import { KeyboardEventHandler, MouseEventHandler, useCallback, useEffect, memo, useRef, useState, WheelEventHandler } from "react";
import Modal from "@mui/material/Modal";
import IconButton from "@mui/material/IconButton";
import Slider from "@mui/material/Slider";
import ArrowBackIcon from '@mui/icons-material/ArrowBack';
import ArrowForwardIcon from '@mui/icons-material/ArrowForward';
import CloseIcon from '@mui/icons-material/Close';
import { useTheme } from '@mui/material/styles';
import { deepEqual } from '../utils/deepEqual';

const LightBox = memo(({ urls, index, label, onClose }: { urls: {url: string, width: number, height: number}[], index: number, label: string, onClose: () => void }) => {
    const theme = useTheme();

    const [currentIndex, setCurrentIndex] = useState(-1);
    const [zoom, setZoom] = useState(1);
    const [pan, setPan] = useState({ x: 0, y: 0 });

    const isDraggingRef = useRef(false);
    const dragStartRef = useRef({ x: 0, y: 0 });
    const timeRef = useRef(0);

    // Add mouse drag handlers for panning
    const handleMouseDown = (e: React.MouseEvent) => {
        if (zoom === 1) return;
        isDraggingRef.current = true;
        dragStartRef.current = {
            x: e.clientX - pan.x,
            y: e.clientY - pan.y
        };
    };

    const handleMouseMove = (e: React.MouseEvent) => {
        if (!isDraggingRef.current) return;
        const newX = e.clientX - dragStartRef.current.x;
        const newY = e.clientY - dragStartRef.current.y;
        
        // Calculate bounds to prevent panning outside image bounds
        const bounds = {
            x: Math.min(Math.max(newX, -(zoom - 1) * 500), (zoom - 1) * 500),
            y: Math.min(Math.max(newY, -(zoom - 1) * 500), (zoom - 1) * 500)
        };
        
        setPan(bounds);
    };

    const handleMouseUp = (_: React.MouseEvent) => {
        isDraggingRef.current = false;
    };

    // Reset pan when zoom changes or image changes
    useEffect(() => {
        setPan({ x: 0, y: 0 });
    }, [zoom, currentIndex]);

    useEffect(() => {
        timeRef.current = Date.now();
    }, [urls]);

    useEffect(() => {
        setZoom(1);
        setPan({ x: 0, y: 0 });
        setCurrentIndex(index);
    }, [index]);

    const handleKeyDown = useCallback<KeyboardEventHandler<HTMLDivElement>>((e) => {
        if (currentIndex === -1) return;

        if (e.key === 'ArrowLeft' || e.key === 'ArrowRight') {
            e.preventDefault();
            e.stopPropagation();

            if (e.key === 'ArrowLeft' && currentIndex > 0) {
                setCurrentIndex(currentIndex - 1);
            }
            if (e.key === 'ArrowRight' && currentIndex < urls.length - 1) {
                setCurrentIndex(currentIndex + 1);
            }    
        }
    }, [currentIndex, urls.length]);

    const handleWheel = useCallback<WheelEventHandler<HTMLDivElement>>((e) => {
        if (currentIndex === -1) return;
        setZoom(prev => Math.min(Math.max(1, prev - e.deltaY * 0.005), 4));
    }, [currentIndex]);

    const currentUrl = () => {
        if (currentIndex === -1) return '';
        return `http://${config.serverAddress}${urls[currentIndex].url.split('?')[0].replace(/\/$/, '')}?t=${timeRef.current}`;
    };

    // Navigation handlers
    const handlePrevImage = useCallback<MouseEventHandler<HTMLButtonElement>>(() => currentIndex > 0 && setCurrentIndex(currentIndex - 1), [currentIndex]);
    const handleNextImage = useCallback<MouseEventHandler<HTMLButtonElement>>(() => currentIndex < urls.length - 1 && setCurrentIndex(currentIndex + 1), [currentIndex, urls.length]);

    return (
        <Modal
            open={currentIndex > -1}
            onClose={onClose}
            onKeyDown={handleKeyDown}
            onWheel={handleWheel}
            aria-labelledby="lightbox"
        >
            <Box
                sx={{
                    position: 'absolute',
                    top: '50%',
                    left: '50%',
                    transform: 'translate(-50%, -50%)',
                    width: '100vw',
                    height: '100vh',
                    display: 'flex',
                    flexDirection: 'column',
                    justifyContent: 'center',
                    alignItems: 'center',
                }}
                onClick={onClose}
            >
                <Box
                    sx={{
                        display: 'flex',
                        alignItems: 'center',
                        p: 2,
                        backgroundColor: theme.palette.background.paper,
                        borderRadius: 1,
                        mb: 1, mt: 2,
                        //border: `1px solid ${theme.palette.divider}`,
                    }}
                    onClick={(e) => { e.stopPropagation(); e.preventDefault(); }}
                >
                    <IconButton 
                        onClick={handlePrevImage}
                        disabled={currentIndex === 0}
                        size="small"
                    >
                        <ArrowBackIcon />
                    </IconButton>
                    <IconButton
                        onClick={handleNextImage}
                        disabled={currentIndex === urls.length - 1}
                        size="small"
                    >
                        <ArrowForwardIcon />
                    </IconButton>
                    <Slider
                        value={zoom}
                        onChange={(_, newValue) => setZoom(newValue as number)}
                        min={1}
                        max={4}
                        step={0.1}
                        sx={{ mx: 2, width: 200 }}
                    />
                    <Box sx={{ flexGrow: 1 }} />
                    <IconButton onClick={onClose} size="small">
                        <CloseIcon />
                    </IconButton>
                </Box>
                <Box
                    sx={{
                        flexGrow: 1,
                        overflow: 'hidden',
                        display: 'flex',
                        justifyContent: 'center',
                        alignItems: 'center',
                        cursor: zoom > 1 ? 'grab' : 'default',
                        '&:active': {
                            cursor: zoom > 1 ? 'grabbing' : 'default',
                        },
                        '& img': {
                            maxWidth: '100%',
                            maxHeight: '100%',
                            objectFit: 'contain',
                            p: 0, m: 0,
                            transform: `scale(${zoom}) translate(${pan.x / zoom}px, ${pan.y / zoom}px)`,
                            transition: isDraggingRef.current ? 'none' : 'transform 0.2s',
                            pointerEvents: 'none',
                            imageRendering: 'pixelated'
                        }
                    }}
                    onMouseDown={handleMouseDown}
                    onMouseMove={handleMouseMove}
                    onMouseUp={handleMouseUp}
                    onMouseLeave={handleMouseUp}
                    onClick={(e) => { e.stopPropagation(); e.preventDefault(); }}
                >
                {currentIndex > -1 && (
                    <img
                        src={currentUrl()}
                        alt={`${label} ${currentIndex}`}
                        width={`${urls[currentIndex].width}`}
                        height={`${urls[currentIndex].height}`}
                    />
                )}
                </Box>
            </Box>
        </Modal>
    )
}, (prevProps, nextProps) => {
    if (prevProps.index !== nextProps.index) { 
        return false;
    }

    if (!deepEqual(prevProps.urls, nextProps.urls)) {
        return false;
    }

    return true;
});

const UIImageField = ({ fieldKey, value, style, disabled, hidden, label }: FieldProps) => {
    if (typeof value === 'string') {
        value = [{url: value, width: 0, height: 0}];
    }

    //const imgWidth = value.length > 1 ? '50%' : '100%';
    const containerWidth = value.length > 1 ? '1288px' : 'auto';
    const maxHeight = value.length > 4 ? '1360px' : 'auto';

    const imageWidth = (width: number, height: number) => {
        if (value.length === 1) {
            return '100%';
        }
        const aspectRatio = width / height;
        if (aspectRatio > 1.6) {
            return '100%';
        }
        return '50%';
    }

    const [modalIndex, setModalIndex] = useState(-1);

    const handleModalOpen = (index: number) => {
        setModalIndex(index);
    };

    return (
        <>
        <Box
            data-key={fieldKey}
            sx={{
                width: containerWidth,
                height: 'auto',
                maxWidth: '2048px',
                maxHeight: maxHeight,
                overflow: value.length > 4 ? 'auto' : 'hidden',
                mb: 2,
                ...style,
            }}
            className={`${value.length > 4 ? 'nowheel' : ''} ${disabled ? 'mellon-disabled' : ''} ${hidden ? 'mellon-hidden' : ''}`}
        >
            {value.map(({url, width, height}: {url: string, width: number, height: number}, index: number) => (
                <Box
                    key={`${fieldKey}-${index}`}
                    sx={{
                        width: imageWidth(Number(width), Number(height)),
                        height: 'auto',
                        display: 'block',
                        float: 'left',
                        '& img': {
                            width: '100%',
                            height: 'auto',
                            display: 'block',
                            p: 0.25,
                            cursor: 'pointer'
                        }
                    }}
                >
                    <img src={`http://${config.serverAddress}${url}`} alt={`${label} ${index}`} onClick={() => handleModalOpen(index)} />
                </Box>
            ))}
        </Box>

        <LightBox
            urls={value}
            index={modalIndex}
            label={label || ''}
            onClose={() => setModalIndex(-1)}
        />
        </>
    );
};

export default UIImageField;

================================================================================
FILE: ./client/src/components/fields/UIThreeField.tsx
================================================================================

// TODO: NOT WORKING, need to find a better way to transmit data to a three.js viewer

import { lazy } from "react";
const ThreePreview = lazy(() => import('./UIThreePreview'));

import { FieldProps } from "../NodeContent";
import Box from "@mui/material/Box";

const UIThreeFields = ({ fieldKey, value, style, disabled, hidden }: FieldProps) => {
    return (
        <Box
            sx={{ p: 0, m: 0, mt: 1, mb: 1, ...style }}
            className={`nodrag nowheel ${disabled ? 'mellon-disabled' : ''} ${hidden ? 'mellon-hidden' : ''}`}
        >
            <ThreePreview nodeId="test" dataKey={fieldKey} value={value} />
        </Box>
    );
};

export default UIThreeFields;

================================================================================
FILE: ./client/src/components/fields/UIThreePreview.tsx
================================================================================

// @ts-nocheck
// TODO: can't make it work with typescript
import { Suspense, useRef, useState, useEffect } from 'react';
import { Canvas } from '@react-three/fiber';
import { useGLTF, Environment, OrbitControls } from '@react-three/drei';
import { useWebSocket } from '../WebsocketContext';

function Model({ url }) {
    const { scene } = useGLTF(url);
    return <primitive object={scene} />;
}

function base64ToBlob(base64, contentType = "", sliceSize = 512) {
    const byteCharacters = atob(base64.split(",")[1]);
    const byteArrays = [];

    for (let offset = 0; offset < byteCharacters.length;
        offset += sliceSize) {
        const slice = byteCharacters.slice(
            offset, offset + sliceSize);

        const byteNumbers = new Array(slice.length);
        for (let i = 0; i < slice.length; i++) {
            byteNumbers[i] = slice.charCodeAt(i);
        }

        const byteArray = new Uint8Array(byteNumbers);
        byteArrays.push(byteArray);
    }

    const blob = new Blob(byteArrays, { type: contentType });
    return blob;
}

export default function ThreePreview({ nodeId, dataKey, width = 512, height = 512, ...props }) {
    const [modelUrl, setModelUrl] = useState<string | null>(null);
    const { threeData } = useWebSocket();

    const modelValue = threeData[`${nodeId}-${dataKey}`];

    useEffect(() => {
        if (!modelValue) {
            setModelUrl(null);
            return;
        }

        if (modelValue.startsWith('data:')) {
            // Convert base64 to blob URL
            const blob = base64ToBlob(modelValue, 'model/gltf-binary');
            const blobUrl = URL.createObjectURL(blob);
            setModelUrl(blobUrl);

            // Cleanup function
            return () => {
                URL.revokeObjectURL(blobUrl);
                if (modelUrl) {
                    useGLTF.clear(modelUrl);
                }
            };
        } else {
            setModelUrl(modelValue);
            return () => {
                if (modelUrl) {
                    useGLTF.clear(modelUrl);
                }
            };
        }

    }, [modelValue]);

    return (
        <div style={{ position: 'relative', width, height }} {...props}>
            <Canvas style={{ background: '#333333' }}>
                <Suspense fallback={null}>
                    <directionalLight position={[5, 5, 5]} intensity={3} />
                    {modelUrl && <Model url={modelUrl} />}
                    <OrbitControls />
                    <Environment preset="warehouse" background={false} />
                </Suspense>
            </Canvas>
        </div>
    );
}

================================================================================
FILE: ./client/src/theme/themeConfig.ts
================================================================================

import { ThemeOptions } from '@mui/material/styles';
import { WorkflowType } from '../stores/nodeStore';

// Shared color palette values
const colors = {
  workflow: {
    primary: '#ffb300',
    background: {
      default: '#121212',
      paper: '#1a1a1a',
    }
  },
  tool: {
    primary: '#e63946', // Vibrant red that works well on light backgrounds
    background: {
      default: '#f5f5f7', // Very light gray with slight blue tint
      paper: '#ffffff'    // Pure white for elevated surfaces
    }
  },
  secondary: '#00695f'
} as const;

// Theme shape variants
const shapes = {
  workflow: {
    borderRadius: 0,
  },
  tool: {
    borderRadius: 8,
  },
} as const;

// Typography variants
const typography = {
  workflow: {
    fontFamily: 'JetBrains Mono',
    fontSize: 14,
    h6: {
      fontFamily: 'JetBrains Mono',
      fontWeight: 700,
      fontSize: '1.15rem',
    },
    button: {
      fontFamily: 'JetBrains Mono',
      textTransform: 'none',
    }
  },
  tool: {
    fontFamily: 'Inter, sans-serif',
    fontSize: 14.5,
    letterSpacing: '0.01em',
    h6: {
      fontFamily: 'Inter, sans-serif',
      fontWeight: 600,
      fontSize: '1.2rem',
      letterSpacing: '0.02em',
    },
    button: {
      fontFamily: 'Inter, sans-serif',
      textTransform: 'none',
      fontWeight: 500,
      fontSize: '0.9rem',
      letterSpacing: '0.015em',
    },
    body1: {
      fontSize: '0.925rem',
      letterSpacing: '0.01em',
    },
    body2: {
      fontSize: '0.85rem',
      letterSpacing: '0.01em',
    }
  }
} as const;

// Base theme configuration that doesn't change with mode
const baseTheme: Partial<ThemeOptions> = {
  components: {
    MuiAccordionSummary: {
      styleOverrides: {
        root: {
          fontFamily: 'inherit',
        },
      },
    },
    // Override default Paper component to respect borderRadius
    MuiPaper: {
      styleOverrides: {
        rounded: {
          borderRadius: 'inherit',
        },
      },
    },
    // Override default Button component to respect borderRadius
    MuiButton: {
      styleOverrides: {
        root: {
          borderRadius: 'inherit',
        },
      },
    },
    // Override default Card component to respect borderRadius
    MuiCard: {
      styleOverrides: {
        root: {
          borderRadius: 'inherit',
        },
      },
    },
  },
};

// Function to create mode-specific theme options
const createModeTheme = (mode: WorkflowType): Partial<ThemeOptions> => ({
  ...baseTheme,
  shape: shapes[mode],
  typography: typography[mode],
  palette: {
    mode: mode === 'workflow' ? 'dark' : 'light',
    primary: {
      main: colors[mode].primary,
    },
    secondary: {
      main: colors.secondary,
    },
    background: colors[mode].background,
  },
});

export const getThemeOptions = (mode: WorkflowType): ThemeOptions => 
  createModeTheme(mode) as ThemeOptions; 
